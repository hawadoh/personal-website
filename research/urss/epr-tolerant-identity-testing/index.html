<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Classical tolerant identity test for the EPR state | ùóßùóòùóî‚Ä¢ùóòùóöùóö</title><meta name=keywords content><meta name=description content="Goal.¬†Given $N$ i.i.d. copies of an unknown bipartite state $\rho_{AB}$ held by Alice and Bob, certify that $\rho_{AB}$ held by Alice and Bob is within trace‚Äëdistance $\varepsilon$ of

$$
\ket{\text{EPR}}_{AB} = \frac{1}{\sqrt2}\left(\ket{00}_{AB} + \ket{11}_{AB}\right),
$$
using only sequential* (one qubit at a time), local measurements in the standard ($\{ \ket{0}, \ket{1} \}$) or Hadamard ($\{ \ket{+}, \ket{-} \}$) bases, and classical communication. Importantly, we never perform any joint or Bell‚Äêbasis measurement on $AB$."><meta name=author content="Howard Cheung"><link rel=canonical href=https://teaegg.net/research/urss/epr-tolerant-identity-testing/><link crossorigin=anonymous href=/assets/css/stylesheet.12d2e5fe7e7a6b449beaee7514d9f08063da1272468eea14524da628ddfaabb5.css integrity="sha256-EtLl/n56a0Sb6u51FNnwgGPaEnJGjuoUUk2mKN36q7U=" rel="preload stylesheet" as=style><link rel=icon href=https://teaegg.net/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://teaegg.net/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://teaegg.net/favicon-32x32.png><link rel=apple-touch-icon href=https://teaegg.net/apple-touch-icon.png><link rel=mask-icon href=https://teaegg.net/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://teaegg.net/research/urss/epr-tolerant-identity-testing/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}]})})</script><link rel=icon type=image/png href=/favicon/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/favicon/favicon.svg><link rel="shortcut icon" href=/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/favicon/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="Teaegg"><link rel=manifest href=/favicon/site.webmanifest><meta property="og:url" content="https://teaegg.net/research/urss/epr-tolerant-identity-testing/"><meta property="og:site_name" content="ùóßùóòùóî‚Ä¢ùóòùóöùóö"><meta property="og:title" content="Classical tolerant identity test for the EPR state"><meta property="og:description" content="Goal.¬†Given $N$ i.i.d. copies of an unknown bipartite state $\rho_{AB}$ held by Alice and Bob, certify that $\rho_{AB}$ held by Alice and Bob is within trace‚Äëdistance $\varepsilon$ of $$ \ket{\text{EPR}}_{AB} = \frac{1}{\sqrt2}\left(\ket{00}_{AB} + \ket{11}_{AB}\right), $$ using only sequential* (one qubit at a time), local measurements in the standard ($\{ \ket{0}, \ket{1} \}$) or Hadamard ($\{ \ket{+}, \ket{-} \}$) bases, and classical communication. Importantly, we never perform any joint or Bell‚Äêbasis measurement on $AB$."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="research"><meta property="article:published_time" content="2025-08-03T23:35:49+01:00"><meta property="article:modified_time" content="2025-08-03T23:35:49+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Classical tolerant identity test for the EPR state"><meta name=twitter:description content="Goal.¬†Given $N$ i.i.d. copies of an unknown bipartite state $\rho_{AB}$ held by Alice and Bob, certify that $\rho_{AB}$ held by Alice and Bob is within trace‚Äëdistance $\varepsilon$ of

$$
\ket{\text{EPR}}_{AB} = \frac{1}{\sqrt2}\left(\ket{00}_{AB} + \ket{11}_{AB}\right),
$$
using only sequential* (one qubit at a time), local measurements in the standard ($\{ \ket{0}, \ket{1} \}$) or Hadamard ($\{ \ket{+}, \ket{-} \}$) bases, and classical communication. Importantly, we never perform any joint or Bell‚Äêbasis measurement on $AB$."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"üî¨ Research","item":"https://teaegg.net/research/"},{"@type":"ListItem","position":2,"name":"üîêüí° Undergraduate Research Support Scheme (URSS)","item":"https://teaegg.net/research/urss/"},{"@type":"ListItem","position":3,"name":"Classical tolerant identity test for the EPR state","item":"https://teaegg.net/research/urss/epr-tolerant-identity-testing/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Classical tolerant identity test for the EPR state","name":"Classical tolerant identity test for the EPR state","description":"Goal.¬†Given $N$ i.i.d. copies of an unknown bipartite state $\\rho_{AB}$ held by Alice and Bob, certify that $\\rho_{AB}$ held by Alice and Bob is within trace‚Äëdistance $\\varepsilon$ of $$ \\ket{\\text{EPR}}_{AB} = \\frac{1}{\\sqrt2}\\left(\\ket{00}_{AB} + \\ket{11}_{AB}\\right), $$ using only sequential* (one qubit at a time), local measurements in the standard ($\\{ \\ket{0}, \\ket{1} \\}$) or Hadamard ($\\{ \\ket{+}, \\ket{-} \\}$) bases, and classical communication. Importantly, we never perform any joint or Bell‚Äêbasis measurement on $AB$.\n","keywords":[],"articleBody":"Goal.¬†Given $N$ i.i.d. copies of an unknown bipartite state $\\rho_{AB}$ held by Alice and Bob, certify that $\\rho_{AB}$ held by Alice and Bob is within trace‚Äëdistance $\\varepsilon$ of $$ \\ket{\\text{EPR}}_{AB} = \\frac{1}{\\sqrt2}\\left(\\ket{00}_{AB} + \\ket{11}_{AB}\\right), $$ using only sequential* (one qubit at a time), local measurements in the standard ($\\{ \\ket{0}, \\ket{1} \\}$) or Hadamard ($\\{ \\ket{+}, \\ket{-} \\}$) bases, and classical communication. Importantly, we never perform any joint or Bell‚Äêbasis measurement on $AB$.\nSingle-pair matching‚Äëoutcomes protocol Suppose Alice and Bob share $N$ i.i.d. copies of an unknown state $\\rho_{AB}$. For each pair $i = 1, \\dots, N$, they do the following in sequence*:\nBasis choice:\nAlice picks $\\theta_i \\in \\{ 0, 1 \\}$ uniformly at random. Bob picks $\\tilde{\\theta}_i \\in \\{ 0, 1 \\}$ uniformly at random. Here $\\theta_i = 0$ means ‚Äústandard basis‚Äù and $\\theta_i = 1$ means ‚ÄúHadamard basis‚Äù.\nLocal measurement:\nAlice measures her qubit in basis $\\theta_i$ to get outcome $x_i \\in \\{ 0, 1 \\}$. Bob measures his qubit in basis $\\tilde\\theta_i$, obtaining $\\tilde x_i \\in \\{ 0, 1 \\}$. Note. Apart from the one-off preparation/distribution of the shared state $\\rho_{AB}$, there is no need for any further quantum channel or quantum memory; Alice and Bob simply perform immediate local measurements. In addition, since each measurement round consumes one i.i.d. copy of $\\rho_{AB}$, the parameter $N$ can be viewed interchangeably as either the number of rounds or the number of copies, and I will use it in both senses throughout our single-pair analysis.\nAfter all $N$ measurement rounds (one round for each i.i.d. copy of $\\rho_{AB}$), Alice and Bob publicly reveal their basis strings $\\theta = (\\theta_1, \\dots, \\theta_N)$ and $\\tilde{\\theta} = (\\tilde{\\theta}_1, \\dots, \\tilde{\\theta}_N)$, and their outcome strings $x = (x_1, \\dots, x_N)$, $\\tilde{x} = (\\tilde{x}_1, \\dots, \\tilde{x}_N)$ over a classical authenticated channel (CAC).\nDefine the matching-basis index set $$ S = \\{i : \\theta_i = \\tilde\\theta_i\\}. $$ On each $i\\in S$, Alice and Bob measured in the same basis. If by rare chance $S = \\varnothing$ (no matching bases at all), simply rerun the whole protocol as the probability of $S = \\varnothing$ is $2^{-N}$, which is negligible for modest $N$.\nCompute the observed error rate $$ \\hat{\\delta} = \\frac{1}{|S|}\\,\\left|\\{\\,i\\in S : x_i \\neq \\tilde x_i\\}\\right|. $$ which represents the mismatch fraction conditioned on matching-basis rounds.\nRemark. The sequential ordering is purely a hardware convenience and not a theoretical requirement: it guarantees that no quantum memory or parallel measurement modules are ever needed. If you already have $N$ measurement setups and don‚Äôt mind operating them in parallel, you may instead prepare all bases at once, measure in parallel, and only then exchange classical data. Both versions give the same statistical bound.\nAsymptotic bound Motivating question. Can we really conclude that, if the classical matching-outcomes test in the protocol above succeeds with high probability (i.e. a small observed error $\\hat{\\delta}$), then the quantum state $\\rho_{AB}$ must be close to an ideal EPR pair, without ever performing a joint or Bell-basis measurement?\nIn other words, when given $\\rho_{AB}^{\\otimes N}$, what is the smallest number $N$ of i.i.d. copies required to certify that $\\rho_{AB}$ lies within trace distance $\\varepsilon$ of the ideal EPR state?\nWe‚Äôll first analyse the idealised, infinite-round/copy limit $N \\to \\infty$ to see theoretically why a high success rate forces high fidelity to $\\ket{\\text{EPR}}_{AB}$. After that, we‚Äôll return to the realistic, finite-sample setting to turn this into a practical protocol in the next section.\nRemark. For very large $N$, the observed matching and mismatch rates concentrate so tightly around the true error parameter $\\delta$ (by the law of large numbers) that we can replace all finite‚Äêsample quantities ($\\hat{\\delta}$) with $\\delta$ itself when deriving the asymptotic bound, making our theoretical analysis easier.\nRecall that:\nThe fidelity between a state $\\rho$ and a pure state $\\ket{\\psi}$ is defined as $$ F\\left(\\rho, \\ket{\\psi}\\right) := \\sqrt{\\bra{\\psi}\\,\\rho\\,\\ket{\\psi}}. $$ The trace distance between two states $\\rho$ and $\\sigma$ is defined as $$ D(\\rho,\\sigma) := \\frac{1}{2}\\|\\rho - \\sigma\\|_1. $$ Lemma. Let $\\rho_{AB}$ be a bipartite state where $A$ and $B$ are each systems of a single qubit. The probability of Alice and Bob getting matching outcomes (00 or 11) when they both measure in the standard basis ($Z$) is given by $\\text{tr}(\\Pi_1\\,\\rho_{AB})$, where $$ \\ket{\\text{EPR}} = \\ket{\\Psi_{00}} = \\frac{1}{\\sqrt{2}}(\\ket{00} + \\ket{11}), \\qquad \\ket{\\Psi_{01}} = \\frac{1}{\\sqrt{2}}(\\ket{00} - \\ket{11}), $$ and $$ \\Pi_1 = \\ket{\\text{EPR}} \\bra{\\text{EPR}} + \\ket{\\Psi_{01}} \\bra{\\Psi_{01}}. $$ Similarly, the probability of Alice and Bob getting matching outcomes (++ or --) when they both measure in the Hadamard basis ($X$) is given by $\\text{tr}(\\Pi_2\\,\\rho_{AB})$, with $$ \\ket{\\Psi_{10}} = \\frac{1}{\\sqrt{2}}(\\ket{01} + \\ket{10}), $$ and $$ \\Pi_2 = \\ket{\\text{EPR}} \\bra{\\text{EPR}} + \\ket{\\Psi_{10}} \\bra{\\Psi_{10}}. $$Proof. The probability of matching outcomes, $$ \\begin{aligned} \\Pr(\\text{match}_{Z}) \u0026= \\Pr(00) + \\Pr(11) \\\\\u0026= \\text{tr}(M_{00} + M_{11}) \u0026\\text{by Born rule} \\\\\u0026= \\text{tr}(\\ket{00}\\bra{00}\\,\\rho_{AB}) + \\text{tr}(\\ket{11}\\bra{11}\\,\\rho_{AB}) \u0026\\text{by def. of POVM operator} \\\\\u0026= \\text{tr}(\\bra{00}\\,\\rho_{AB}\\,\\ket{00}) + \\text{tr}(\\bra{11}\\,\\rho_{AB}\\,\\ket{11}) \u0026\\text{by cyclicity of trace} \\\\\u0026= \\bra{00}\\,\\rho_{AB}\\,\\ket{00} + \\bra{11}\\,\\rho_{AB}\\,\\ket{11} \u0026\\text{as trace of scalar = itself.} \\end{aligned} $$ Expanding $\\Pi_1$ we get $$ \\begin{aligned} \\Pi_1 \u0026= \\ket{\\text{EPR}} \\bra{\\text{EPR}} + \\ket{\\Psi_{01}} \\bra{\\Psi_{01}} \\\\\u0026=\\tfrac{1}{2}(\\ket{00}\\bra{00} + \\ket{00}\\bra{11} + \\ket{11}\\bra{00} + \\ket{11}\\bra{11} \\\\\u0026\\qquad+ \\ket{00}\\bra{00} - \\ket{00}\\bra{11} - \\ket{11}\\bra{00} + \\ket{11}\\bra{11}) \\\\\u0026= \\tfrac{1}{2}(2\\ket{00}\\bra{00} + 2\\ket{11}\\bra{11}) \\\\\u0026= \\ket{00}\\bra{00} + \\ket{11}\\bra{11}. \\end{aligned} $$Then $$ \\begin{aligned} \\text{tr}(\\Pi_1\\,\\rho_{AB}) \u0026= \\text{tr}(\\,(\\ket{00}\\bra{00} + \\ket{11}\\bra{11})\\,\\rho_{AB}) \u0026\\text{by def. of }\\Pi_1 \\\\\u0026= \\text{tr}(\\ket{00}\\bra{00}\\,\\rho_{AB}) + \\text{tr}(\\ket{11}\\bra{11}\\,\\rho_{AB}) \u0026\\text{by linearity of trace} \\\\\u0026= \\text{tr}(\\bra{00}\\,\\rho_{AB}\\,\\ket{00}) + \\text{tr}(\\bra{11}\\,\\rho_{AB}\\,\\ket{11}) \u0026\\text{by cyclicity of trace} \\\\\u0026= \\bra{00}\\,\\rho_{AB}\\,\\ket{00} + \\bra{11}\\,\\rho_{AB}\\,\\ket{11} \u0026\\text{as trace of scalar = itself.} \\end{aligned} $$ Hence $\\Pr(\\text{match}_Z) = \\text{tr}(\\Pi_1\\,\\rho_{AB})$ as required.\nSimilarly, for the measurement of systems $A$ and $B$ is performed in the Hadamard basis, we can first perform a change in basis and simplify $\\Pi_2$. Recall that $$ \\ket{0} = \\frac1{\\sqrt2}(\\ket{+} + \\ket{-}),\\qquad \\ket{1} = \\frac1{\\sqrt2}(\\ket{+} - \\ket{-}). $$Then $$ \\begin{aligned} \\ket{\\text{EPR}} \u0026= \\frac{1}{\\sqrt2}(\\ket{00} + \\ket{11}) \\\\\u0026= \\frac{1}{\\sqrt2}\\left( \\frac{\\ket{+} + \\ket{-}}{\\sqrt2} \\otimes \\frac{\\ket{+} + \\ket{-}}{\\sqrt2} + \\frac{\\ket{+} - \\ket{-}}{\\sqrt2} \\otimes \\frac{\\ket{+} - \\ket{-}}{\\sqrt2} \\right) \\\\\u0026= \\frac{1}{\\sqrt2}\\bigl(\\ket{++} + \\ket{--}\\bigr). \\end{aligned} $$Similarly one can easily verify $$ \\ket{\\Psi_{10}} = \\frac{1}{\\sqrt2}(\\ket{01} + \\ket{10}) = \\frac{1}{\\sqrt2}\\bigl(\\ket{++} - \\ket{--}\\bigr). $$Expanding $\\Pi_2$ we get $$ \\begin{aligned} \\Pi_2 \u0026= \\tfrac{1}{2}(\\ket{++}\\bra{++} + \\ket{++}\\bra{--} + \\ket{--}\\bra{++} + \\ket{--}\\bra{--} \\\\\u0026\\qquad+ \\ket{++}\\bra{++} - \\ket{++}\\bra{--} - \\ket{--}\\bra{++} + \\ket{--}\\bra{--}) \\\\\u0026= \\tfrac{1}{2}(2\\ket{++}\\bra{++} + 2\\ket{--}\\bra{--}) \\\\\u0026= \\ket{++}\\bra{++} + \\ket{--}\\bra{--}. \\end{aligned} $$Finally, by exactly the same Born-rule steps as above (now applied in the Hadamard basis), we have: $$ \\Pr(\\text{match}_X) = \\text{tr}(\\ket{++}\\bra{++}\\,\\rho_{AB}) + \\text{tr}(\\ket{--}\\bra{--}\\,\\rho_{AB}) = \\text{tr}(\\Pi_2\\,\\rho_{AB}),$$ so the proof is complete.\nNow suppose that $\\rho_{AB}$ is any state such that $$ \\underbrace{\\frac{1}{2}\\,\\text{tr}\\bigl(\\Pi_1\\,\\rho_{AB}\\bigr)}_{\\substack{\\text{matching outcomes}\\\\\\text{in standard (Z) basis}}} ~+~ \\underbrace{\\frac{1}{2}\\,\\text{tr}\\bigl(\\Pi_2\\,\\rho_{AB}\\bigr)}_{\\substack{\\text{matching outcomes}\\\\\\text{in Hadamard (X) basis}}} ~=~ \\underbrace{1 - \\delta}_{\\substack{\\text{overall success}\\\\\\text{probability}}} \\qquad (*) $$ for some $\\delta \\geq 0$.\nImagine we‚Äôre measuring $\\rho_{AB}$ in the Bell basis $\\{ \\ket{\\Psi_{00}}, \\ket{\\Psi_{01}}, \\ket{\\Psi_{10}}, \\ket{\\Psi_{11}} \\}$ (where $\\ket{\\text{EPR}} = \\ket{\\Psi_{00}}$). The measurement has four possible outcomes, corresponding to the four Bell states. Using Born rule and properties of trace, we can deduce the probability of getting each outcome: $$ \\begin{aligned} \u0026p_{00} = \\bra{\\Psi_{00}}\\,\\rho_{AB}\\,\\ket{\\Psi_{00}}, \u0026p_{01} = \\bra{\\Psi_{01}}\\,\\rho_{AB}\\,\\ket{\\Psi_{01}}, \\\\\u0026p_{10} = \\bra{\\Psi_{10}}\\,\\rho_{AB}\\,\\ket{\\Psi_{10}}, \u0026p_{11} = \\bra{\\Psi_{11}}\\,\\rho_{AB}\\,\\ket{\\Psi_{11}}. \\end{aligned} $$Since these are all the possible outcomes, $$ p_{00} + p_{01} + p_{10} + p_{11} = 1. \\qquad \\text{(Norm)} $$ Also, expanding $\\ket{\\Psi_{00}}\\bra{\\Psi_{00}}$ and $\\ket{\\Psi_{01}}\\bra{\\Psi_{01}}$ gives $$ \\begin{aligned} \\ket{\\Psi_{00}}\\bra{\\Psi_{00}} \u0026= \\tfrac{1}{2}\\bigl(\\ket{00}+\\ket{11}\\bigr)\\bigl(\\bra{00}+\\bra{11}\\bigr) \\\\\u0026= \\tfrac{1}{2}\\bigl(\\ket{00}\\bra{00}+\\ket{00}\\bra{11}+\\ket{11}\\bra{00}+\\ket{11}\\bra{11}\\bigr), \\\\ \\ket{\\Psi_{01}}\\bra{\\Psi_{01}} \u0026= \\tfrac{1}{2}\\bigl(\\ket{00}-\\ket{11}\\bigr)\\bigl(\\bra{00}-\\bra{11}\\bigr) \\\\\u0026= \\tfrac{1}{2}\\bigl(\\ket{00}\\bra{00}-\\ket{00}\\bra{11}-\\ket{11}\\bra{00}+\\ket{11}\\bra{11}\\bigr). \\end{aligned} $$Adding them gives $$ \\begin{aligned} \\ket{\\Psi_{00}}\\bra{\\Psi_{00}} + \\ket{\\Psi_{01}}\\bra{\\Psi_{01}} \u0026= \\tfrac{1}{2}\\bigl(2\\ket{00}\\bra{00} + 2\\ket{11}\\bra{11}\\bigr) \\\\ \u0026= \\ket{00}\\bra{00} + \\ket{11}\\bra{11} \\\\\u0026= \\Pi_1. \\end{aligned} $$ Similarly, expanding $\\ket{\\Psi_{00}}\\bra{\\Psi_{00}}$ and $\\ket{\\Psi_{10}}\\bra{\\Psi_{10}}$ gives $$ \\begin{aligned} \\ket{\\Psi_{00}}\\bra{\\Psi_{00}} \u0026= \\tfrac{1}{2}\\bigl(\\ket{++}+\\ket{--}\\bigr)\\bigl(\\bra{++}+\\bra{--}\\bigr) \\\\\u0026=\\tfrac{1}{2}\\bigl(\\ket{++}\\bra{++} + \\ket{++}\\bra{--} + \\ket{--}\\bra{++} + \\ket{--}\\bra{--}\\bigr), \\\\\\ket{\\Psi_{10}}\\bra{\\Psi_{10}} \u0026= \\tfrac{1}{2}\\bigl(\\ket{++}-\\ket{--}\\bigr)\\bigl(\\bra{++}-\\bra{--}\\bigr)\\\\ \u0026=\\tfrac{1}{2}\\bigl(\\ket{++}\\bra{++} - \\ket{++}\\bra{--} - \\ket{--}\\bra{++} + \\ket{--}\\bra{--}\\bigr). \\end{aligned} $$Adding these two lines gives $$ \\begin{aligned} \\ket{\\Psi_{00}}\\bra{\\Psi_{00}} + \\ket{\\Psi_{10}}\\bra{\\Psi_{10}} \u0026= \\tfrac{1}{2}\\bigl(2\\ket{++}\\bra{++} + 2\\ket{--}\\bra{--}\\bigr)\\\\ \u0026= \\ket{++}\\bra{++} + \\ket{--}\\bra{--} \\\\\u0026= \\Pi_2. \\end{aligned} $$ Using the definitions of $\\Pi_1$ and $\\Pi_2$ in terms of Bell states, Born rule, and properties of the trace, we can rewrite the average test success probability using these new terms.\nFor the standard basis part: $$ \\begin{aligned} \\text{tr}\\bigl(\\Pi_1\\,\\rho_{AB}\\bigr) \u0026= \\bra{00}\\,\\rho_{AB}\\,\\ket{00} + \\bra{11}\\,\\rho_{AB}\\,\\ket{11} \\\\\u0026= \\bra{\\Psi_{00}}\\,\\rho_{AB}\\,\\ket{\\Psi_{00}} + \\bra{\\Psi_{01}}\\,\\rho_{AB}\\,\\ket{\\Psi_{01}} \\\\\u0026= p_{00} + p_{01}, \\end{aligned} $$ and similarly for the Hadamard basis part: $$ \\begin{aligned} \\text{tr}\\bigl(\\Pi_2\\,\\rho_{AB}\\bigr) \u0026= \\bra{++}\\,\\rho_{AB}\\,\\ket{++} + \\bra{--}\\,\\rho_{AB}\\,\\ket{--} \\\\\u0026= \\bra{\\Psi_{00}}\\,\\rho_{AB}\\,\\ket{\\Psi_{00}} + \\bra{\\Psi_{10}}\\,\\rho_{AB}\\,\\ket{\\Psi_{10}} \\\\\u0026= p_{00} + p_{10}. \\end{aligned} $$ Hence, $$ \\begin{aligned} \\tfrac{1}{2}\\,\\text{tr}\\bigl(\\Pi_1\\,\\rho_{AB}\\bigr) + \\tfrac{1}{2}\\,\\text{tr}\\bigl(\\Pi_2\\,\\rho_{AB}\\bigr) \u0026= 1 - \\delta \u0026\\text{from $(*)$ above} \\\\[6pt]\\tfrac{1}{2}(p_{00} + p_{01}) + \\tfrac{1}{2}(p_{00} + p_{10}) \u0026= 1 - \\delta \\\\[6pt]p_{00} + \\tfrac{1}{2}(p_{01} + p_{10}) \u0026= 1 - \\delta \\\\[6pt]p_{00} + \\tfrac{1}{2}(1 - p_{00} - p_{11}) \u0026= 1 - \\delta \u0026\\text{by (norm)} \\\\[6pt]\\tfrac{1}{2}p_{00} - \\tfrac{1}{2}p_{11} \u0026= \\tfrac{1}{2} - \\delta \\\\[6pt]p_{00} - p_{11} \u0026= 1 - 2\\delta. \\end{aligned} $$ We don‚Äôt know the exact value for $p_{11}$, but since $p_{11}$ is a probability, $p_{11} \\geq 0$. Hence we can remove it and get the inequality $$ p_{00} \\geq 1 - 2\\delta. $$Therefore, the fidelity, as the number of rounds $N \\to \\infty$, $$ \\begin{aligned} F \u0026:= F(\\rho_{AB}, \\ket{\\text{EPR}}\\bra{\\text{EPR}})\\\\ \u0026= \\sqrt{\\bra{\\text{EPR}}\\,\\rho_{AB}\\,\\ket{\\text{EPR}}}\\\\ \u0026= \\sqrt{p_{00}}\\\\ \u0026\\geq \\sqrt{1 - 2\\delta} \\end{aligned} $$ for some true error rate $\\delta \\in [0, 1]$ where $\\delta = \\Pr[x_i \\neq \\tilde{x}_i ~|~ \\theta_i = \\tilde{\\theta}_i]$ is the mismatch probability.\nFrom $(*)$, we‚Äôve derived that if the average success probability of the classical outcomes test above is high ($\\geq 1 - \\delta$), then the fidelity (a measure of overlap between two states) of the shared quantum state $\\rho_{AB}$ with a perfect EPR pair between Alice and Bob must also be high ($\\geq \\sqrt{1 - 2\\delta}$), provided $\\delta$ is sufficiently small.\nRearranging $F^2\\geq 1-2\\delta$ gives $$ 1 - F^2 \\leq 2\\delta. $$ The Fuchs‚Äìvan‚ÄØde‚ÄØGraaf inequality gives, for the trace distance $\\varepsilon := D\\left(\\rho_{AB}, \\ket{\\text{EPR}}\\bra{\\text{EPR}}\\right)$, $$ \\varepsilon \\leq \\sqrt{1 - F^2}. $$ Combining the two inequalities give $\\varepsilon \\leq \\sqrt{2\\delta}$, and equivalently, $\\delta \\geq \\frac{1}{2}\\varepsilon^2$.\nTheorem (Asymptotic EPR Identity Bound).\nIn the asymptotic limit $N \\to \\infty$, let Alice and Bob share $N$ i.i.d. copies of an unknown state $\\rho_{AB}$. Define the true matching-basis error rate $\\delta = \\Pr[x_i \\neq \\tilde{x}_i ~|~ \\theta_i = \\tilde{\\theta}_i]$. Then, the trace distance $D(\\rho_{AB}, \\ket{\\text{EPR}} \\bra{\\text{EPR}}_{AB}) = \\varepsilon \\in [0, 1]$ between $\\rho_{AB}$ and the ideal EPR pair satisfies $$ \\varepsilon \\leq \\sqrt{2\\delta}, \\quad\\iff\\quad \\delta \\geq \\frac{\\varepsilon^2}{2}. $$ Finite-sample analysis With the asymptotic bound in hand, our task becomes a practical one: from a finite sample we must decide ‚Äúclose‚Äù or ‚Äúfar‚Äù while keeping the probability of error below some small target, say $\\alpha$.\nAlthough $$ \\varepsilon \\leq \\sqrt{2\\delta} $$ holds exactly once we know the true mismatch rate $\\delta$, in practice we only observe the empirical rate $\\hat{\\delta}$ from a finite number of rounds (as defined in the protocol); in the finite-sample setting we cannot hope to pinpoint the true $\\delta$ exactly.\nIf we tried to draw a single ‚Äúhard‚Äù cutoff line at $$ \\delta_* = \\frac{\\varepsilon^2}{2}, $$ then sadly we would suffer both false-accept and false-reject errors because the statistical fluctuations would cause the measured error rate $\\hat{\\delta}$ to frequently land on the wrong side of the cutoff line whenever the true value $\\delta$ is too close to $\\delta_*$.\nIn other words, with a finite number of samples, it is impossible to reliably distinguish between two scenarios that are infinitesimally close but on opposite sides of a sharp boundary. The statistical ‚Äúnoise‚Äù from finite sampling is larger than the tiny difference we are trying to measure. This means that an identity test that distinguishes states that are $\\varepsilon$-close from those that are more than $\\varepsilon$-far is not robust! The solution is to adopt a tolerant testing framework.\nInstead of a single distance threshold $\\varepsilon$, we define two: an acceptance tolerance $\\varepsilon_1$ and a rejection tolerance $\\varepsilon_2$, where $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$. Our goal is no longer to pinpoint a single boundary, but to reliably distinguish states that are ‚Äúclose‚Äù ($D(\\rho_{AB}, \\ket{\\text{EPR}}) \\leq \\varepsilon_1$) from those that are ‚Äúfar‚Äù ($D(\\rho_{AB}, \\ket{\\text{EPR}}) \\geq \\varepsilon_2$).\nThis framework creates a small ‚Äúpromise gap‚Äù around $\\delta_*$. By translating our trace distance tolerances ($\\varepsilon_1$ and $\\varepsilon_2$) into error rate thresholds, $\\delta_{\\text{close}}$ and $\\delta_{\\text{far}}$, which are functions of $\\varepsilon_1$ and $\\varepsilon_2$ respectively, we establish a ‚Äúbuffer zone‚Äù that can absorb those statistical fluctuations.\nBy making this ‚Äúpromise gap‚Äù just large enough and then applying a concentration bound to $\\hat{\\delta}$, we can guarantee that, with probability at least $1 - \\alpha$, the empirical error rate $\\hat{\\delta}$ stays on the correct side of its respective cutoff - so we will correctly declare ‚Äúclose‚Äù whenever $\\hat{\\delta} \\leq \\delta_{\\text{close}}$ and ‚Äúfar‚Äù whenever $\\hat{\\delta} \\geq \\delta_{\\text{far}}$, each with error at most $\\alpha$.\nFor simplicity, write $\\rho := \\rho_{AB}$ and $\\Phi := \\ket{\\text{EPR}}\\bra{\\text{EPR}}$. We need to define the hypotheses $\\mathbf{H_0}$ ($\\varepsilon_1$-close) and $\\mathbf{H_1}$ ($\\varepsilon_2$-far) for our test: $$ \\begin{cases} ~\\mathbf{H_0}: \u0026D(\\rho, \\Phi) \\,\\leq\\,\\varepsilon_1 \\quad\\iff\\quad \\rho \\text{ is ‚Äúclose‚Äù to }\\Phi, \\\\ ~\\mathbf{H_1}: \u0026D(\\rho, \\Phi) \\,\\geq\\,\\varepsilon_2 \\quad\\iff\\quad \\rho \\text{ is ‚Äúfar‚Äù from }\\Phi, \\end{cases} $$Also, recall that the asymptotic inequality $$ D(\\rho, \\Phi) \\leq \\sqrt{2\\delta} $$ was derived from the Fuchs‚Äìvan de Graaf bound and the matching-outcomes success rate. This is the soundness direction: it tells us that if the true mismatch rate $\\delta$ is small, then the state is also close in trace distance. It applies directly to the ‚Äúfar‚Äù case ($\\mathbf{H_1}$), where $D(\\rho, \\Phi) \\geq \\varepsilon_2$ forces a lower bound $\\delta \\geq \\varepsilon_2^2/2$ on the mismatch rate from the following inequality chain: $$ \\sqrt{2\\delta} \\,\\geq\\, D(\\rho, \\Phi) \\,\\geq\\, \\varepsilon_2 \\quad\\implies\\quad \\delta \\,\\geq\\, \\tfrac{\\varepsilon_2^2}{2}. $$For the ‚Äúclose‚Äù case ($H_0$), we cannot run this implication backwards: $D(\\rho, \\Phi) \\leq \\sqrt{2\\delta}$ does not give an upper bound on $\\delta$ in terms of $D(\\rho, \\Phi)$. Instead, we use a standard variational/POVM bound: for any projector $\\Pi$, $$ \\bigl| \\text{tr}(\\Pi\\rho) - \\text{tr}(\\Pi\\Phi) \\bigr| = \\bigl| \\text{tr}[\\Pi(\\rho - \\Phi)] \\bigr| \\,\\leq\\, D(\\rho, \\Phi). $$ Choosing $\\Pi$ as the mismatch projector for matching-basis rounds: $$ \\Pi_{\\text{mis}}^{Z} = \\ket{01}\\bra{01} + \\ket{10}\\bra{10},\\qquad \\Pi_{\\text{mis}}^{X} = \\ket{+-}\\bra{+-} + \\ket{-+}\\bra{-+}, $$ the overall mismatch rate is $\\delta = \\tfrac{1}{2}\\bigl(\\text{tr}[\\Pi_{\\text{mis}}^{Z}\\rho] + \\text{tr}[\\Pi_{\\text{mis}}^{X}\\rho]\\bigr)$, which occurs with probability zero for the ideal EPR state: $$ \\text{tr}[\\Pi_{\\text{mis}}^{Z}\\Phi] = \\text{tr}[\\Pi_{\\text{mis}}^{X}\\Phi] = 0. $$ Since each $\\Pi_{\\text{mis}}^{B}$ ($B \\in \\{Z, X\\}$) is a positive projector and $\\text{tr}[\\Pi_{\\text{mis}}^{B}\\rho] \\geq 0$, we have $$ \\bigl| \\text{tr}[\\Pi_{\\text{mis}}^{B}(\\rho - \\Phi)] \\bigr| = \\bigl| \\text{tr}[\\Pi_{\\text{mis}}^{B}\\rho] - 0 \\bigr| = \\text{tr}[\\Pi_{\\text{mis}}^{B}\\rho]. $$Apply the variational bound $\\bigl|\\text{tr}[\\Pi(\\rho - \\sigma)]\\bigr| \\leq D(\\rho, \\sigma)$ with $\\Pi = \\Pi_{\\text{mis}}^{B}$ and $\\sigma = \\Phi$: $$ \\text{tr}[\\Pi_{\\text{mis}}^{B}\\rho] \\leq D(\\rho, \\Phi). $$Thus $$ \\delta_Z = \\text{tr}[\\Pi_{\\text{mis}}^{Z}\\rho] \\leq D(\\rho, \\Phi),\\qquad \\delta_X = \\text{tr}[\\Pi_{\\text{mis}}^{X}\\rho] \\leq D(\\rho, \\Phi). $$Averaging gives $$ \\delta = \\tfrac{1}{2}(\\delta_Z + \\delta_X) \\leq D(\\rho, \\Phi), $$ so we have the bound $\\delta \\leq D(\\rho, \\Phi)$. Therefore, under $\\mathbf{H_0}$ with $D(\\rho, \\Phi) \\leq \\varepsilon_1$, the mismatch rate satisfies $\\delta \\leq \\varepsilon_1$.\nLet‚Äôs make this intuition precise.\nFirst, starting from the matching-outcomes protocol, we establish a Bernoulli trial model. Consider $S \\subseteq \\{1, \\dots, N\\}$, the set of matching‚Äêbasis rounds. For each $i \\in S$, define the indicator $$ Y_i := \\begin{cases} 1 \u0026\\text{if } x_i \\neq \\tilde x_i\\\\ 0 \u0026\\text{if } x_i = \\tilde x_i \\end{cases} $$ so each $Y_i \\in \\{0, 1\\}$. Under the i.i.d. assumption, $\\{ Y_i \\}_{i \\in S}$ is a set of independent Bernoulli random variables each with parameter $\\delta = \\Pr[x_i \\neq \\tilde{x}_i ~|~ \\theta_i = \\tilde{\\theta}_i]$, the true error rate (mismatch probability) conditioned on matching bases:\n$$ Y_i \\sim \\text{Bernoulli}(\\delta) \\quad\\forall i \\in S. $$The empirical error rate is the observable: $$ \\hat{\\delta} = \\frac{1}{|S|}\\sum_{i \\in S} Y_i. $$ This is the sample mean of $|S|$ independent bounded variables in $[0, 1]$.\nThe Chernoff-Hoeffding concentration bound (for Bernoulli RVs) tells us that if we average $|S|$ independent $\\{ 0, 1 \\}$ variables whose true mean is $\\delta$, then the chance our empirical average $\\hat{\\delta}$ deviates from $\\delta$ by more than some amount $t \u003e 0$ (the bad event) is tiny: $$ \\Pr\\left(|\\hat{\\delta} - \\delta| \\geq t\\right) \\leq 2e^{-2|S|t^2}. $$ The bigger $|S|$ is, the smaller this probability becomes. The larger we demand $t$ (a looser estimate), the fewer samples we need. To make this failure probability to be at most $\\alpha$, it suffices that (by rearranging) $$ |S| = \\frac{1}{2t^2}\\,\\ln\\!\\left(\\frac{2}{\\alpha}\\right) $$ which will be useful soon.\nAs we‚Äôve discussed, in a tolerant test, instead of a single decision point $\\varepsilon$, we have to fix two trace-distance tolerances $$ 0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1, $$ where\n$\\varepsilon_1$ is the acceptance tolerance for $\\mathbf{H_0}$; $D(\\rho, \\Phi) \\leq \\varepsilon_1$ implies ‚Äúclose‚Äù, and $\\varepsilon_2$ is the rejection tolerance for $\\mathbf{H_1}$; $D(\\rho, \\Phi) \\geq \\varepsilon_2$ implies ‚Äúfar‚Äù. We translate these trace distance parameters into error rate thresholds by $$ \\delta_{\\text{close}} := \\varepsilon_1, \\qquad \\delta_{\\text{far}} := \\frac{\\varepsilon_2^2}{2}. $$For the promise gap to be non-trivial, we need $\\delta_{\\text{far}} \u003e \\delta_{\\text{close}}$, which translates to $$ \\varepsilon_1 \u003c \\frac{\\varepsilon_2^2}{2}. $$ This imposes an extra constraint beyond the generic condition $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$.\nNow let‚Äôs look at a natural proposal for the decision rule‚Ä¶\nDecision rule (flawed). After measuring and computing the empirical error rate $\\hat{\\delta}$:\nIf $\\hat{\\delta} \\leq \\delta_{\\text{close}}$, declare ‚Äúclose‚Äù (accept). If $\\hat{\\delta} \\geq \\delta_{\\text{far}}$, declare ‚Äúfar‚Äù (reject). If $\\delta_{\\text{close}} \u003c \\hat{\\delta} \u003c \\delta_{\\text{far}}$, declare the result inconclusive. It looks promising and intuitive. But is this viable? Unfortunately, no. The reason this rule is flawed is the same reason a single hard cutoff $\\delta_*$ is flawed! So this rule fails to provide a high-confidence guarantee for the very states it‚Äôs supposed to certify.\nConsider a state whose true error rate is exactly on the boundary, $\\delta = \\delta_{\\text{close}}$. The measured value $\\hat{\\delta}$ is a random variable centred on this true value. Due to statistical noise, there is roughly a $50\\%$ chance that the measurement will yield $\\hat{\\delta} \u003e \\delta_{\\text{close}}$. According to this rule, we would declare the result ‚Äúinconclusive‚Äù i.e. fail to accept about half the time! An error rate of $\\sim\\!50\\%$ is unacceptably high and provides no meaningful confidence. If $\\delta = \\delta_{\\text{far}}$ exactly, then again we suffer from the same problem.\nTo fix this, we need to relax the decision boundary: instead of testing directly at the promise thresholds $\\delta_{\\text{close}}$ and $\\delta_{\\text{far}}$, we introduce a ‚Äúbuffer zone‚Äù to absorb statistical fluctuations.\nTo implement this we introduce a margin $t \u003e 0$, which:\nwidens our decision zone so random fluctuations don‚Äôt flip us at the boundary, and serves as the deviation parameter in our Chernoff‚ÄìHoeffding bound, which tells us that with very high probability we have $|\\hat{\\delta} - \\delta| \u003c t$, meaning the measured value $\\hat{\\delta}$ won‚Äôt fluctuate upwards or downwards by more than $t$. By choosing our single cutoff $$ c = \\delta_{\\text{close}} + t, $$ we build in exactly enough ‚Äúslack‚Äù so that even if the true rate sits at the lower promise boundary, $\\delta = \\delta_{\\text{close}}$, then by the Chernoff-Hoeffding bound $$ \\Pr\\bigl[\\hat{\\delta} \\geq c\\bigr] ~\\leq~\\Pr\\bigl[\\hat{\\delta} - \\delta \\geq t\\bigr] ~\\leq~2e^{-2|S|t^2}\\,, $$ i.e. the completeness error is only the exponentially small Chernoff tail and not the horrible $50\\%$ we were getting. By the same choice $c = \\delta_{\\text{far}} - t$ on the upper side, we get a symmetric buffer $(c, \\delta_{\\text{far}})$ that makes the soundness error equally tiny.\nSo‚Ä¶ the correct, albeit counter-intuitive, solution is to use a single decision cutoff $c$ placed strategically inside the promise gap $(\\delta_{\\text{close}}, \\delta_{\\text{far}})$. We‚Äôve gone full circle!\nA very natural way to pick the margin $t \u003e 0$ is to split the gap between $\\delta_{\\text{close}}$ and $\\delta_{\\text{far}}$ in half:\n$$ t = \\frac{\\delta_{\\text{far}} - \\delta_{\\text{close}}}{2} = \\frac{\\varepsilon_2^2}{4} - \\frac{\\varepsilon_1}{2} = \\frac{\\varepsilon_2^2 - 2\\varepsilon_1}{4}. $$ As $\\delta_{\\text{far}} \u003e \\delta_{\\text{close}}$ under our restriction $\\varepsilon_1 \u003c \\varepsilon_2^2/2$, the requirement $t \u003e 0$ is satisfied. Then $$ c = \\frac{\\delta_{\\text{close}} + \\delta_{\\text{far}}}{2} = \\frac{\\varepsilon_1}{2} + \\frac{\\varepsilon_2^2}{4} = \\frac{2\\varepsilon_1 + \\varepsilon_2^2}{4} = \\delta_{\\text{close}} + t = \\delta_{\\text{far}} - t $$ would conveniently place our decision boundary exactly in the middle for perfect symmetry.\nDecision rule. After measuring and computing $\\hat{\\delta}$,\nIf $\\hat{\\delta} \\leq c$, accept $\\mathbf{H_0}$ (‚Äúclose‚Äù). If $\\hat{\\delta} \u003e c$, accept $\\mathbf{H_1}$ (‚Äúfar‚Äù). $$ \\text{Decision} = \\begin{cases} \\text{‚Äúclose‚Äù}, \u0026 \\hat{\\delta} \\leq c,\\\\ \\text{‚Äúfar‚Äù}, \u0026 \\hat{\\delta} \u003e c. \\end{cases} $$ Let‚Äôs quickly prove correctness under the good event $$ \\mathcal{G} = \\left\\{\\, |\\hat{\\delta} - \\delta| \u003c t \\,\\right\\}. $$ Correctness includes completeness ($\\mathbf{H_0}$: ‚Äúclose‚Äù $\\Rightarrow$ ‚Äúaccept‚Äù) and soundness ($\\mathbf{H_1}$: ‚Äúfar‚Äù $\\Rightarrow$ ‚Äúreject‚Äù).\nCompleteness (‚Äúclose‚Äù case).\nIf the true $\\delta \\leq \\delta_{\\text{close}} = c - t$, then conditioned on $\\mathcal{G}$ we have $$ -t \u003c \\hat{\\delta} - \\delta \u003c t. $$ Using the right inequality ($\\hat{\\delta} - \\delta \u003c t$), $$ \\hat{\\delta} \u003c \\delta + t ~\\leq~ (c - t) + t ~=~ c, $$ hence $\\hat{\\delta} \\leq c$ and we accept ‚Äúclose‚Äù.\nSoundness (‚Äúfar‚Äù case).\nIf the true $\\delta \\geq \\delta_{\\text{far}} = c + t$, then conditioned on $\\mathcal{G}$ the left inequality ($-t \u003c \\hat{\\delta} - \\delta$) gives $$ \\hat{\\delta} \u003e \\delta - t ~\\geq~ (c + t) - t ~=~ c, $$ hence $\\hat{\\delta} \u003e c$ and we reject (‚Äúfar‚Äù).\nBoth completeness ($\\delta \\leq \\delta_{\\text{close}}$) and soundness ($\\delta \\geq \\delta_{\\text{far}}$) can fail only if $|\\hat{\\delta} - \\delta| \\geq t$ (the bad event), which the concentration bound guarantees occurs with probability at most $\\alpha/2$. All that remains is to choose the sample size $|S|$ (and $N$) so that $\\Pr[\\mathcal{G}] \\geq 1 - \\alpha/2$.\nFix a target failure probability $\\alpha \\in (0,1)$. Substituting $t = \\frac{\\varepsilon_2^2 - 2\\varepsilon_1}{4}$ into the $|S|$ equation from earlier and allocating $\\alpha/2$ to the estimation tail gives $$ \\begin{aligned} |S| ~\u0026=~ \\frac{1}{2t^2}\\,\\ln\\!\\left(\\frac{4}{\\alpha}\\right) ~=~ \\frac{1}{2\\bigl( \\,(\\varepsilon_2^2 - 2\\varepsilon_1)/4\\, \\bigr)^2}\\,\\ln\\!\\left(\\frac{4}{\\alpha}\\right) \\\\\\\\~\u0026=~ \\frac{8\\,\\ln(4/\\alpha)}{(\\varepsilon_2^2 - 2\\varepsilon_1)^2} ~=~ O\\!\\left(\\frac{1}{(\\varepsilon_2^2 - 2\\varepsilon_1)^2}\\right). \\end{aligned} $$Therefore, if we manage to collect $|S| = O\\Bigl((\\varepsilon_2^2 - 2\\varepsilon_1)^{-2}\\Bigr)$ matching‚Äêbasis samples satisfying the display above, then with probability $\\geq 1 - \\alpha/2$ we have $|\\hat{\\delta} - \\delta| \u003c t$ (the good event $\\mathcal{G}$), which guarantees both completeness and soundness as shown above.\nFinally, we need to determine a bound on $N$, the actual number of rounds we‚Äôll run the protocol for. Our overall success requires guarding against two distinct types of errors: estimation failure ($E_{\\text{estimation}}$), for which we now have $\\Pr(E_{\\text{estimation}}) \\leq \\alpha/2$, and sampling failure ($E_{\\text{sample}}$), where we fail to collect enough data in the first place. The total failure probability is bounded by their sum ($\\alpha$) using the union bound.\nSince the probability of the measurement bases matching in any given round is $1/2$, as it occurs uniformly at random, the expected number of matching-basis samples is $\\mathbb{E}[|S|] = N/2$. To safeguard against statistical fluctuations, we should choose $N$ to be larger than the simple estimate of $2|S|$. A robust and standard choice is $N = 4|S|$. With this choice, the probability of obtaining fewer than $|S|$ matching-basis samples - the event $E_{\\text{sample}}$ - can be shown via a standard Chernoff bound to be less than $e^{-|S|/4}$. Let the random variable for the number of matching-basis rounds from a total of $N$ trials be $X$. Then $$ X \\sim \\text{Binomial}\\!\\left(N, \\tfrac{1}{2}\\right). $$ As we have chosen $N = 4|S|$, note that $$ \\mathbb{E}[X] = \\frac{N}{2} = 2|S|. $$ The multiplicative Chernoff bound gives, for any $0 \u003c \\delta \u003c 1$, $$ \\Pr\\bigl[X \u003c (1-\\delta)\\,\\mathbb{E}[X]\\bigr] ~\\leq~\\exp\\Bigl(-\\tfrac{\\delta^2}{2}\\,\\mathbb{E}[X]\\Bigr). $$Setting $\\delta = \\tfrac{1}{2}$ so that $(1 - \\delta)\\,\\mathbb{E}[X]=|S|$ yields $$ \\Pr\\bigl[X \u003c |S|\\bigr] ~\\leq~ \\exp\\Bigl(-\\tfrac{(1/2)^2}{2}\\cdot 2|S|\\Bigr) ~=~ e^{-|S|/4}. $$To make both failure modes at most $\\alpha/2$, we require $$ |S| \\,\\geq\\, \\frac{8\\,\\ln(4/\\alpha)}{(\\varepsilon_2^2 - 2\\varepsilon_1)^2} \\qquad\\text{and}\\qquad |S| \\,\\geq\\, 4\\,\\ln\\!\\frac{2}{\\alpha}. $$ Equivalently, with $N=4|S|$, $$ N \\ \\geq\\ \\max\\!\\left\\{\\,\\frac{32\\,\\ln(4/\\alpha)}{(\\varepsilon_2^2 - 2\\varepsilon_1)^2}\\,,\\ \\ 16\\,\\ln\\!\\frac{2}{\\alpha}\\right\\}. $$For admissible parameters ($0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$ with $\\varepsilon_1 \u003c \\varepsilon_2^2/2$), we have $0 \u003c \\varepsilon_2^2 - 2\\varepsilon_1 \\leq 1$, hence $(\\varepsilon_2^2 - 2\\varepsilon_1)^{-2} \\geq 1$. Therefore $$ \\frac{32\\,\\ln(4/\\alpha)}{(\\varepsilon_2^2 - 2\\varepsilon_1)^2} \\geq 32\\,\\ln\\!\\frac{4}{\\alpha} \u003e 16\\,\\ln\\!\\frac{2}{\\alpha} $$ because $32\\ln(4/\\alpha) - 16\\ln(2/\\alpha) = 16\\bigl(2\\ln(4/\\alpha) - \\ln(2/\\alpha)\\bigr) = 16\\ln(8/\\alpha) \u003e 0$ for all $\\alpha \\in (0,1)$. Hence the first term dominates for all admissible values, and the bound simplifies to $$ N \\geq \\frac{32 \\ln(4/\\alpha)}{(\\varepsilon_2^2 - 2\\varepsilon_1)^2}. $$With this, we can now use the union bound to find the total probability of failure: $$ \\Pr(\\text{Total Failure}) = \\Pr(E_{\\text{sample}}) + \\Pr(E_{\\text{estimation}}) \\leq \\frac{\\alpha}{2} + \\frac{\\alpha}{2} = \\alpha. $$Therefore, the choice of $N = 4|S|$ together with the displayed $|S|$ bound is sufficient. The total number of rounds/i.i.d. copies required for the test protocol is: $$ N = 4|S| = \\frac{32 \\ln(4/\\alpha)}{(\\varepsilon_2^2 - 2\\varepsilon_1)^2} = O\\Bigl((\\varepsilon_2^2 - 2\\varepsilon_1)^{-2}\\Bigr). $$Putting everything together, we arrive at our main result. All the hard work we‚Äôve done in this finite-sample analysis provides a complete description for the number of rounds $N$ needed to achieve a desired confidence level $1 - \\alpha$. The key takeaway is that the required sample complexity scales as $N = O\\bigl((\\varepsilon_2^2 - 2\\varepsilon_1)^{-2}\\bigr)$, so the closer the gap between $\\varepsilon_1$ and $\\varepsilon_2$, the number of samples needed grows extremely rapidly. The formal statement is as follows:\nTheorem (Finite-Sample Tolerant EPR Identity Test).\nGiven $N$ i.i.d. copies of $\\rho_{AB}$, fix two trace-distance tolerances $$ 0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1, $$ where the constraint $\\varepsilon_1 \u003c \\varepsilon_2^2/2$ holds. Fix the desired maximum failure probability $\\alpha \\in (0, 1)$. Set the cutoff $$ c = \\frac{2\\varepsilon_1 + \\varepsilon_2^2}{4}. $$ Consider the matching-outcomes protocol executed for a total of $N$ rounds, consuming $N$ i.i.d. copies in total. Let the decision rule be to accept if and only if the observed error rate, $\\hat{\\delta}$, is less than or equal to the cutoff, $c$: $$ \\text{Decision} = \\begin{cases} \\text{‚Äúclose‚Äù}, \u0026 \\hat{\\delta} \\leq c,\\\\ \\text{‚Äúfar‚Äù}, \u0026 \\hat{\\delta} \u003e c. \\end{cases} $$ Then if $$ N \\geq \\frac{32\\,\\ln(4/\\alpha)}{(\\varepsilon_2^2 - 2\\varepsilon_1)^2} \\qquad\\left( = O\\Bigl((\\varepsilon_2^2 - 2\\varepsilon_1)^{-2}\\Bigr) \\right), $$ the test provides the following guarantees:\nIf $D(\\rho_{AB}, \\ket{\\text{EPR}} \\bra{\\text{EPR}}_{AB}) \\leq \\varepsilon_1$, then the test accepts (outputs ‚Äúclose‚Äù) with confidence at least $1 - \\alpha$. If $D(\\rho_{AB}, \\ket{\\text{EPR}} \\bra{\\text{EPR}}_{AB}) \\geq \\varepsilon_2$, then the test rejects (outputs ‚Äúfar‚Äù) with confidence at least $1 - \\alpha$. If $\\varepsilon_1 \u003c D(\\rho_{AB}, \\ket{\\text{EPR}} \\bra{\\text{EPR}}_{AB}) \u003c \\varepsilon_2$, no guarantee is made on the outcome; the test may go either way (accept or reject). We can quickly give a corollary for the exact, non-tolerant identity test as well. Recall that we write $\\rho = \\rho_{AB}$ and $\\Phi = \\ket{\\text{EPR}}\\bra{\\text{EPR}}_{AB}$.\nCorollary (Non-tolerant identity test for the EPR state).\nFix $\\varepsilon \\in (0,1]$ and failure probability $\\alpha \\in (0,1)$. Consider the hypotheses $$ \\begin{cases} ~\\mathbf{H_0}:~ \u0026 \\rho = \\Phi \\quad\\text{(exact identity)},\\\\[4pt] ~\\mathbf{H_1}:~ \u0026 D(\\rho,\\Phi) \\,\\geq\\, \\varepsilon \\quad\\text{($\\varepsilon$-far)}. \\end{cases} $$ Run the matching-outcomes protocol for a total of $N$ rounds, with $$ N ~\\geq~ \\frac{4}{\\varepsilon^2}\\,\\ln\\!\\frac{1}{\\alpha}. $$ Decision: accept $\\mathbf{H_0}$ iff no mismatches are observed on the matching-basis rounds (i.e. $\\hat{\\delta} = 0$).\nGuarantee. Completeness holds with probability $1$ and soundness holds with probability at least $1 - \\alpha$:\nIf $\\rho = \\Phi$, then $\\delta = 0$ and hence $\\hat{\\delta} = 0$ almost surely, so the test accepts. If $D(\\rho,\\Phi) \\geq \\varepsilon$, then by the asymptotic identity bound $D \\leq \\sqrt{2\\delta}$ we have $\\delta \\geq \\varepsilon^2/2$. For each round $i \\in [N]$, the probability of no counted mismatch is $$ 1 - \\left[\\Pr(x_i \\neq \\tilde{x}_i \\mid \\theta_i = \\tilde{\\theta}_i) \\cdot \\Pr(\\theta_i = \\tilde{\\theta}_i)\\right] = 1 - \\delta \\cdot \\tfrac{1}{2} $$ (either bases don‚Äôt match, or they match and outcomes agree), so over $N$ rounds $$ \\Pr[\\hat{\\delta}=0] ~=~ (1 - \\delta/2)^{N} ~\\leq~ \\bigl(1 - \\tfrac{\\varepsilon^2}{4}\\bigr)^{N} ~\\leq~ e^{-N\\,\\frac{\\varepsilon^2}{4}} ~\\leq~ \\alpha, $$ so the test rejects with probability at least $1 - \\alpha$. Total rounds. This gives a direct $N$-bound; no separate sampling condition on the number of matching-basis rounds is required, since unmatched rounds are already absorbed into the per-round factor $(1 - \\delta/2)$.\n","wordCount":"4489","inLanguage":"en","datePublished":"2025-08-03T23:35:49+01:00","dateModified":"2025-08-03T23:35:49+01:00","author":{"@type":"Person","name":"Howard Cheung"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://teaegg.net/research/urss/epr-tolerant-identity-testing/"},"publisher":{"@type":"Organization","name":"ùóßùóòùóî‚Ä¢ùóòùóöùóö","logo":{"@type":"ImageObject","url":"https://teaegg.net/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://teaegg.net/ title=Home>ùóßùóòùóî‚Ä¢ùóòùóöùóö</a><div class=logo-switches><button id=theme-toggle title="Toggle theme" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://teaegg.net/aboutme/ title="About Me"><span>About Me</span></a></li><li><a href=https://teaegg.net/journal/ title=Journal><span>Journal</span></a></li><li><a href=https://teaegg.net/research/ title=Research><span>Research</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://teaegg.net/>üè† Home</a>&nbsp;¬ª&nbsp;<a href=https://teaegg.net/research/>üî¨ Research</a>&nbsp;¬ª&nbsp;<a href=https://teaegg.net/research/urss/>üîêüí° Undergraduate Research Support Scheme (URSS)</a></div><h1 class="post-title entry-hint-parent">Classical tolerant identity test for the EPR state</h1><div class=post-meta><span title='2025-08-03 23:35:49 +0100 +0100'>August 3, 2025</span>&nbsp;¬∑&nbsp;22 min&nbsp;¬∑&nbsp;Howard Cheung</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#single-pair-matchingoutcomes-protocol aria-label="Single-pair matching‚Äëoutcomes protocol">Single-pair matching‚Äëoutcomes protocol</a></li><li><a href=#asymptotic-bound aria-label="Asymptotic bound">Asymptotic bound</a></li><li><a href=#finite-sample-analysis aria-label="Finite-sample analysis">Finite-sample analysis</a></li></ul></div></details></div><div class=post-content><p><strong>Goal.</strong>¬†Given $N$ i.i.d. copies of an unknown bipartite state $\rho_{AB}$ held by Alice and Bob, certify that $\rho_{AB}$ held by Alice and Bob is within trace‚Äëdistance $\varepsilon$ of</p>$$
\ket{\text{EPR}}_{AB} = \frac{1}{\sqrt2}\left(\ket{00}_{AB} + \ket{11}_{AB}\right),
$$<p>using only <em>sequential*</em> (one qubit at a time), local measurements in the <strong>standard</strong> ($\{ \ket{0}, \ket{1} \}$) or <strong>Hadamard</strong> ($\{ \ket{+}, \ket{-} \}$) bases, and classical communication. Importantly, we never perform any joint or Bell‚Äêbasis measurement on $AB$.</p><hr><h2 id=single-pair-matchingoutcomes-protocol>Single-pair matching‚Äëoutcomes protocol<a hidden class=anchor aria-hidden=true href=#single-pair-matchingoutcomes-protocol>#</a></h2><p>Suppose Alice and Bob share $N$ i.i.d. copies of an unknown state $\rho_{AB}$. For each pair $i = 1, \dots, N$, they do the following <em>in sequence*</em>:</p><ol><li><p><strong>Basis choice:</strong></p><ul><li>Alice picks $\theta_i \in \{ 0, 1 \}$ uniformly at random.</li><li>Bob picks $\tilde{\theta}_i \in \{ 0, 1 \}$ uniformly at random.</li></ul><p>Here $\theta_i = 0$ means &ldquo;standard basis&rdquo; and $\theta_i = 1$ means &ldquo;Hadamard basis&rdquo;.</p></li><li><p><strong>Local measurement:</strong></p><ul><li>Alice measures her qubit in basis $\theta_i$ to get outcome $x_i \in \{ 0, 1 \}$.</li><li>Bob measures his qubit in basis $\tilde\theta_i$, obtaining $\tilde x_i \in \{ 0, 1 \}$.</li></ul></li></ol><blockquote><p><strong>Note.</strong> Apart from the one-off preparation/distribution of the shared state $\rho_{AB}$, there is no need for any further quantum channel or quantum memory; Alice and Bob simply perform immediate local measurements. In addition, since each measurement round consumes one i.i.d. copy of $\rho_{AB}$, the parameter $N$ can be viewed interchangeably as either the number of <u>rounds</u> or the number of <u>copies</u>, and I will use it in both senses throughout our single-pair analysis.</p></blockquote><p>After all $N$ measurement rounds (one round for each i.i.d. copy of $\rho_{AB}$), Alice and Bob publicly reveal their basis strings $\theta = (\theta_1, \dots, \theta_N)$ and $\tilde{\theta} = (\tilde{\theta}_1, \dots, \tilde{\theta}_N)$, and their outcome strings $x = (x_1, \dots, x_N)$, $\tilde{x} = (\tilde{x}_1, \dots, \tilde{x}_N)$ over a classical authenticated channel (CAC).</p><p>Define the matching-basis index set</p>$$
S = \{i : \theta_i = \tilde\theta_i\}.
$$<p>On each $i\in S$, Alice and Bob measured in the <em>same</em> basis. If by rare chance $S = \varnothing$ (no matching bases at all), simply rerun the whole protocol as the probability of $S = \varnothing$ is $2^{-N}$, which is negligible for modest $N$.</p><p>Compute the <strong>observed error rate</strong></p>$$
\hat{\delta} = \frac{1}{|S|}\,\left|\{\,i\in S : x_i \neq \tilde x_i\}\right|.
$$<p>which represents the mismatch fraction conditioned on matching-basis rounds.</p><blockquote><p><strong>Remark.</strong> The sequential ordering is purely a hardware convenience and <em>not</em> a theoretical requirement: it guarantees that no quantum memory or parallel measurement modules are ever needed. If you already have $N$ measurement setups and don&rsquo;t mind operating them in parallel, you may instead prepare all bases at once, measure in parallel, and only then exchange classical data. Both versions give the same statistical bound.</p></blockquote><hr><h2 id=asymptotic-bound>Asymptotic bound<a hidden class=anchor aria-hidden=true href=#asymptotic-bound>#</a></h2><p><strong>Motivating question.</strong>
Can we really conclude that, if the <em>classical</em> matching-outcomes test in the protocol above succeeds with high probability (i.e. a small observed error $\hat{\delta}$), then the <em>quantum</em> state $\rho_{AB}$ must be close to an ideal EPR pair, <em>without ever</em> performing a joint or Bell-basis measurement?</p><p>In other words, when given $\rho_{AB}^{\otimes N}$, what is the smallest number $N$ of i.i.d. copies required to certify that $\rho_{AB}$ lies within trace distance $\varepsilon$ of the ideal EPR state?</p><p>We&rsquo;ll first analyse the idealised, infinite-round/copy limit $N \to \infty$ to see theoretically why a high success rate forces high fidelity to $\ket{\text{EPR}}_{AB}$. After that, we&rsquo;ll return to the realistic, finite-sample setting to turn this into a practical protocol in the next section.</p><blockquote><p><strong>Remark.</strong> For very large $N$, the observed matching and mismatch rates concentrate so tightly around the true error parameter $\delta$ (by the law of large numbers) that we can replace all finite‚Äêsample quantities ($\hat{\delta}$) with $\delta$ itself when deriving the asymptotic bound, making our theoretical analysis easier.</p></blockquote><p>Recall that:</p><ul><li>The <em>fidelity</em> between a state $\rho$ and a pure state $\ket{\psi}$ is defined as
$$
F\left(\rho, \ket{\psi}\right) := \sqrt{\bra{\psi}\,\rho\,\ket{\psi}}.
$$</li><li>The <em>trace distance</em> between two states $\rho$ and $\sigma$ is defined as
$$
D(\rho,\sigma) := \frac{1}{2}\|\rho - \sigma\|_1.
$$</li></ul><p><strong>Lemma.</strong> Let $\rho_{AB}$ be a bipartite state where $A$ and $B$ are each systems of a single qubit. The probability of Alice and Bob getting matching outcomes (<code>00</code> or <code>11</code>) when they both measure in the standard basis ($Z$) is given by $\text{tr}(\Pi_1\,\rho_{AB})$, where</p>$$
\ket{\text{EPR}} = \ket{\Psi_{00}} = \frac{1}{\sqrt{2}}(\ket{00} + \ket{11}), \qquad \ket{\Psi_{01}} = \frac{1}{\sqrt{2}}(\ket{00} - \ket{11}),
$$<p>and</p>$$
\Pi_1 = \ket{\text{EPR}} \bra{\text{EPR}} + \ket{\Psi_{01}} \bra{\Psi_{01}}.
$$<p>Similarly, the probability of Alice and Bob getting matching outcomes (<code>++</code> or <code>--</code>) when they both measure in the Hadamard basis ($X$) is given by $\text{tr}(\Pi_2\,\rho_{AB})$, with</p>$$
\ket{\Psi_{10}} = \frac{1}{\sqrt{2}}(\ket{01} + \ket{10}),
$$<p>and</p>$$
\Pi_2 = \ket{\text{EPR}} \bra{\text{EPR}} + \ket{\Psi_{10}} \bra{\Psi_{10}}.
$$<p><strong>Proof.</strong>
The probability of matching outcomes,</p>$$
\begin{aligned}
\Pr(\text{match}_{Z}) &= \Pr(00) + \Pr(11)
\\&= \text{tr}(M_{00} + M_{11}) &\text{by Born rule}
\\&= \text{tr}(\ket{00}\bra{00}\,\rho_{AB}) + \text{tr}(\ket{11}\bra{11}\,\rho_{AB}) &\text{by def. of POVM operator}
\\&= \text{tr}(\bra{00}\,\rho_{AB}\,\ket{00}) + \text{tr}(\bra{11}\,\rho_{AB}\,\ket{11}) &\text{by cyclicity of trace}
\\&= \bra{00}\,\rho_{AB}\,\ket{00} + \bra{11}\,\rho_{AB}\,\ket{11} &\text{as trace of scalar = itself.}
\end{aligned}
$$<p>Expanding $\Pi_1$ we get</p>$$
\begin{aligned}
\Pi_1 &= \ket{\text{EPR}} \bra{\text{EPR}} + \ket{\Psi_{01}} \bra{\Psi_{01}}
\\&=\tfrac{1}{2}(\ket{00}\bra{00} + \ket{00}\bra{11} + \ket{11}\bra{00} + \ket{11}\bra{11}
\\&\qquad+ \ket{00}\bra{00} - \ket{00}\bra{11} - \ket{11}\bra{00} + \ket{11}\bra{11})
\\&= \tfrac{1}{2}(2\ket{00}\bra{00} + 2\ket{11}\bra{11})
\\&= \ket{00}\bra{00} + \ket{11}\bra{11}.
\end{aligned}
$$<p>Then</p>$$
\begin{aligned}
\text{tr}(\Pi_1\,\rho_{AB}) &= \text{tr}(\,(\ket{00}\bra{00} + \ket{11}\bra{11})\,\rho_{AB}) &\text{by def. of }\Pi_1
\\&= \text{tr}(\ket{00}\bra{00}\,\rho_{AB}) + \text{tr}(\ket{11}\bra{11}\,\rho_{AB}) &\text{by linearity of trace}
\\&= \text{tr}(\bra{00}\,\rho_{AB}\,\ket{00}) + \text{tr}(\bra{11}\,\rho_{AB}\,\ket{11}) &\text{by cyclicity of trace}
\\&= \bra{00}\,\rho_{AB}\,\ket{00} + \bra{11}\,\rho_{AB}\,\ket{11} &\text{as trace of scalar = itself.}
\end{aligned}
$$<p>Hence $\Pr(\text{match}_Z) = \text{tr}(\Pi_1\,\rho_{AB})$ as required.</p><p>Similarly, for the measurement of systems $A$ and $B$ is performed in the Hadamard basis, we can first perform a change in basis and simplify $\Pi_2$. Recall that</p>$$
\ket{0} = \frac1{\sqrt2}(\ket{+} + \ket{-}),\qquad
\ket{1} = \frac1{\sqrt2}(\ket{+} - \ket{-}).
$$<p>Then</p>$$
\begin{aligned}
\ket{\text{EPR}} &= \frac{1}{\sqrt2}(\ket{00} + \ket{11})
\\&= \frac{1}{\sqrt2}\left(
\frac{\ket{+} + \ket{-}}{\sqrt2} \otimes \frac{\ket{+} + \ket{-}}{\sqrt2} + \frac{\ket{+} - \ket{-}}{\sqrt2} \otimes \frac{\ket{+} - \ket{-}}{\sqrt2}
\right)
\\&= \frac{1}{\sqrt2}\bigl(\ket{++} + \ket{--}\bigr).
\end{aligned}
$$<p>Similarly one can easily verify</p>$$
\ket{\Psi_{10}}
= \frac{1}{\sqrt2}(\ket{01} + \ket{10})
= \frac{1}{\sqrt2}\bigl(\ket{++} - \ket{--}\bigr).
$$<p>Expanding $\Pi_2$ we get</p>$$
\begin{aligned}
\Pi_2 &= \tfrac{1}{2}(\ket{++}\bra{++} + \ket{++}\bra{--} + \ket{--}\bra{++} + \ket{--}\bra{--}
\\&\qquad+ \ket{++}\bra{++} - \ket{++}\bra{--} - \ket{--}\bra{++} + \ket{--}\bra{--})
\\&= \tfrac{1}{2}(2\ket{++}\bra{++} + 2\ket{--}\bra{--})
\\&= \ket{++}\bra{++} + \ket{--}\bra{--}.
\end{aligned}
$$<p>Finally, by exactly the same Born-rule steps as above (now applied in the Hadamard basis), we have:</p>$$
\Pr(\text{match}_X) = \text{tr}(\ket{++}\bra{++}\,\rho_{AB}) + \text{tr}(\ket{--}\bra{--}\,\rho_{AB}) = \text{tr}(\Pi_2\,\rho_{AB}),$$<p>so the proof is complete.</p><p>Now suppose that $\rho_{AB}$ is any state such that</p>$$
\underbrace{\frac{1}{2}\,\text{tr}\bigl(\Pi_1\,\rho_{AB}\bigr)}_{\substack{\text{matching outcomes}\\\text{in standard (Z) basis}}}
~+~
\underbrace{\frac{1}{2}\,\text{tr}\bigl(\Pi_2\,\rho_{AB}\bigr)}_{\substack{\text{matching outcomes}\\\text{in Hadamard (X) basis}}}
~=~
\underbrace{1 - \delta}_{\substack{\text{overall success}\\\text{probability}}} \qquad (*)
$$<p>for some $\delta \geq 0$.</p><p>Imagine we&rsquo;re measuring $\rho_{AB}$ in the Bell basis $\{ \ket{\Psi_{00}}, \ket{\Psi_{01}}, \ket{\Psi_{10}}, \ket{\Psi_{11}} \}$ (where $\ket{\text{EPR}} = \ket{\Psi_{00}}$). The measurement has four possible outcomes, corresponding to the four Bell states. Using Born rule and properties of trace, we can deduce the probability of getting each outcome:</p>$$
\begin{aligned}
&p_{00} = \bra{\Psi_{00}}\,\rho_{AB}\,\ket{\Psi_{00}}, &p_{01} = \bra{\Psi_{01}}\,\rho_{AB}\,\ket{\Psi_{01}},
\\&p_{10} = \bra{\Psi_{10}}\,\rho_{AB}\,\ket{\Psi_{10}}, &p_{11} = \bra{\Psi_{11}}\,\rho_{AB}\,\ket{\Psi_{11}}.
\end{aligned}
$$<p>Since these are all the possible outcomes,</p>$$
p_{00} + p_{01} + p_{10} + p_{11} = 1. \qquad \text{(Norm)}
$$<p>Also, expanding $\ket{\Psi_{00}}\bra{\Psi_{00}}$ and $\ket{\Psi_{01}}\bra{\Psi_{01}}$ gives</p>$$
\begin{aligned}
\ket{\Psi_{00}}\bra{\Psi_{00}}
&= \tfrac{1}{2}\bigl(\ket{00}+\ket{11}\bigr)\bigl(\bra{00}+\bra{11}\bigr)
\\&= \tfrac{1}{2}\bigl(\ket{00}\bra{00}+\ket{00}\bra{11}+\ket{11}\bra{00}+\ket{11}\bra{11}\bigr),
\\
\ket{\Psi_{01}}\bra{\Psi_{01}}
&= \tfrac{1}{2}\bigl(\ket{00}-\ket{11}\bigr)\bigl(\bra{00}-\bra{11}\bigr)
\\&= \tfrac{1}{2}\bigl(\ket{00}\bra{00}-\ket{00}\bra{11}-\ket{11}\bra{00}+\ket{11}\bra{11}\bigr).
\end{aligned}
$$<p>Adding them gives</p>$$
\begin{aligned}
\ket{\Psi_{00}}\bra{\Psi_{00}} + \ket{\Psi_{01}}\bra{\Psi_{01}}
&= \tfrac{1}{2}\bigl(2\ket{00}\bra{00} + 2\ket{11}\bra{11}\bigr)
\\
&= \ket{00}\bra{00} + \ket{11}\bra{11}
\\&= \Pi_1.
\end{aligned}
$$<p>Similarly, expanding $\ket{\Psi_{00}}\bra{\Psi_{00}}$ and $\ket{\Psi_{10}}\bra{\Psi_{10}}$ gives</p>$$
\begin{aligned}
\ket{\Psi_{00}}\bra{\Psi_{00}}
&= \tfrac{1}{2}\bigl(\ket{++}+\ket{--}\bigr)\bigl(\bra{++}+\bra{--}\bigr)
\\&=\tfrac{1}{2}\bigl(\ket{++}\bra{++} + \ket{++}\bra{--} + \ket{--}\bra{++} + \ket{--}\bra{--}\bigr),
\\\ket{\Psi_{10}}\bra{\Psi_{10}}
&= \tfrac{1}{2}\bigl(\ket{++}-\ket{--}\bigr)\bigl(\bra{++}-\bra{--}\bigr)\\
&=\tfrac{1}{2}\bigl(\ket{++}\bra{++} - \ket{++}\bra{--} - \ket{--}\bra{++} + \ket{--}\bra{--}\bigr).
\end{aligned}
$$<p>Adding these two lines gives</p>$$
\begin{aligned}
\ket{\Psi_{00}}\bra{\Psi_{00}} + \ket{\Psi_{10}}\bra{\Psi_{10}} &= \tfrac{1}{2}\bigl(2\ket{++}\bra{++} + 2\ket{--}\bra{--}\bigr)\\
&= \ket{++}\bra{++} + \ket{--}\bra{--}
\\&= \Pi_2.
\end{aligned}
$$<p>Using the definitions of $\Pi_1$ and $\Pi_2$ in terms of Bell states, Born rule, and properties of the trace, we can rewrite the average test success probability using these new terms.</p><p>For the standard basis part:</p>$$
\begin{aligned}
\text{tr}\bigl(\Pi_1\,\rho_{AB}\bigr) &= \bra{00}\,\rho_{AB}\,\ket{00} + \bra{11}\,\rho_{AB}\,\ket{11}
\\&= \bra{\Psi_{00}}\,\rho_{AB}\,\ket{\Psi_{00}} + \bra{\Psi_{01}}\,\rho_{AB}\,\ket{\Psi_{01}}
\\&= p_{00} + p_{01},
\end{aligned}
$$<p>and similarly for the Hadamard basis part:</p>$$
\begin{aligned}
\text{tr}\bigl(\Pi_2\,\rho_{AB}\bigr) &= \bra{++}\,\rho_{AB}\,\ket{++} + \bra{--}\,\rho_{AB}\,\ket{--}
\\&= \bra{\Psi_{00}}\,\rho_{AB}\,\ket{\Psi_{00}} + \bra{\Psi_{10}}\,\rho_{AB}\,\ket{\Psi_{10}}
\\&= p_{00} + p_{10}.
\end{aligned}
$$<p>Hence,</p>$$
\begin{aligned}
\tfrac{1}{2}\,\text{tr}\bigl(\Pi_1\,\rho_{AB}\bigr) + \tfrac{1}{2}\,\text{tr}\bigl(\Pi_2\,\rho_{AB}\bigr) &= 1 - \delta &\text{from $(*)$ above}
\\[6pt]\tfrac{1}{2}(p_{00} + p_{01}) + \tfrac{1}{2}(p_{00} + p_{10}) &= 1 - \delta
\\[6pt]p_{00} + \tfrac{1}{2}(p_{01} + p_{10}) &= 1 - \delta
\\[6pt]p_{00} + \tfrac{1}{2}(1 - p_{00} - p_{11}) &= 1 - \delta &\text{by (norm)}
\\[6pt]\tfrac{1}{2}p_{00} - \tfrac{1}{2}p_{11} &= \tfrac{1}{2} - \delta
\\[6pt]p_{00} - p_{11} &= 1 - 2\delta.
\end{aligned}
$$<p>We don&rsquo;t know the exact value for $p_{11}$, but since $p_{11}$ is a probability, $p_{11} \geq 0$. Hence we can remove it and get the inequality</p>$$
p_{00} \geq 1 - 2\delta.
$$<p>Therefore, the fidelity, as the number of rounds $N \to \infty$,</p>$$
\begin{aligned}
F &:= F(\rho_{AB}, \ket{\text{EPR}}\bra{\text{EPR}})\\
&= \sqrt{\bra{\text{EPR}}\,\rho_{AB}\,\ket{\text{EPR}}}\\
&= \sqrt{p_{00}}\\
&\geq \sqrt{1 - 2\delta}
\end{aligned}
$$<p>for some <em>true</em> error rate $\delta \in [0, 1]$ where $\delta = \Pr[x_i \neq \tilde{x}_i ~|~ \theta_i = \tilde{\theta}_i]$ is the mismatch probability.</p><p>From $(*)$, we&rsquo;ve derived that if the average success probability of the classical outcomes test above is high ($\geq 1 - \delta$), then the fidelity (a measure of overlap between two states) of the shared quantum state $\rho_{AB}$ with a perfect EPR pair between Alice and Bob must also be high ($\geq \sqrt{1 - 2\delta}$), provided $\delta$ is sufficiently small.</p><p>Rearranging $F^2\geq 1-2\delta$ gives</p>$$
1 - F^2 \leq 2\delta.
$$<p>The <em>Fuchs‚Äìvan‚ÄØde‚ÄØGraaf inequality</em> gives, for the trace distance $\varepsilon := D\left(\rho_{AB}, \ket{\text{EPR}}\bra{\text{EPR}}\right)$,</p>$$
\varepsilon \leq \sqrt{1 - F^2}.
$$<p>Combining the two inequalities give $\varepsilon \leq \sqrt{2\delta}$, and equivalently, $\delta \geq \frac{1}{2}\varepsilon^2$.</p><blockquote><p><strong>Theorem (Asymptotic EPR Identity Bound).</strong></p><p>In the asymptotic limit $N \to \infty$, let Alice and Bob share $N$ i.i.d. copies of an unknown state $\rho_{AB}$. Define the <em>true</em> matching-basis error rate $\delta = \Pr[x_i \neq \tilde{x}_i ~|~ \theta_i = \tilde{\theta}_i]$. Then, the trace distance $D(\rho_{AB}, \ket{\text{EPR}} \bra{\text{EPR}}_{AB}) = \varepsilon \in [0, 1]$ between $\rho_{AB}$ and the ideal EPR pair satisfies</p>$$
\varepsilon \leq \sqrt{2\delta},
\quad\iff\quad
\delta \geq \frac{\varepsilon^2}{2}.
$$</blockquote><hr><h2 id=finite-sample-analysis>Finite-sample analysis<a hidden class=anchor aria-hidden=true href=#finite-sample-analysis>#</a></h2><p>With the asymptotic bound in hand, our task becomes a practical one: from a finite sample we must decide &ldquo;close&rdquo; or &ldquo;far&rdquo; while keeping the probability of error below some small target, say $\alpha$.</p><p>Although</p>$$
\varepsilon \leq \sqrt{2\delta}
$$<p>holds exactly once we know the true mismatch rate $\delta$, in practice we only observe the empirical rate $\hat{\delta}$ from a finite number of rounds (as defined in the protocol); in the finite-sample setting we cannot hope to pinpoint the true $\delta$ exactly.</p><p>If we tried to draw a single &ldquo;hard&rdquo; cutoff line at</p>$$
\delta_* = \frac{\varepsilon^2}{2},
$$<p>then sadly we would suffer both false-accept and false-reject errors because the statistical fluctuations would cause the measured error rate $\hat{\delta}$ to frequently land on the wrong side of the cutoff line whenever the true value $\delta$ is too close to $\delta_*$.</p><p>In other words, with a finite number of samples, it is <strong>impossible</strong> to reliably distinguish between two scenarios that are infinitesimally close but on opposite sides of a sharp boundary. The statistical &ldquo;noise&rdquo; from finite sampling is larger than the tiny difference we are trying to measure. This means that an identity test that distinguishes states that are $\varepsilon$-close from those that are more than $\varepsilon$-far is not robust! The solution is to adopt a <em>tolerant</em> testing framework.</p><p>Instead of a single distance threshold $\varepsilon$, we define two: an acceptance tolerance $\varepsilon_1$ and a rejection tolerance $\varepsilon_2$, where $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$. Our goal is no longer to pinpoint a single boundary, but to reliably distinguish states that are &ldquo;close&rdquo; ($D(\rho_{AB}, \ket{\text{EPR}}) \leq \varepsilon_1$) from those that are &ldquo;far&rdquo; ($D(\rho_{AB}, \ket{\text{EPR}}) \geq \varepsilon_2$).</p><p>This framework creates a small &ldquo;promise gap&rdquo; around $\delta_*$. By translating our trace distance tolerances ($\varepsilon_1$ and $\varepsilon_2$) into error rate thresholds, $\delta_{\text{close}}$ and $\delta_{\text{far}}$, which are functions of $\varepsilon_1$ and $\varepsilon_2$ respectively, we establish a &ldquo;buffer zone&rdquo; that can absorb those statistical fluctuations.</p><p>By making this &ldquo;promise gap&rdquo; just large enough and then applying a <em>concentration bound</em> to $\hat{\delta}$, we can guarantee that, with probability at least $1 - \alpha$, the empirical error rate $\hat{\delta}$ stays on the correct side of its respective cutoff - so we will correctly declare &ldquo;close&rdquo; whenever $\hat{\delta} \leq \delta_{\text{close}}$ and &ldquo;far&rdquo; whenever $\hat{\delta} \geq \delta_{\text{far}}$, each with error at most $\alpha$.</p><p>For simplicity, write $\rho := \rho_{AB}$ and $\Phi := \ket{\text{EPR}}\bra{\text{EPR}}$. We need to define the hypotheses $\mathbf{H_0}$ ($\varepsilon_1$-close) and $\mathbf{H_1}$ ($\varepsilon_2$-far) for our test:</p>$$
\begin{cases}
~\mathbf{H_0}: &D(\rho, \Phi) \,\leq\,\varepsilon_1 \quad\iff\quad \rho \text{ is ‚Äúclose‚Äù to }\Phi,
\\ ~\mathbf{H_1}: &D(\rho, \Phi) \,\geq\,\varepsilon_2 \quad\iff\quad \rho \text{ is ‚Äúfar‚Äù from }\Phi,
\end{cases}
$$<p>Also, recall that the asymptotic inequality</p>$$
D(\rho, \Phi) \leq \sqrt{2\delta}
$$<p>was derived from the Fuchs‚Äìvan de Graaf bound and the matching-outcomes success rate. This is the <em>soundness direction</em>: it tells us that if the true mismatch rate $\delta$ is small, then the state is also close in trace distance. It applies directly to the &ldquo;far&rdquo; case ($\mathbf{H_1}$), where $D(\rho, \Phi) \geq \varepsilon_2$ forces a lower bound $\delta \geq \varepsilon_2^2/2$ on the mismatch rate from the following inequality chain:</p>$$
\sqrt{2\delta} \,\geq\, D(\rho, \Phi) \,\geq\, \varepsilon_2 \quad\implies\quad \delta \,\geq\, \tfrac{\varepsilon_2^2}{2}.
$$<p>For the &ldquo;close&rdquo; case ($H_0$), we cannot run this implication backwards: $D(\rho, \Phi) \leq \sqrt{2\delta}$ does not give an <em>upper bound</em> on $\delta$ in terms of $D(\rho, \Phi)$. Instead, we use a standard variational/POVM bound: for any projector $\Pi$,</p>$$
\bigl| \text{tr}(\Pi\rho) - \text{tr}(\Pi\Phi) \bigr| = \bigl| \text{tr}[\Pi(\rho - \Phi)] \bigr| \,\leq\, D(\rho, \Phi).
$$<p>Choosing $\Pi$ as the mismatch projector for matching-basis rounds:</p>$$
\Pi_{\text{mis}}^{Z} = \ket{01}\bra{01} + \ket{10}\bra{10},\qquad
\Pi_{\text{mis}}^{X} = \ket{+-}\bra{+-} + \ket{-+}\bra{-+},
$$<p>the overall mismatch rate is $\delta = \tfrac{1}{2}\bigl(\text{tr}[\Pi_{\text{mis}}^{Z}\rho] + \text{tr}[\Pi_{\text{mis}}^{X}\rho]\bigr)$, which occurs with probability zero for the ideal EPR state:</p>$$
\text{tr}[\Pi_{\text{mis}}^{Z}\Phi] = \text{tr}[\Pi_{\text{mis}}^{X}\Phi] = 0.
$$<p>Since each $\Pi_{\text{mis}}^{B}$ ($B \in \{Z, X\}$) is a positive projector and $\text{tr}[\Pi_{\text{mis}}^{B}\rho] \geq 0$, we have</p>$$
\bigl| \text{tr}[\Pi_{\text{mis}}^{B}(\rho - \Phi)] \bigr|
= \bigl| \text{tr}[\Pi_{\text{mis}}^{B}\rho] - 0 \bigr|
= \text{tr}[\Pi_{\text{mis}}^{B}\rho].
$$<p>Apply the variational bound $\bigl|\text{tr}[\Pi(\rho - \sigma)]\bigr| \leq D(\rho, \sigma)$ with $\Pi = \Pi_{\text{mis}}^{B}$ and $\sigma = \Phi$:</p>$$
\text{tr}[\Pi_{\text{mis}}^{B}\rho] \leq D(\rho, \Phi).
$$<p>Thus</p>$$
\delta_Z = \text{tr}[\Pi_{\text{mis}}^{Z}\rho] \leq D(\rho, \Phi),\qquad
\delta_X = \text{tr}[\Pi_{\text{mis}}^{X}\rho] \leq D(\rho, \Phi).
$$<p>Averaging gives</p>$$
\delta = \tfrac{1}{2}(\delta_Z + \delta_X) \leq D(\rho, \Phi),
$$<p>so we have the bound $\delta \leq D(\rho, \Phi)$. Therefore, under $\mathbf{H_0}$ with $D(\rho, \Phi) \leq \varepsilon_1$, the mismatch rate satisfies $\delta \leq \varepsilon_1$.</p><p>Let&rsquo;s make this intuition precise.</p><p>First, starting from the matching-outcomes protocol, we establish a Bernoulli trial model. Consider $S \subseteq \{1, \dots, N\}$, the set of matching‚Äêbasis rounds. For each $i \in S$, define the indicator</p>$$
Y_i :=
\begin{cases}
1 &\text{if } x_i \neq \tilde x_i\\
0 &\text{if } x_i = \tilde x_i
\end{cases}
$$<p>so each $Y_i \in \{0, 1\}$. Under the i.i.d. assumption, $\{ Y_i \}_{i \in S}$ is a set of independent Bernoulli random variables each with parameter $\delta = \Pr[x_i \neq \tilde{x}_i ~|~ \theta_i = \tilde{\theta}_i]$, the <em>true</em> error rate (mismatch probability) conditioned on matching bases:</p>$$
Y_i \sim \text{Bernoulli}(\delta) \quad\forall i \in S.
$$<p>The <em>empirical</em> error rate is the observable:</p>$$
\hat{\delta} = \frac{1}{|S|}\sum_{i \in S} Y_i.
$$<p>This is the sample mean of $|S|$ independent bounded variables in $[0, 1]$.</p><p>The Chernoff-Hoeffding concentration bound (for Bernoulli RVs) tells us that if we average $|S|$ independent $\{ 0, 1 \}$ variables whose true mean is $\delta$, then the chance our empirical average $\hat{\delta}$ deviates from $\delta$ by more than some amount $t > 0$ (the <em>bad</em> event) is tiny:</p>$$
\Pr\left(|\hat{\delta} - \delta| \geq t\right) \leq 2e^{-2|S|t^2}.
$$<ul><li>The bigger $|S|$ is, the smaller this probability becomes.</li><li>The larger we demand $t$ (a looser estimate), the fewer samples we need.</li></ul><p>To make this failure probability to be at most $\alpha$, it suffices that (by rearranging)</p>$$
|S| = \frac{1}{2t^2}\,\ln\!\left(\frac{2}{\alpha}\right)
$$<p>which will be useful soon.</p><p>As we&rsquo;ve discussed, in a tolerant test, instead of a single decision point $\varepsilon$, we have to fix two trace-distance tolerances</p>$$
0 \leq \varepsilon_1 < \varepsilon_2 \leq 1,
$$<p>where</p><ul><li>$\varepsilon_1$ is the acceptance tolerance for $\mathbf{H_0}$; $D(\rho, \Phi) \leq \varepsilon_1$ implies &ldquo;close&rdquo;, and</li><li>$\varepsilon_2$ is the rejection tolerance for $\mathbf{H_1}$; $D(\rho, \Phi) \geq \varepsilon_2$ implies &ldquo;far&rdquo;.</li></ul><p>We translate these trace distance parameters into error rate thresholds by</p>$$
\delta_{\text{close}} := \varepsilon_1,
\qquad
\delta_{\text{far}} := \frac{\varepsilon_2^2}{2}.
$$<p>For the promise gap to be non-trivial, we need $\delta_{\text{far}} > \delta_{\text{close}}$, which translates to</p>$$
\varepsilon_1 < \frac{\varepsilon_2^2}{2}.
$$<p>This imposes an extra constraint beyond the generic condition $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$.</p><p>Now let&rsquo;s look at a natural proposal for the decision rule&mldr;</p><blockquote><p><strong>Decision rule <em>(flawed)</em>.</strong> After measuring and computing the empirical error rate $\hat{\delta}$:</p><ul><li>If $\hat{\delta} \leq \delta_{\text{close}}$, declare <strong>&ldquo;close&rdquo;</strong> (accept).</li><li>If $\hat{\delta} \geq \delta_{\text{far}}$, declare <strong>&ldquo;far&rdquo;</strong> (reject).</li><li>If $\delta_{\text{close}} < \hat{\delta} < \delta_{\text{far}}$, declare the result <strong>inconclusive</strong>.</li></ul></blockquote><p>It looks promising and intuitive. But is this viable? Unfortunately, no. The reason this rule is flawed is the same reason a single hard cutoff $\delta_*$ is flawed! So this rule fails to provide a high-confidence guarantee for the very states it&rsquo;s supposed to certify.</p><p>Consider a state whose true error rate is exactly on the boundary, $\delta = \delta_{\text{close}}$. The measured value $\hat{\delta}$ is a random variable centred on this true value. Due to statistical noise, there is roughly a $50\%$ chance that the measurement will yield $\hat{\delta} > \delta_{\text{close}}$. According to this rule, we would declare the result &ldquo;inconclusive&rdquo; i.e. fail to accept about half the time! An error rate of $\sim\!50\%$ is unacceptably high and provides no meaningful confidence. If $\delta = \delta_{\text{far}}$ exactly, then again we suffer from the same problem.</p><p>To fix this, we need to relax the decision boundary: instead of testing directly at the promise thresholds $\delta_{\text{close}}$ and $\delta_{\text{far}}$, we introduce a &ldquo;buffer zone&rdquo; to absorb statistical fluctuations.</p><p>To implement this we introduce a <em>margin</em> $t > 0$, which:</p><ul><li>widens our decision zone so random fluctuations don&rsquo;t flip us at the boundary, and</li><li>serves as the deviation parameter in our Chernoff‚ÄìHoeffding bound, which tells us that with very high probability we have $|\hat{\delta} - \delta| < t$, meaning the measured value $\hat{\delta}$ won&rsquo;t fluctuate upwards or downwards by more than $t$.</li></ul><p>By choosing our single cutoff</p>$$
c = \delta_{\text{close}} + t,
$$<p>we build in exactly enough &ldquo;slack&rdquo; so that even if the <em>true</em> rate sits at the lower promise boundary, $\delta = \delta_{\text{close}}$, then by the Chernoff-Hoeffding bound</p>$$
\Pr\bigl[\hat{\delta} \geq c\bigr]
~\leq~\Pr\bigl[\hat{\delta} - \delta \geq t\bigr]
~\leq~2e^{-2|S|t^2}\,,
$$<p>i.e. the completeness error is only the exponentially small Chernoff tail and not the horrible $50\%$ we were getting. By the same choice $c = \delta_{\text{far}} - t$ on the upper side, we get a <em>symmetric</em> buffer $(c, \delta_{\text{far}})$ that makes the soundness error equally tiny.</p><p>So&mldr; the correct, albeit counter-intuitive, solution is to use a single decision cutoff $c$ placed strategically inside the promise gap $(\delta_{\text{close}}, \delta_{\text{far}})$. We&rsquo;ve gone full circle!</p><p>A very natural way to pick the margin $t > 0$ is to split the gap between $\delta_{\text{close}}$ and $\delta_{\text{far}}$ in half:</p>$$
t = \frac{\delta_{\text{far}} - \delta_{\text{close}}}{2} = \frac{\varepsilon_2^2}{4} - \frac{\varepsilon_1}{2} = \frac{\varepsilon_2^2 - 2\varepsilon_1}{4}.
$$<p>As $\delta_{\text{far}} > \delta_{\text{close}}$ under our restriction $\varepsilon_1 < \varepsilon_2^2/2$, the requirement $t > 0$ is satisfied. Then</p>$$
c
= \frac{\delta_{\text{close}} + \delta_{\text{far}}}{2}
= \frac{\varepsilon_1}{2} + \frac{\varepsilon_2^2}{4}
= \frac{2\varepsilon_1 + \varepsilon_2^2}{4}
= \delta_{\text{close}} + t
= \delta_{\text{far}} - t
$$<p>would conveniently place our decision boundary exactly in the middle for perfect symmetry.</p><blockquote><p><strong>Decision rule.</strong> After measuring and computing $\hat{\delta}$,</p><ul><li>If $\hat{\delta} \leq c$, accept $\mathbf{H_0}$ (&ldquo;close&rdquo;).</li><li>If $\hat{\delta} > c$, accept $\mathbf{H_1}$ (&ldquo;far&rdquo;).
$$
\text{Decision} =
\begin{cases}
\text{‚Äúclose‚Äù}, & \hat{\delta} \leq c,\\
\text{‚Äúfar‚Äù}, & \hat{\delta} > c.
\end{cases}
$$</li></ul></blockquote><p>Let&rsquo;s quickly prove correctness under the <em>good event</em></p>$$
\mathcal{G} = \left\{\, |\hat{\delta} - \delta| < t \,\right\}.
$$<p>Correctness includes completeness ($\mathbf{H_0}$: &ldquo;close&rdquo; $\Rightarrow$ &ldquo;accept&rdquo;) and soundness ($\mathbf{H_1}$: &ldquo;far&rdquo; $\Rightarrow$ &ldquo;reject&rdquo;).</p><ol><li><p><strong>Completeness</strong> (&ldquo;close&rdquo; case).<br>If the true $\delta \leq \delta_{\text{close}} = c - t$, then conditioned on $\mathcal{G}$ we have</p>$$
-t < \hat{\delta} - \delta < t.
$$<p>Using the right inequality ($\hat{\delta} - \delta < t$),</p>$$
\hat{\delta} < \delta + t ~\leq~ (c - t) + t ~=~ c,
$$<p>hence $\hat{\delta} \leq c$ and we accept &ldquo;close&rdquo;.</p></li><li><p><strong>Soundness</strong> (&ldquo;far&rdquo; case).<br>If the true $\delta \geq \delta_{\text{far}} = c + t$, then conditioned on $\mathcal{G}$ the left inequality ($-t < \hat{\delta} - \delta$) gives</p>$$
\hat{\delta} > \delta - t ~\geq~ (c + t) - t ~=~ c,
$$<p>hence $\hat{\delta} > c$ and we reject (&ldquo;far&rdquo;).</p></li></ol><p>Both completeness ($\delta \leq \delta_{\text{close}}$) and soundness ($\delta \geq \delta_{\text{far}}$) can fail only if $|\hat{\delta} - \delta| \geq t$ (the <em>bad</em> event), which the concentration bound guarantees occurs with probability at most $\alpha/2$. All that remains is to choose the sample size $|S|$ (and $N$) so that $\Pr[\mathcal{G}] \geq 1 - \alpha/2$.</p><p>Fix a target failure probability $\alpha \in (0,1)$. Substituting $t = \frac{\varepsilon_2^2 - 2\varepsilon_1}{4}$ into the $|S|$ equation from earlier and allocating $\alpha/2$ to the estimation tail gives</p>$$
\begin{aligned}
|S|
~&=~
\frac{1}{2t^2}\,\ln\!\left(\frac{4}{\alpha}\right)
~=~
\frac{1}{2\bigl( \,(\varepsilon_2^2 - 2\varepsilon_1)/4\, \bigr)^2}\,\ln\!\left(\frac{4}{\alpha}\right)
\\\\~&=~
\frac{8\,\ln(4/\alpha)}{(\varepsilon_2^2 - 2\varepsilon_1)^2}
~=~
O\!\left(\frac{1}{(\varepsilon_2^2 - 2\varepsilon_1)^2}\right).
\end{aligned}
$$<p>Therefore, if we manage to collect $|S| = O\Bigl((\varepsilon_2^2 - 2\varepsilon_1)^{-2}\Bigr)$ matching‚Äêbasis samples satisfying the display above, then with probability $\geq 1 - \alpha/2$ we have $|\hat{\delta} - \delta| < t$ (the good event $\mathcal{G}$), which guarantees both completeness and soundness as shown above.</p><p>Finally, we need to determine a bound on $N$, the actual number of rounds we&rsquo;ll run the protocol for. Our overall success requires guarding against two distinct types of errors: estimation failure ($E_{\text{estimation}}$), for which we now have $\Pr(E_{\text{estimation}}) \leq \alpha/2$, and sampling failure ($E_{\text{sample}}$), where we fail to collect enough data in the first place. The total failure probability is bounded by their sum ($\alpha$) using the <em>union bound</em>.</p><p>Since the probability of the measurement bases matching in any given round is $1/2$, as it occurs uniformly at random, the expected number of matching-basis samples is $\mathbb{E}[|S|] = N/2$. To safeguard against statistical fluctuations, we should choose $N$ to be larger than the simple estimate of $2|S|$. A robust and standard choice is $N = 4|S|$. With this choice, the probability of obtaining fewer than $|S|$ matching-basis samples - the event $E_{\text{sample}}$ - can be shown via a standard Chernoff bound to be less than $e^{-|S|/4}$. Let the random variable for the number of matching-basis rounds from a total of $N$ trials be $X$. Then</p>$$
X \sim \text{Binomial}\!\left(N, \tfrac{1}{2}\right).
$$<p>As we have chosen $N = 4|S|$, note that</p>$$
\mathbb{E}[X] = \frac{N}{2} = 2|S|.
$$<p>The multiplicative Chernoff bound gives, for any $0 < \delta < 1$,</p>$$
\Pr\bigl[X < (1-\delta)\,\mathbb{E}[X]\bigr]
~\leq~\exp\Bigl(-\tfrac{\delta^2}{2}\,\mathbb{E}[X]\Bigr).
$$<p>Setting $\delta = \tfrac{1}{2}$ so that $(1 - \delta)\,\mathbb{E}[X]=|S|$ yields</p>$$
\Pr\bigl[X < |S|\bigr]
~\leq~
\exp\Bigl(-\tfrac{(1/2)^2}{2}\cdot 2|S|\Bigr)
~=~
e^{-|S|/4}.
$$<p>To make both failure modes at most $\alpha/2$, we require</p>$$
|S| \,\geq\, \frac{8\,\ln(4/\alpha)}{(\varepsilon_2^2 - 2\varepsilon_1)^2}
\qquad\text{and}\qquad
|S| \,\geq\, 4\,\ln\!\frac{2}{\alpha}.
$$<p>Equivalently, with $N=4|S|$,</p>$$
N \ \geq\ \max\!\left\{\,\frac{32\,\ln(4/\alpha)}{(\varepsilon_2^2 - 2\varepsilon_1)^2}\,,\ \ 16\,\ln\!\frac{2}{\alpha}\right\}.
$$<p>For admissible parameters ($0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$ with $\varepsilon_1 < \varepsilon_2^2/2$), we have $0 < \varepsilon_2^2 - 2\varepsilon_1 \leq 1$, hence $(\varepsilon_2^2 - 2\varepsilon_1)^{-2} \geq 1$. Therefore</p>$$
\frac{32\,\ln(4/\alpha)}{(\varepsilon_2^2 - 2\varepsilon_1)^2} \geq 32\,\ln\!\frac{4}{\alpha} > 16\,\ln\!\frac{2}{\alpha}
$$<p>because $32\ln(4/\alpha) - 16\ln(2/\alpha) = 16\bigl(2\ln(4/\alpha) - \ln(2/\alpha)\bigr) = 16\ln(8/\alpha) > 0$ for all $\alpha \in (0,1)$. Hence the first term dominates for all admissible values, and the bound simplifies to</p>$$
N \geq \frac{32 \ln(4/\alpha)}{(\varepsilon_2^2 - 2\varepsilon_1)^2}.
$$<p>With this, we can now use the union bound to find the total probability of failure:</p>$$
\Pr(\text{Total Failure}) = \Pr(E_{\text{sample}}) + \Pr(E_{\text{estimation}}) \leq \frac{\alpha}{2} + \frac{\alpha}{2} = \alpha.
$$<p>Therefore, the choice of $N = 4|S|$ together with the displayed $|S|$ bound is sufficient. The total number of rounds/i.i.d. copies required for the test protocol is:</p>$$
N = 4|S| = \frac{32 \ln(4/\alpha)}{(\varepsilon_2^2 - 2\varepsilon_1)^2} = O\Bigl((\varepsilon_2^2 - 2\varepsilon_1)^{-2}\Bigr).
$$<p>Putting everything together, we arrive at our main result. All the hard work we&rsquo;ve done in this finite-sample analysis provides a complete description for the number of rounds $N$ needed to achieve a desired confidence level $1 - \alpha$. The key takeaway is that the required sample complexity scales as $N = O\bigl((\varepsilon_2^2 - 2\varepsilon_1)^{-2}\bigr)$, so the closer the gap between $\varepsilon_1$ and $\varepsilon_2$, the number of samples needed grows extremely rapidly. The formal statement is as follows:</p><blockquote><p><strong>Theorem (Finite-Sample Tolerant EPR Identity Test).</strong></p><p>Given $N$ i.i.d. copies of $\rho_{AB}$, fix two trace-distance tolerances</p>$$
0 \leq \varepsilon_1 < \varepsilon_2 \leq 1,
$$<p>where the constraint $\varepsilon_1 < \varepsilon_2^2/2$ holds. Fix the desired maximum failure probability $\alpha \in (0, 1)$.
Set the cutoff</p>$$
c = \frac{2\varepsilon_1 + \varepsilon_2^2}{4}.
$$<p>Consider the matching-outcomes protocol executed for a total of $N$ rounds, consuming $N$ i.i.d. copies in total. Let the decision rule be to accept <em><strong>if and only if</strong></em> the observed error rate, $\hat{\delta}$, is less than or equal to the cutoff, $c$:</p>$$
\text{Decision} =
\begin{cases}
\text{‚Äúclose‚Äù}, & \hat{\delta} \leq c,\\
\text{‚Äúfar‚Äù}, & \hat{\delta} > c.
\end{cases}
$$<p>Then if</p>$$
N \geq \frac{32\,\ln(4/\alpha)}{(\varepsilon_2^2 - 2\varepsilon_1)^2} \qquad\left( = O\Bigl((\varepsilon_2^2 - 2\varepsilon_1)^{-2}\Bigr) \right),
$$<p>the test provides the following guarantees:</p><ul><li>If $D(\rho_{AB}, \ket{\text{EPR}} \bra{\text{EPR}}_{AB}) \leq \varepsilon_1$, then the test <strong>accepts</strong> (outputs &ldquo;close&rdquo;) with confidence at least $1 - \alpha$.</li><li>If $D(\rho_{AB}, \ket{\text{EPR}} \bra{\text{EPR}}_{AB}) \geq \varepsilon_2$, then the test <strong>rejects</strong> (outputs &ldquo;far&rdquo;) with confidence at least $1 - \alpha$.</li><li>If $\varepsilon_1 < D(\rho_{AB}, \ket{\text{EPR}} \bra{\text{EPR}}_{AB}) < \varepsilon_2$, <strong>no guarantee</strong> is made on the outcome; the test may go either way (accept or reject).</li></ul></blockquote><p>We can quickly give a corollary for the exact, non-tolerant identity test as well. Recall that we write $\rho = \rho_{AB}$ and $\Phi = \ket{\text{EPR}}\bra{\text{EPR}}_{AB}$.</p><blockquote><p><strong>Corollary (Non-tolerant identity test for the EPR state).</strong></p><p>Fix $\varepsilon \in (0,1]$ and failure probability $\alpha \in (0,1)$. Consider the hypotheses</p>$$
\begin{cases}
~\mathbf{H_0}:~ & \rho = \Phi \quad\text{(exact identity)},\\[4pt]
~\mathbf{H_1}:~ & D(\rho,\Phi) \,\geq\, \varepsilon \quad\text{($\varepsilon$-far)}.
\end{cases}
$$<p>Run the matching-outcomes protocol for a total of $N$ rounds, with</p>$$
N ~\geq~ \frac{4}{\varepsilon^2}\,\ln\!\frac{1}{\alpha}.
$$<p><strong>Decision:</strong> accept $\mathbf{H_0}$ <em><strong>iff</strong></em> no mismatches are observed on the matching-basis rounds (i.e. $\hat{\delta} = 0$).</p><p><strong>Guarantee.</strong> Completeness holds with probability $1$ and soundness holds with probability at least $1 - \alpha$:</p><ul><li>If $\rho = \Phi$, then $\delta = 0$ and hence $\hat{\delta} = 0$ <a href=https://en.wikipedia.org/wiki/Almost_surely target=_blank rel=noopener>almost surely</a>, so the test accepts.</li><li>If $D(\rho,\Phi) \geq \varepsilon$, then by the asymptotic identity bound $D \leq \sqrt{2\delta}$ we have $\delta \geq \varepsilon^2/2$. For each round $i \in [N]$, the probability of <em>no counted mismatch</em> is
$$
1 - \left[\Pr(x_i \neq \tilde{x}_i \mid \theta_i = \tilde{\theta}_i) \cdot \Pr(\theta_i = \tilde{\theta}_i)\right] = 1 - \delta \cdot \tfrac{1}{2}
$$
(either bases don&rsquo;t match, or they match and outcomes agree), so over $N$ rounds
$$
\Pr[\hat{\delta}=0] ~=~ (1 - \delta/2)^{N}
~\leq~ \bigl(1 - \tfrac{\varepsilon^2}{4}\bigr)^{N}
~\leq~ e^{-N\,\frac{\varepsilon^2}{4}}
~\leq~ \alpha,
$$
so the test rejects with probability at least $1 - \alpha$.</li></ul><p><strong>Total rounds.</strong> This gives a <em>direct</em> $N$-bound; no separate sampling condition on the number of matching-basis rounds is required, since unmatched rounds are already absorbed into the per-round factor $(1 - \delta/2)$.</p></blockquote></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://teaegg.net/research/urss/intro/><span class=title>¬´ Prev</span><br><span>URSS introduction</span>
</a><a class=next href=https://teaegg.net/research/urss/n-epr-test/><span class=title>Next ¬ª</span><br><span>Classical tolerant identity test for multiple EPR states</span></a></nav></footer></article></main><footer class=footer><span>¬© 2025 ∆¨·òø·ó© ·òø·òú·òú ‚ñ∂Ô∏é ‚Ä¢·Åä·Åä||·Åä|·Åã|||| | ¬∑ Built by Howard ìÜ©ìÇÄìÜ™
<span class=only-desktop>¬∑ Powered by
<a href=https://gohugo.io>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod>PaperMod</a></span></span></footer><a href=#top aria-label="go to top" title="Go to Top" class=top-link id=top-link><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){const n=document.getElementById("greeting");if(!n)return;const e=(new Date).getHours();let t;e>=6&&e<12?t="ÍßÅ …¢÷Ö÷Ö÷Ö…ñ  ç÷Ö Ä’º…®’º…¢! üåª ÍßÇ":e>=12&&e<18?t="ùêÜùê®ùê®ùêù ùêöùêüùê≠ùêûùê´ùêßùê®ùê®ùêß. ‚òÄÔ∏èüå≥‚òï":e>=18&&e<22?t="ùòéùò∞ùò∞ùò• ùò¶ùò∑ùò¶ùòØùò™ùòØùò®. üåÑüõãÔ∏èüìñ":t="ùïôùïñùï™ ùïüùïöùïòùïôùï• ùï†ùï®ùïù... ü¶âüåôüåÉ",n.textContent=t})()</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>