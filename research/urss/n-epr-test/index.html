<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Classical tolerant identity test for multiple EPR states | ùóßùóòùóî‚Ä¢ùóòùóöùóö</title><meta name=keywords content><meta name=description content="Change in notation
With the tolerant identity test for a single state $\rho_{AB}$ complete, we now turn to the problem of certifying multiple ($n$) EPR pairs at once. For brevity we write $\Phi = \ket{\text{EPR}}\bra{\text{EPR}}_{AB}$ throughout. The problem statement is as follows:

Problem.
Given two trace distance tolerances $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$, a failure probability $\alpha \in (0, 1)$, and $N$ i.i.d. copies of an unknown $2n$-qubit global state $\varrho$ on $A^n B^n$ i.e. the source produces $\varrho^{\otimes N}$, how large must $N$ at least be so that, using only local $Z$/$X$ measurements and classical postprocessing, we can decide with at least confidence $1 - \alpha$ whether
"><meta name=author content="Howard Cheung"><link rel=canonical href=https://teaegg.net/research/urss/n-epr-test/><link crossorigin=anonymous href=/assets/css/stylesheet.12d2e5fe7e7a6b449beaee7514d9f08063da1272468eea14524da628ddfaabb5.css integrity="sha256-EtLl/n56a0Sb6u51FNnwgGPaEnJGjuoUUk2mKN36q7U=" rel="preload stylesheet" as=style><link rel=icon href=https://teaegg.net/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://teaegg.net/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://teaegg.net/favicon-32x32.png><link rel=apple-touch-icon href=https://teaegg.net/apple-touch-icon.png><link rel=mask-icon href=https://teaegg.net/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://teaegg.net/research/urss/n-epr-test/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}]})})</script><link rel=icon type=image/png href=/favicon/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/favicon/favicon.svg><link rel="shortcut icon" href=/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/favicon/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="Teaegg"><link rel=manifest href=/favicon/site.webmanifest><meta property="og:url" content="https://teaegg.net/research/urss/n-epr-test/"><meta property="og:site_name" content="ùóßùóòùóî‚Ä¢ùóòùóöùóö"><meta property="og:title" content="Classical tolerant identity test for multiple EPR states"><meta property="og:description" content="Change in notation With the tolerant identity test for a single state $\rho_{AB}$ complete, we now turn to the problem of certifying multiple ($n$) EPR pairs at once. For brevity we write $\Phi = \ket{\text{EPR}}\bra{\text{EPR}}_{AB}$ throughout. The problem statement is as follows:
Problem.
Given two trace distance tolerances $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$, a failure probability $\alpha \in (0, 1)$, and $N$ i.i.d. copies of an unknown $2n$-qubit global state $\varrho$ on $A^n B^n$ i.e. the source produces $\varrho^{\otimes N}$, how large must $N$ at least be so that, using only local $Z$/$X$ measurements and classical postprocessing, we can decide with at least confidence $1 - \alpha$ whether "><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="research"><meta property="article:published_time" content="2025-08-08T17:42:31+01:00"><meta property="article:modified_time" content="2025-08-08T17:42:31+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Classical tolerant identity test for multiple EPR states"><meta name=twitter:description content="Change in notation
With the tolerant identity test for a single state $\rho_{AB}$ complete, we now turn to the problem of certifying multiple ($n$) EPR pairs at once. For brevity we write $\Phi = \ket{\text{EPR}}\bra{\text{EPR}}_{AB}$ throughout. The problem statement is as follows:

Problem.
Given two trace distance tolerances $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$, a failure probability $\alpha \in (0, 1)$, and $N$ i.i.d. copies of an unknown $2n$-qubit global state $\varrho$ on $A^n B^n$ i.e. the source produces $\varrho^{\otimes N}$, how large must $N$ at least be so that, using only local $Z$/$X$ measurements and classical postprocessing, we can decide with at least confidence $1 - \alpha$ whether
"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"üî¨ Research","item":"https://teaegg.net/research/"},{"@type":"ListItem","position":2,"name":"üîêüí° Undergraduate Research Support Scheme (URSS)","item":"https://teaegg.net/research/urss/"},{"@type":"ListItem","position":3,"name":"Classical tolerant identity test for multiple EPR states","item":"https://teaegg.net/research/urss/n-epr-test/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Classical tolerant identity test for multiple EPR states","name":"Classical tolerant identity test for multiple EPR states","description":"Change in notation With the tolerant identity test for a single state $\\rho_{AB}$ complete, we now turn to the problem of certifying multiple ($n$) EPR pairs at once. For brevity we write $\\Phi = \\ket{\\text{EPR}}\\bra{\\text{EPR}}_{AB}$ throughout. The problem statement is as follows:\nProblem.\nGiven two trace distance tolerances $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$, a failure probability $\\alpha \\in (0, 1)$, and $N$ i.i.d. copies of an unknown $2n$-qubit global state $\\varrho$ on $A^n B^n$ i.e. the source produces $\\varrho^{\\otimes N}$, how large must $N$ at least be so that, using only local $Z$/$X$ measurements and classical postprocessing, we can decide with at least confidence $1 - \\alpha$ whether ","keywords":[],"articleBody":"Change in notation With the tolerant identity test for a single state $\\rho_{AB}$ complete, we now turn to the problem of certifying multiple ($n$) EPR pairs at once. For brevity we write $\\Phi = \\ket{\\text{EPR}}\\bra{\\text{EPR}}_{AB}$ throughout. The problem statement is as follows:\nProblem.\nGiven two trace distance tolerances $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$, a failure probability $\\alpha \\in (0, 1)$, and $N$ i.i.d. copies of an unknown $2n$-qubit global state $\\varrho$ on $A^n B^n$ i.e. the source produces $\\varrho^{\\otimes N}$, how large must $N$ at least be so that, using only local $Z$/$X$ measurements and classical postprocessing, we can decide with at least confidence $1 - \\alpha$ whether $$ D\\!\\left[\\,\\varrho~,~ \\Phi^{\\otimes n}\\,\\right] $$ is small ($\\leq \\varepsilon_1$) or large ($\\geq \\varepsilon_2$)?\nDefinition (block). A block is one i.i.d. copy of the $2n$-qubit global state $\\varrho$, where we label the qubits as $(A_j, B_j)_{j=1}^n$ for convenience. We refer to each pair $(A_j, B_j)$ as a coordinate for convenience.\nBefore analysing the multi-pair scenario, let‚Äôs revisit the single-pair case first. It helps to reframe one round of the single-pair matching-outcomes protocol as a callable oracle $\\mathbb{O}$ that consumes a fresh pair of $\\rho_{AB}$ and outputs a classical bit when the bases match.\nSuppose Alice and Bob share $N$ i.i.d. copies of an unknown pair $\\rho_{AB}$. We package one measurement round into a callable oracle $\\mathbb{O}(\\rho_{AB})$ and then do simple classical post-processing. Combining $N$ oracle calls and doing the simple classical post-processing is equivalent to the $N$-round protocol!\nSingle-pair oracle $\\mathbb{O}(\\rho_{AB})$ Input: one fresh pair of the bipartite state $\\rho_{AB}$.\nProcedure:\nPick two independent basis bits $\\theta \\in \\{ 0, 1 \\}$ and $\\tilde{\\theta} \\in \\{ 0, 1 \\}$ uniformly at random. Here $\\theta = 0$ means ‚Äústandard basis ($Z$)‚Äù and $\\theta = 1$ means ‚ÄúHadamard basis ($X$)‚Äù. Measure the $A$ subsystem of $\\rho_{AB}$ in basis $\\theta$ to obtain $x \\in \\{0, 1\\}$ and the $B$ subsystem in basis $\\tilde{\\theta}$ to obtain $\\tilde{x} \\in \\{0, 1\\}$. If $\\theta = \\tilde{\\theta}$ (matching bases), set $M = 1$ and $Y = \\mathbf{1}[x \\neq \\tilde x] \\in \\{0, 1\\}$; otherwise $\\theta \\neq \\tilde{\\theta}$ (mismatched bases), set $M = 0$ and $Y = \\bot$. Output: a pair $(M, Y)$ with $M \\in \\{0, 1\\}$ and $Y \\in \\{\\bot, 0, 1\\}$.\nThe oracle hides the two-party details: one call consumes one fresh pair $\\rho_{AB}$. When it emits a bit (i.e. $Y \\neq \\bot$), that bit is a Bernoulli trial with mean $\\delta$, which is the true matching-basis mismatch probability: $$ \\mathbb{E}[\\,Y \\mid M = 1\\,] = \\delta \\in[0, \\tfrac{1}{2}] \\quad\\text{(after the standard relabelling per basis)}. $$(We relabel Bob‚Äôs outcomes per basis so each per-basis mismatch rate is $\\leq 1/2$; see the convention below.)\nThis oracle $\\mathbb{O}$ encapsulates the entire procedure of basis selection, local measurement, and comparison for a single coordinate $(A_j, B_j)$ of a block. A block has $n$ coordinates, we call $\\mathbb{O}$ once per coordinate so $n$ times in total (either sequentially or in parallel). We then keep only the calls where the bases matched and do simple classical post-processing (count mismatches). Over $N$ blocks, this amounts to $n \\cdot N$ oracle calls in total.\nRemark. ‚ÄúSequential‚Äù vs ‚Äúparallel‚Äù only affects implementation. Equivalently one can run many calls (measure many coordinates) in parallel and reveal bases afterwards over a classical channel; the distribution of $(M, Y)$ is identical.\nSingle-pair protocol (post-processing over $N$ oracle calls) In our single-pair case, the number of coordinates $n = 1$, so trivially we would call the oracle $N$ times as we‚Äôre given $N$ blocks.\nMake $N$ independent calls to $\\mathbb{O}(\\rho_{AB})$. From those $N$ calls we obtain $(M_1, Y_1), \\ldots, (M_N, Y_N)$. Define the set of matching-basis rounds $$ S = \\bigl\\{i \\in \\{1, \\dots, N\\} : M_i = 1 \\bigr\\} \\subseteq \\bigl\\{ 1, \\dots, N \\bigr\\}. $$ If by rare chance $S = \\varnothing$ (no matching bases at all), simply rerun the whole protocol as the probability of $S = \\varnothing$ is $2^{-N}$, which is negligible for modest $N$. Compute the observed error rate $$ \\hat{\\delta} = \\frac{1}{|S|}\\sum_{i\\in S} Y_i. $$ which represents the mismatch fraction conditioned on matching-basis rounds. Note. This is exactly equivalent to the usual BB84-style ‚Äúannounce bases and outcomes over a classical authenticated channel (CAC) and keep only the matching bases‚Äù description; we‚Äôve just folded that bookkeeping into $(M_i, Y_i)$.\nWith this, we can provide an alternative but mathematically equivalent tolerant identity test for one EPR state ($n = 1$).\nTheorem (Finite-sample classical tolerant identity test for the EPR state).\nGiven $N$ (i.i.d.) blocks of $\\varrho = \\rho_{AB}$, fix two trace-distance tolerances $$ 0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1, $$ and the desired maximum failure probability $\\alpha \\in (0, 1)$. Set the cutoff $$ c = \\frac{\\varepsilon_1^2 + \\varepsilon_2^2}{4}. $$ Consider the reformulated matching protocol above where we make $N$ independent calls to $\\mathbb{O}(\\varrho)$ (one per block), and compute the observed error rate $\\hat{\\delta}$. For the test, let the decision rule be to accept iff $\\hat{\\delta} \\leq c$: $$ \\text{Decision} = \\begin{cases} \\text{‚Äúclose‚Äù}, \u0026 \\hat{\\delta} \\leq c,\\\\ \\text{‚Äúfar‚Äù}, \u0026 \\hat{\\delta} \u003e c. \\end{cases} $$ Then if $$ N \\geq \\frac{32\\,\\ln(2/\\alpha)}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2} \\qquad\\left( = O\\Bigl((\\varepsilon_2^2 - \\varepsilon_1^2)^{-2}\\Bigr) \\right), $$ after running the test, the following holds:\nCompleteness. If $D(\\varrho, \\Phi) \\leq \\varepsilon_1$, then the test accepts (outputs ‚Äúclose‚Äù) with confidence at least $1 - \\alpha$. Soundness If $D(\\varrho, \\Phi) \\geq \\varepsilon_2$, then the test rejects (outputs ‚Äúfar‚Äù) with confidence at least $1 - \\alpha$. Promise gap. If $\\varepsilon_1 \u003c D(\\varrho, \\Phi) \u003c \\varepsilon_2$, no guarantee is made on the outcome; the test may go either way (accept or reject). Note that we call the oracle $N$ times in this case only because $n = 1$. In general $n \\geq 2$ so this is not true; the number of oracle calls is $n \\cdot N$.\nWith the notations established and the single-pair scenario ($n = 1$) as a reference, we now turn to analysing the number of blocks needed to certify multiple EPR pairs for $n \\geq 2$ as per the problem statement.\ndo-rE-MI ‚ô´ For brevity we write $\\rho = \\rho_{AB}$ throughout. In particular, we will show how the same matching-outcomes protocol extends in three settings of increasing generality and difficulty:\nEasy (i.i.d. pairs).\nAll $n$ pairs are identical: $$ \\varrho = \\rho^{\\otimes n}\\quad\\text{vs.}\\quad\\Phi^{\\otimes n}. $$ Medium (independent, non-identical pairs).\nEach pair may differ but remains uncorrelated: $$ \\varrho = \\rho_1\\otimes\\rho_2\\otimes\\dots\\otimes\\rho_n \\quad\\text{vs.}\\quad \\Phi^{\\otimes n}. $$ Hard (arbitrary adversary).\nThe most general case allows an arbitrary $2n$-qubit state $\\varrho$, possibly entangled across pairs, against which we still wish to test closeness to $\\Phi^{\\otimes n}$.\nWe will analyse $N$, the number of blocks (i.i.d. copies) of the $2n$-qubit state $\\varrho$ required to decide closeness to $\\Phi^{\\otimes n}$. As we‚Äôve seen, each block contains $n$ pairs and therefore induces $n$ calls to the single-pair oracle $\\mathbb{O}$ (once per coordinate), so the total number of oracle calls is $n \\cdot N$. We state all bounds in terms of the number blocks needed, $N$, as the primary resource, and convert to total oracle calls by multiplying by $n$ when helpful. (The measurement bases match with probability $1/2$ independently per coordinate.)\nWhy do we count blocks? This is because the physical source hands us i.i.d. blocks - full $2n$-qubit copies of $\\varrho$. Block complexity answers the operational question ‚Äúhow many copies of $\\varrho$ must we request to decide ‚Äòclose‚Äô vs ‚Äòfar‚Äô?‚Äù. Inside each block we make $n$ single‚Äëpair measurements (one per coordinate), i.e. $n$ oracle calls, so the total number of calls is $T = n \\cdot N$. While oracle‚Äëcall counts are useful for estimating raw measurement time or hardware throughput, the fundamental resource is the number of i.i.d. copies of $\\varrho$, i.e. the number of blocks $N$.\nNote. In the context of BB84, these three scenarios correspond directly to the class of attacks that an eavesdropper (Eve) might do:\nEasy (i.i.d. pairs): Eve applies the same attack channel to each transmitted qubit independently, with no memory from one round to the next. Every round she starts from scratch, so her joint state is $\\varrho = \\rho^{\\otimes n}$.\nMedium (independent, non-identical pairs): Eve still treats each qubit independently and measures immediately, but she may choose a different attack in each round. Her overall state is the product $\\varrho = \\rho_{1}\\otimes\\rho_{2}\\otimes\\dots\\otimes\\rho_{n}$.\nHard (arbitrary adversary): Eve may entangle her systems across rounds and defer all measurements until the end. There is no tensor-product structure, so her state is an arbitrary $2n$-qubit $\\varrho$.\nBy proving security in each model, starting with the easiest and working up to the fully coherent setting, we obtain a hierarchy of BB84 security guarantees that mirror the increasing power of potential attack by Eve.\nWe begin with the i.i.d. case as it‚Äôs both the simplest to analyse and a useful building block for the more challenging scenarios.\nEasy case (i.i.d. pairs) A na√Øve per-pair approach using trace distance A first idea is to ignore the joint state and run the single-pair tolerant test on each of the $n$ coordinates separately, then accept only if every coordinate passes. Equivalently, one could tally the per-pair/per-coordinate (which is the same under the independent assumption of i.i.d.) mismatch indicators into a total error count and compare that sum against a scaled threshold, thanks to the i.i.d. assumption.\nLet $D_1 = D(\\rho, \\Phi)$ and $D_n = D(\\rho^{\\otimes n}, \\Phi^{\\otimes n})$. By subadditivity, $$ D_n \\leq n\\,D_1. $$To guarantee $D_n \\leq \\varepsilon_1$, it suffices to enforce the per-pair condition $D_1 \\leq \\varepsilon_1/n$. Thus at the per-pair level the tolerances become $\\varepsilon_1/n$ vs. $\\varepsilon_2/n$. Since the single-pair sample complexity scales like $(\\varepsilon_2^2 - \\varepsilon_1^2)^{-2}$, replacing $\\varepsilon_j \\mapsto \\varepsilon_j/n$ shrinks the squared gap by $n^2$, and the per-coordinate number of blocks needed inflates by $n^4$:\n$$ N_{\\text{per-coord}} ~\\gtrsim~ \\frac{32\\,n^4}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2}\\,\\ln\\!\\frac{2}{\\alpha}. $$We need all $n$ coordinates to pass simultaneously with total failure probability $\\alpha$. A union bound replaces $\\alpha$ by $\\alpha/n$, contributing an extra $\\log n$ factor:\n$$ N_{\\text{na√Øve (blocks)}} ~\\gtrsim~ \\frac{32\\,n^4}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2}\\,\\ln\\!\\frac{2n}{\\alpha}. $$Takeaway. The na√Øve per-pair route costs $O(n^4\\log n)$ blocks, whereas the collective (fidelity-based) test from the next section needs only $O(n)$ blocks (up to the same $(\\varepsilon_2^2 - \\varepsilon_1^2)^{-2}$ and $\\log(1/\\alpha)$ factors). The huge gap in our na√Øve method comes from shrinking tolerances by $1/n$ at the per-pair level (which explodes sample size by $n^4$); the union bound adds only the mild $\\log n$. At first glance the na√Øve method seems reasonably efficient, but a closer look shows it is actually markedly worse than the collective strategy developed below.\nRemark. In the easy and medium cases, ‚Äúper-coordinate‚Äù and ‚Äúper-pair‚Äù are interchangeable because within each block the state factorises across coordinates: easy: $\\varrho = \\rho^{\\otimes n}$; medium: $\\varrho = \\bigotimes_{i=1}^n \\rho_i$. In particular, there is no cross-coordinate entanglement inside a block (pairs may be identical in the easy case and merely different in the medium case). In the hard case, $\\varrho$ may be arbitrarily entangled across coordinates, so we use per-coordinate language exclusively there to be precise.\nGlobal block test using fidelity Given a global state $\\varrho = \\rho^{\\otimes n}$, for a single pair $\\rho$: $$ F_1 ~=~ F(\\rho,\\Phi), \\quad D_1 ~=~ D(\\rho,\\Phi), $$ and in the $n$-pair i.i.d. case we have the rules $$ F_n ~:=~ F\\bigl(\\rho^{\\otimes n},\\,\\Phi^{\\otimes n}\\bigr) ~=~ F_1^{n}, \\qquad D_n ~:=~ D\\bigl(\\rho^{\\otimes n},\\,\\Phi^{\\otimes n}\\bigr) ~\\leq~ n\\,D_1. $$ This means we can express the $n$-pair (block) closeness conditions entirely in terms of the single-pair fidelity $F_1$, thanks to the exact tensor-product multiplicativity rule $F(\\rho^{\\otimes n},\\Phi^{\\otimes n}) = F(\\rho,\\Phi)^n$ (or equivalently $F_n = F_1^n$). Working directly with fidelity avoids the looser trace-distance bound $D(\\rho^{\\otimes n},\\Phi^{\\otimes n}) \\leq n\\,D(\\rho,\\Phi)$, which would give a much weaker bound than the tight scaling we get from fidelity.\nTranslating hypotheses Our goal is to distinguish $$ \\begin{cases} ~\\mathbf{H_0}: \u0026D_n \\,\\leq\\,\\varepsilon_1 \\quad\\iff\\quad \\rho^{\\otimes n}\\text{ is ‚Äúclose‚Äù to }\\Phi^{\\otimes n},\\\\[6pt] ~\\mathbf{H_1}: \u0026D_n \\,\\geq\\,\\varepsilon_2 \\quad\\iff\\quad \\rho^{\\otimes n}\\text{ is ‚Äúfar‚Äù from }\\Phi^{\\otimes n}, \\end{cases} $$ with $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$. By Fuchs‚Äìvan de Graaf, $$ 1 - F_n ~\\leq~ D_n ~\\leq~ \\sqrt{1 - F_n^{2}}, $$ so controlling $F_n$ tightly leads to a corresponding control on $D_n$. Since $F_n = F_1^{n}$, we can use this and the upper bound of Fuchs‚Äìvan de Graaf to rewrite the hypotheses as fidelity conditions per-pair: $$ \\begin{cases} ~\\mathbf{H_0}: \\quad \u0026D_n \\,\\leq\\,\\varepsilon_1 \u0026\\impliedby \u0026F_n^2 ~\\geq~ 1 - \\varepsilon_1^2 \u0026\\iff \u0026F_1 ~\\geq~ (1 - \\varepsilon_1^2)^{1/(2n)} \\\\[4pt] ~\\mathbf{H_1}: \\quad \u0026D_n \\,\\geq\\,\\varepsilon_2 \u0026\\implies \u0026F_n^2 ~\\leq~ 1 - \\varepsilon_2^2 \u0026\\iff \u0026F_1 ~\\leq~ (1 - \\varepsilon_2^2)^{1/(2n)} \\end{cases}\\quad. $$You might be wondering why we need a sufficient condition for $\\mathbf{H_0}$ and a necessary condition for $\\mathbf{H_1}$. This is because we need to guarantee that accepted states are truly close (requiring a sufficient condition) and that far states are rejected (requiring a necessary condition) to prevent false accepts.\nSoundness of acceptance (Accept $\\Rightarrow$ Close; avoid false accepts). Why do we use a ‚Äúsufficient‚Äù $F\\!\\to\\!D$ direction? We want ‚Äúif the test accepts, the global state is close‚Äù, i.e. no false accept. That needs an upper bound on distance from fidelity, which comes from the right-hand FvG: $$ D_n \\leq \\sqrt{1 - F_n^2}. $$ So we enforce $F_n \\geq \\sqrt{1 - \\varepsilon_1^2}$ (equivalently $F_1 \\geq (1 - \\varepsilon_1^2)^{1/(2n)}$), which forces $D_n \\leq \\varepsilon_1$. If instead you used the left-hand side $1 - F_n \\leq D_n$ with a threshold $F_n \\geq 1-\\varepsilon_1$, you could falsely accept a far state. Example: take $\\varepsilon_1 = 0.1$ and a state with $F_n = 0.90$. The right-hand FvG still allows $D_n$ to be as high as $\\sqrt{1 - 0.9^2} \\approx 0.436 \u003e 0.1$, so the state could be far from the target yet would be accepted by this flawed rule.\nSoundness of rejection (Far $\\Rightarrow$ Reject; again avoid false accepts). Why do we use a ‚Äúnecessary‚Äù $D\\!\\to\\!F$ direction? We want every far state to be rejected, i.e. no false accept. We start from ‚Äúfar $\\Rightarrow$ small fidelity‚Äù, and again consider the right-hand FvG: $$ D_n \\geq \\varepsilon_2 \\implies F_n \\leq \\sqrt{1 - \\varepsilon_2^2}. $$ Together with $\\sqrt{1 - 2\\delta} \\leq F_1$, this yields $\\delta \\geq \\delta_{\\text{far}} = \\frac{1}{2}[1 - (1 - \\varepsilon_2^2)^{1/n}]$. Any simpler rule like ‚Äúreject if $F_n \\leq \\tau$‚Äù with $\\tau \u003c \\sqrt{1 - \\varepsilon_2^2}$ will falsely accept some far states. Example: $\\varepsilon_2 = 0.8 \\implies \\sqrt{1 - \\varepsilon_2^2} = 0.6$; a state with $F_n = 0.55$ has $D_n = \\sqrt{1 - 0.55^2} \\approx 0.835 \u003e \\varepsilon_2$ yet would be accepted by $\\tau = 0.4$.\nWhat about completeness? We will soon see that the proof for completeness (avoiding false rejects of close states) is not a deterministic guarantee, but a statistical one. It‚Äôs the promise that if you are given a good state, your experiment will correctly identify it with very high confidence $1 - \\alpha$. This guarantee comes from the power of the Chernoff-Hoeffding concentration bound, and we will see the full reasoning below.\nRemark. You might notice that this explicit discussion of sufficient and necessary conditions was not needed for the single-pair test. This is because the single-pair proof is more direct - in that case, the Asymptotic EPR Identity Bound ($\\delta \\geq \\varepsilon^2/2$) provides a single powerful link between the trace distance $\\varepsilon$ and the error rate $\\delta$, without needing to use fidelity as an intermediary, so it implicitly contains both the necessary and sufficient logic needed to construct the test. In contrast, the multi-pair proof uses the asymmetric Fuchs-van de Graaf inequalities, forcing us to explicitly analyse the logical direction for each guarantee.\nLet‚Äôs quickly verify that $F_n^2 \\geq 1 - \\varepsilon_1^2$ is a sufficient condition for $D_n \\leq \\varepsilon_1$ ($\\mathbf{H_0}$): $$ F_n^2 \\geq 1 - \\varepsilon_1^2 \\quad\\iff\\quad 1 - F_n^2 \\leq \\varepsilon_1^2 $$ by rearranging. Substituting this into the upper bound of Fuchs‚Äìvan de Graaf yields $$ D_n ~\\leq~ \\sqrt{1 - F_n^2} ~\\leq~ \\sqrt{\\varepsilon_1^2} ~=~ \\varepsilon_1 $$ so indeed $[F_n^2 \\geq 1 - \\varepsilon_1^2] \\implies [D_n \\leq \\varepsilon_1]$. Similarly we can verify that $F_n^2 \\leq 1 - \\varepsilon_2^2$ is a necessary condition for $D_n \\geq \\varepsilon_2$ ($\\mathbf{H_1}$) by plugging $\\mathbf{H_1}$ into the upper bound of Fuchs‚Äìvan de Graaf: $$ \\varepsilon_2 \\leq D_n \\quad\\implies\\quad \\varepsilon_2 ~\\leq~ D_n ~\\leq~ \\sqrt{1 - F_n^2}. $$ Rearranging $$ \\varepsilon_2 \\leq \\sqrt{1 - F_n^2} \\quad\\iff\\quad F_n^2 \\leq 1 - \\varepsilon_2^2 $$ immediately shows that $[D_n \\geq \\varepsilon_2] \\implies [F_n^2 \\leq 1 - \\varepsilon_2^2]$ as required.\nDefining the error rate thresholds Lemma (single-pair oracle asymptotic link). For one call to $\\mathbb{O}(\\rho_{AB})$, with $\\delta = \\Pr[Y = 1 \\mid M = 1]$, we have $F(\\rho_{AB}, \\Phi) \\geq \\sqrt{1 - 2\\delta}$.\nProof sketch. This lemma is a direct consequence of the Asymptotic EPR Identity Bound established in the single-pair analysis. Since the oracle $\\mathbb{O}(\\rho_{AB})$ is simply a procedural reframing of a single round of that protocol, the fundamental relationship between the true error rate $\\delta$ and the fidelity $F$ remains unchanged. $\\quad\\square$\nUsing this lemma directly, the link between fidelity $F_1$ and true error rate $\\delta$ is $$ F_1 \\geq \\sqrt{1 - 2\\delta} \\quad\\iff\\quad \\delta \\geq \\frac{1 - F_1^2}{2}. $$ We will use this relation to define thresholds on $\\delta$.\nConvention. For each basis, we relabel Bob‚Äôs outcomes if needed so the mismatch rate is $\\leq 1/2$ (i.e. replace $\\delta_b$ by $\\min \\{\\delta_b, 1 - \\delta_b\\}$). With this standard symmetrisation, the aggregated $\\delta \\in [0, 1/2]$ and the bound $F_1 \\geq \\sqrt{1 - 2\\delta}$ is always meaningful.\nConcretely, let $$ f(\\varepsilon) := \\frac{1 - (1 - \\varepsilon^2)^{1/n}}{2}, $$ and $$ \\qquad \\delta_{\\text{close}} := \\frac{1 - (1 - \\varepsilon_1^2)^{1/n}}{2} = f(\\varepsilon_1), \\qquad \\delta_{\\text{far}} := \\frac{1 - (1 - \\varepsilon_2^2)^{1/n}}{2} = f(\\varepsilon_2). $$These choices are justified as follows:\n(Close) If $\\delta \\leq \\delta_{\\text{close}}$, then $F_1 \\geq \\sqrt{1 - 2\\delta} \\geq \\sqrt{1-2\\delta_{\\text{close}}}$, hence $$ F_n \\geq (1 - 2\\delta_{\\text{close}})^{n/2} = \\sqrt{1 - \\varepsilon_1^{2}}, $$ so from above $D_n \\leq \\varepsilon_1$.\n(Far) If $D_n \\geq \\varepsilon_2$, then $F_n \\leq \\sqrt{1 - \\varepsilon_2^{2}}$, i.e. $F_1 \\leq (1 - \\varepsilon_2^{2})^{1/(2n)}$. Combining with $\\sqrt{1 - 2\\delta} \\leq F_1$ forces $$ 1 - 2\\delta \\leq (1 - \\varepsilon_2^{2})^{1/n} \\quad\\implies\\quad \\delta \\geq \\delta_{\\text{far}}. $$ Bounding the promise gap The promise gap in $\\delta$ is $$ \\Delta_{\\delta} ~=~ \\delta_{\\text{far}} - \\delta_{\\text{close}} ~=~ f(\\varepsilon_2) - f(\\varepsilon_1). $$ To get a lower bound on the promise gap, we first note that $$ f(\\varepsilon) = \\frac{1 - (1 - \\varepsilon^2)^{1/n}}{2} $$ is continuous on $[0, 1]$ for any $n \\geq 2$; we only consider $n \\geq 2$ since $n$ is the number of EPR pairs and so $n = 1$ reduces to the single-pair test. Indeed, $f$ is built by composing several maps on $[0, 1]$:\n$\\varepsilon \\mapsto \\varepsilon^2$ (continuous), $x \\mapsto 1 - x$ (continuous), $y \\mapsto y^{1/n}$ (continuous for $y \\geq 0$). Each of these components is continuous on the domain $[0, 1]$. Hence their composition, $f$, is also continuous on the closed interval $[0, 1]$.\nBy the fundamental theorem of calculus, $$ \\Delta_\\delta = f(\\varepsilon_2)-f(\\varepsilon_1) = \\int_{\\varepsilon_1}^{\\varepsilon_2} f'(\\varepsilon)\\,d\\varepsilon. $$ For $n\\ge2$, differentiating $f(\\varepsilon)$ gives $$ f'(\\varepsilon) = \\frac{\\varepsilon}{n}(1 - \\varepsilon^2)^{\\frac{1}{n} - 1}. $$ Since $0 \\leq \\varepsilon \u003c 1$ implies $1 - \\varepsilon^2 \\in (0, 1]$ and $\\frac{1}{n} - 1 \\leq 0$ as $n \\geq 2$, we have $$ (1 - \\varepsilon^2)^{\\frac{1}{n} - 1} \\geq 1 \\qquad\\left[\\,\\forall \\varepsilon \\in [0, 1)\\,\\right]. $$ Multiplying through by $\\varepsilon/n$ we get $$ f'(\\varepsilon) \\geq \\frac{\\varepsilon}{n}. $$ Therefore, $$ \\Delta_\\delta = \\int_{\\varepsilon_1}^{\\varepsilon_2} f'(\\varepsilon)\\,d\\varepsilon ~\\geq~ \\int_{\\varepsilon_1}^{\\varepsilon_2}\\frac{\\varepsilon}{n}\\,d\\varepsilon =\\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n}. $$Taking $\\varepsilon_2\\to 1^{-}$ (and using continuity of $f$) shows the same bound holds when $\\varepsilon_2 = 1$. Hence, for all $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$, $$ \\Delta_\\delta \\geq \\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n}. $$ Note. At $\\varepsilon=1$, the factor $(1 - \\varepsilon^2)^{\\frac{1}{n} - 1}$ diverges (for $n \u003e 2$), which only strengthens $(1 - \\varepsilon^2)^{\\frac{1}{n} - 1} \\geq 1$ and $f'(\\varepsilon) \\geq \\varepsilon/n$. The integral is interpreted as a limit from below when the upper limit is $1$.\nDecision rule and sample complexity Define a margin $$ t := \\frac{\\Delta_{\\delta}}{2} = \\frac{\\delta_{\\text{far}} - \\delta_{\\text{close}}}{2}. $$ Pick a single cutoff inside the gap (the midpoint): $$ \\kappa := \\frac{\\delta_{\\text{close}} + \\delta_{\\text{far}}}{2} = \\frac{f(\\varepsilon_1) + f(\\varepsilon_2)}{2}. $$In the easy (i.i.d.) case the true mismatch rate is identical across coordinates, so we pool all matching‚Äëbasis trials across all coordinates and blocks; let $S$ denote the set of all matching‚Äëbasis indices among the total $T = n \\cdot N$ calls.\nAfter running the protocol and computing the empirical mismatch rate $\\hat\\delta$ on the matching-basis rounds $S$, we define the decision rule as\n$$ \\textbf{Decision rule (easy case)} = \\begin{cases} \\text{‚Äúclose‚Äù} \u0026 \\text{if } \\hat\\delta \\leq \\kappa,\\\\ \\text{‚Äúfar‚Äù} \u0026 \\text{if } \\hat\\delta \u003e \\kappa. \\end{cases} $$ On matching-basis rounds, the indicators $\\{ Y_i \\}_{i \\in S}$ are i.i.d. Bernoulli random variables with mean $\\delta$. Chernoff‚ÄìHoeffding gives, for any $t \u003e 0$, $$ \\Pr\\!\\left[|\\hat\\delta - \\delta| \\geq t\\right] \\leq 2e^{-2|S|t^2}. $$ Completeness ($\\delta \\leq \\delta_{\\text{close}}$): If the good event $|\\hat\\delta - \\delta| \u003c t$ holds, then $\\hat\\delta \\leq \\delta_{\\text{close}} + t = \\kappa \\Rightarrow$ accept.\nSoundness ($\\delta \\geq \\delta_{\\text{far}}$): If $|\\hat\\delta-\\delta| \u003c t$, then $\\hat\\delta \u003e \\delta_{\\text{far}} - t = \\kappa \\Rightarrow$ reject.\nTherefore, each error (completeness or soundness) occurs only if $|\\hat\\delta-\\delta|\\geq t$ (the bad event). To make this probability $\\leq \\alpha$, it suffices that $$ 2e^{-2|S|t^2} \\leq \\alpha \\quad\\iff\\quad |S| \\geq \\frac{2}{\\Delta_\\delta^{2}}\\,\\ln\\!\\frac{2}{\\alpha} \\qquad (t = \\Delta_\\delta/2). $$ The bound on $\\Delta_\\delta$ from the integral earlier states that $$ \\Delta_\\delta \\geq \\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n}. $$ From this, we can derive that $$ \\begin{aligned} \\Delta_\\delta ~~\\geq~~ \\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n} \u0026{\\quad\\iff\\quad} \\Delta_\\delta^2 ~~\\geq~~ \\left(\\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n}\\right)^2 \\\\[10pt]\u0026{\\quad\\iff\\quad} \\Delta_\\delta^2 ~~\\geq~~ \\frac{\\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^2}{4n^2} \\\\[10pt]\u0026{\\quad\\iff\\quad} \\frac{1}{\\Delta_\\delta^2} ~\\leq~~ \\frac{4n^2}{\\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^2} \\\\[15pt]\u0026{\\quad\\iff\\quad} \\frac{2}{\\Delta_\\delta^2} \\,\\ln\\! \\frac{2}{\\alpha} ~~\\leq~~ \\frac{8n^2}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2} \\,\\ln\\! \\frac{2}{\\alpha} \\quad[\\,=: L\\,]. \\end{aligned} $$ Since $\\Delta_\\delta \\geq (\\varepsilon_2^2 - \\varepsilon_1^2)/(2n)$ and $\\frac{2}{\\Delta_\\delta^2}\\,\\ln\\!\\frac{2}{\\alpha}$ is strictly decreasing in $\\Delta_\\delta$, the true requirement is always at most $L$. Therefore, choosing $|S| \\geq L$ guarantees the condition is satisfied for all admissible $\\Delta_\\delta$: $$ |S| \\geq \\underbrace{\\frac{8\\,n^2}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2}\\,\\ln\\!\\frac{2}{\\alpha}}_{\\text{Our choice (worst-case }L\\text{)}} \\quad\\geq\\quad \\underbrace{\\frac{2}{\\Delta_\\delta^{2}}\\,\\ln\\!\\frac{2}{\\alpha}}_{\\text{What we actually need}}. $$ In other words, a sufficient condition for $|S|$ is: $$ |S| ~~\\geq~~ \\frac{8\\,n^2}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2}\\,\\ln\\!\\frac{2}{\\alpha}. $$Let $T := n \\cdot N$ be the total number of single‚Äëpair measurements (oracle calls). Since a call has matching bases with probability $1/2$, a Chernoff bound shows that choosing $T = 4|S|$ (equivalently, $N = 4|S|/n$ blocks) makes the event of getting fewer than $|S|$ matches have probability at most $e^{-|S|/4}$, which is negligibly small for moderate $|S|$. Therefore, $$ N ~=~ \\frac{4|S|}{n} ~~\\geq~~ \\frac{32\\,n}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2}\\,\\ln\\!\\frac{2}{\\alpha} \\qquad\\left[= O\\!\\left(n\\,(\\varepsilon_2^2 - \\varepsilon_1^2)^{-2}\\right)\\right], $$ and equivalently (in terms of total oracle calls) $$ T = n \\cdot N \\geq \\frac{32\\,n^2}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2}\\,\\ln\\!\\frac{2}{\\alpha}. $$So it turns out that extending the test from a single pair to $n$ i.i.d. pairs is not free: the sample cost grows linearly in the number of blocks (equivalently, quadratically in the total number of oracle calls). This is because certifying that the entire collection of $n$ states is globally $\\varepsilon$-close is much stricter than certifying a single state. A small imperfection in each pair, when compounded over the tensor product, can cause a large global deviation.\nTo keep the global fidelity $F_n = F_1^n$ high, each single-pair fidelity $F_1$ must be extremely close to $1$. Since the true error rate $\\delta$ measures per-pair imperfection, this requirement forces $\\delta$ to be much smaller than in the single-pair case. Consequently, the promise gap $\\Delta_\\delta$ (the separation between the ‚Äúclose‚Äù and ‚Äúfar‚Äù thresholds) shrinks by about a factor of $n$, compressing the relevant error-rate range into a tiny window near zero.\nA core principle of statistics is that the uncertainty of an estimated average is proportional to the inverse square root of the number of samples (in our case, this is $1 / \\sqrt{|S|}$). To reliably measure a promise gap that is $n$ times smaller, our estimate for $\\Delta_\\delta$ must be $n$ times more precise. Achieving this $n$-fold increase in precision requires an $n^2$-fold increase in the number of pooled calls (hence $O(n^2)$ total single‚Äëpair measurements) which, when grouped as blocks of size $n$, translates to an $O(n)$ growth in the number of blocks $N$.\nTheorem (Finite-sample tolerant EPR identity test, i.i.d. product version).\nLet $n \\geq 2$ and suppose the global state $\\rho^{\\otimes n}$ for some bipartite state $\\rho$. Fix global trace-distance tolerances $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$ and failure probability $\\alpha \\in (0,1)$. Define $$ \\begin{aligned} \u0026f(\\varepsilon) = \\frac{1}{2}\\!\\left[1 - (1 - \\varepsilon^2)^{1/n}\\right]\u0026,\u0026 \u0026\\delta_{\\text{close}} = f(\\varepsilon_1), \\\\[10pt]\u0026\\delta_{\\text{far}} = f(\\varepsilon_2)\u0026,\u0026 \\qquad \u0026\\kappa = \\frac{\\delta_{\\text{close}} + \\delta_{\\text{far}}}{2}. \\end{aligned} $$Protocol. Prepare $N$ (i.i.d.) blocks of $\\rho^{\\otimes n}$. For each block $j \\in [N]$ and coordinate $i \\in [n]$, make one call to $\\mathbb{O}(\\rho)$, obtaining $(M_{(j,i)}, Y_{(j,i)})$. Let $$ S := \\{\\, (j,i) \\in [N] \\times [n] ~:~ M_{(j,i)} = 1 \\,\\} $$ be the set of calls with matching bases. Define the pooled empirical mismatch rate as $$ \\hat{\\delta} := \\frac{1}{|S|} \\sum_{(j,i) \\in S} Y_{(j,i)}, $$ where $Y_{(j,i)} \\in \\{0,1\\}$ for all $(j,i) \\in S$.\nDecision rule. Accept iff $\\hat{\\delta} \\leq \\kappa$.\nIf $$ N ~~\\geq~~ \\frac{32\\,n}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2} \\,\\ln\\!\\frac{2}{\\alpha}, \\qquad\\left[= O\\!\\left(n\\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^{-2}\\right)\\right] $$ equivalently, the number of oracle calls, $$ T = n \\cdot N ~~\\geq~~ \\frac{32\\,n^2}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2}\\,\\ln\\!\\frac{2}{\\alpha}, \\qquad\\left[= O\\!\\left(n^2\\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^{-2}\\right)\\right] $$ then the following statements are true:\nCompleteness. If $D(\\rho^{\\otimes n}, \\Phi^{\\otimes n}) \\leq \\varepsilon_1$, the test accepts with probability at least $1 - \\alpha$. Soundness. If $D(\\rho^{\\otimes n}, \\Phi^{\\otimes n}) \\geq \\varepsilon_2$, the test rejects with probability at least $1 - \\alpha$. Promise gap. If $\\varepsilon_1 \u003c D(\\rho^{\\otimes n},\\Phi^{\\otimes n}) \u003c \\varepsilon_2$, no guarantee is made; the test may accept or reject. Note. In the i.i.d. case, all coordinates $i \\in [n]$ have the same true mismatch rate, so pooling over $S$ is valid. Matching bases occur with probability $1/2$ independently per coordinate; the constants above already account (via Chernoff-Hoeffding bounds) for obtaining enough matches with high probability.\nThat completes the ‚Äúeasy‚Äù i.i.d. case. Next, we‚Äôll remove the identical-pair assumption.\nMedium case (independent, non-identical pairs) Here the joint state is a product of possibly different single-pair states $$ \\varrho = \\rho_{1}\\otimes\\rho_{2}\\otimes\\dots\\otimes\\rho_{n}, \\quad \\text{vs. } ~ \\Phi^{\\otimes n}. $$ with no entanglement across copies but with potentially different single-pair states $\\rho_i$. In the context of BB84, each copy is attacked ‚Äúfrom scratch‚Äù (no cross-round entanglement) but Eve may prepare a different state in every round.\nExactly as before, we want a single classical test that, with failure probability at most $\\alpha$, distinguishes $$ \\begin{cases} ~\\text{H}_0\\text{ (‚Äúclose‚Äù)} \u0026: D_n \\leq \\varepsilon_1,\\\\[6pt] ~\\text{H}_1\\text{ (‚Äúfar‚Äù)} \u0026: D_n \\geq \\varepsilon_2, \\end{cases} \\qquad 0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1, $$ where $D_n := D(\\rho_1 \\otimes \\dots \\otimes \\rho_n, \\Phi^{\\otimes n})$.\nFor each coordinate $i$ (i.e. each position in the $n$-tuple of pairs), let $$ \\delta_i := \\Pr[\\text{mismatch} \\mid \\text{matching bases on coordinate } i] $$ be the true mismatch probability for that coordinate, and let $$ \\hat{\\delta}_i := \\frac{\\#\\{\\text{mismatches on coordinate } i\\}}{\\#\\{\\text{matching-basis trials on coordinate } i\\}} $$ be its empirical mismatch rate from the data.\nIn the easy case, all $\\delta_i$ are identical because of the i.i.d. assumption. So pooling all matching-basis trials into a single $\\hat{\\delta}$ is equivalent to estimating $\\delta_i$ for any $i$. And as we‚Äôve seen, we only need one concentration bound.\nHowever, for our medium (independent, non-identical) case, the $\\delta_i$ may differ. To certify all coordinates simultaneously, we need to guarantee that $|\\hat{\\delta}_i - \\delta_i|$ is small for every $i$. This unfortunately forces us to run the test on each coordinate separately and then take a union bound over the $n$ coordinates, and we‚Äôll soon see that this adds an extra $n \\log n$ factor in the sample complexity on top of the easy case.\nLet‚Äôs get started. First, we organise repeated i.i.d. copies of the entire $n$-tuple into blocks using the definition from near the very beginning of this post. As a reminder, in the context of the medium case, a block is one i.i.d. copy of the global product state $\\varrho$. Note that in the medium case (in fact, for all three cases) we are still given i.i.d. copies of $$ \\varrho = \\rho_1 \\otimes \\rho_2 \\otimes \\cdots \\otimes \\rho_n, $$ but within $\\varrho$, the individual $\\rho_i$ may be different.\nAfter preparing a block, we make independent calls to the single-pair oracle $\\mathbb{O}$ on each coordinate $i = 1, \\dots, n$. The block then outputs $$ \\bigl\\{ (M_{(j, i)},\\,Y_{(j, i)}) \\bigr\\}_{i=1}^n, $$ where $j$ indexes the block. Explicitly, in block $j$ we obtain for each coordinate $i$:\na matching indicator $M_{(j, i)} \\in \\{0, 1\\}$, which is $1$ if Alice‚Äôs and Bob‚Äôs bases matched for that pair; and, if $M_{(j, i)} = 1$, a mismatch bit $Y_{(j, i)} \\in \\{0, 1\\}$ with $\\mathbb{E}[Y_{(j,i)} \\mid M_{(j,i)} = 1] = \\delta_i$. We repeat this procedure over $N$ independent blocks. The entire dataset forms an $N \\times n$ table: $$ \\begin{array}{c|cccc} \\text{block } j \u0026 i=1 \u0026 i=2 \u0026 \\cdots \u0026 i=n \\\\ \\hline 1 \u0026 (M_{(1,1)}, Y_{(1,1)}) \u0026 (M_{(1,2)}, Y_{(1,2)}) \u0026 \\cdots \u0026 (M_{(1,n)}, Y_{(1,n)}) \\\\ 2 \u0026 (M_{(2,1)}, Y_{(2,1)}) \u0026 (M_{(2,2)}, Y_{(2,2)}) \u0026 \\cdots \u0026 (M_{(2,n)}, Y_{(2,n)}) \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ N \u0026 (M_{(N,1)}, Y_{(N,1)}) \u0026 (M_{(N,2)}, Y_{(N,2)}) \u0026 \\cdots \u0026 (M_{(N,n)}, Y_{(N,n)}) \\end{array} $$where each cell comes from a single call to $\\mathbb{O}(\\rho_i)$. In total, we have made $T = n \\cdot N$ calls to the oracle. In this table:\nRows (fixed $j$): contain all $n$ coordinates in the same block, prepared together as one copy of $\\varrho$. The $\\rho_i$ can be different, so entries in the same row are generally not identically distributed. Columns (fixed $i$): contain the same coordinate across $N$ i.i.d. blocks. These entries are i.i.d. samples from $\\rho_i$, since each block contains a fresh copy of it in position $i$. Therefore, when analysing each coordinate ($i$) separately, the $N$ entries in a column are independent and identically distributed. The union bound will later account for all $n$ coordinates at once.\nA pipeline for the decision rule For our decision rule, we must reason directly with the product fidelity $$ F_n^2 ~=~ \\prod_{i=1}^n F_i^2, $$ since this is what determines the global trace distance in $\\mathbf{H_0}$ and $\\mathbf{H_1}$. Any aggregate statistic of the per-coordinate error rates (such as $\\max_i\\hat\\delta_i$ or an average) can misclassify states: even if one coordinate has a relatively large mismatch rate $\\delta_i$ (and thus a lower $F_i$), the remaining coordinates may have fidelities close to $1$, so that the product fidelity $F_n$ still satisfies the global acceptance condition. In this case, a per‚Äêcoordinate max rule would incorrectly reject such a state. To align the test with the global criterion, we instead construct upper confidence bounds $U_i$ such that, with high probability, $\\delta_i \\leq U_i$ for all $i$ simultaneously. These bounds give $$ F_i^2 ~\\geq~ 1 - 2U_i $$ and hence a lower confidence bound on the product fidelity, $$ \\widehat{F}_{\\text{LCB}}^{\\,2} := \\prod_{i=1}^n (1 - 2U_i) ~\\leq~ F_n^2. $$We then accept iff $\\widehat{F}_{\\text{LCB}}^{\\,2}$ exceeds a threshold, so the decision rule targets the global fidelity condition directly.\nIn short, we would first establish a per-coordinate UCB on $\\delta_i$, use that to establish a LCB on the global fidelity $F_n$, then we can derive a decision rule. Let‚Äôs break down the pipeline step by step.\nPer-coordinate UCB on $\\delta_i$ For each coordinate $i \\in [n]$, define the matching-basis index set across blocks (columns) $$ S_i := \\{\\, j \\in [N] : M_{(j, i)} = 1 \\,\\}. $$The empirical mismatch rate on coordinate $i$ is $$ \\hat\\delta_i ~=~ \\frac{1}{|S_i|} \\sum_{j \\in S_i} Y_{(j, i)} \\quad\\text{(defined when }|S_i| \u003e 0\\text{)}. $$Recall the per-coordinate true error rate $\\delta_i = \\Pr[Y = 1 \\mid M = 1]$.\nThe random variables $\\{Y_{(j,i)}\\}_{j\\in S_i}$ are i.i.d. Bernoulli with mean $\\delta_i$. For any $t \u003e 0$, we have the one-sided Hoeffding bound $$ \\Pr\\!\\left[\\delta_i - \\hat\\delta_i \\geq t\\right] \\leq e^{-2|S_i|t^2}. $$Compared to the two-sided Hoeffding bound used earlier, the absolute value on the left-hand side has been dropped. Intuitively, the two-sided version accounts for both deviations above and below the mean, each equally likely, which introduces the extra factor of $2$ in front of the exponential. In the one-sided case, we only consider one direction of deviation, so this factor disappears.\nTo turn the Hoeffding bound into a high-confidence margin, we pick $t$ so that the bad event $\\delta_i \u003e \\hat{\\delta}_i + t$ occurs with probability at most a chosen budget $\\beta$: $$ e^{-2|S_i|t^2} \\leq \\beta. $$Taking logarithms and rearranging gives $$ t^2 \\geq \\frac{\\ln(1/\\beta)}{2|S_i|} \\quad\\implies\\quad t \\geq \\sqrt{\\frac{\\ln(1/\\beta)}{2|S_i|}}. $$Since $|S_i|$ can be different for each coordinate, the margin for $t$ will in general depend on $i$. Therefore, we write it as $t_i$. In practice, choosing $t_i$ larger than necessary would make the bound looser by increasing the UCB $U_i$. To keep the bound as tight as possible, we take the smallest $t_i$ that satisfies the inequality (i.e. set it by taking the equality) and set $$ t_i = \\sqrt{\\frac{\\ln(1/\\beta)}{2|S_i|}}. $$This choice guarantees that $$ \\Pr[\\delta_i \u003e \\hat{\\delta}_i + t_i] \\leq \\beta $$ for the given coordinate $i$.\nBy the union bound, for any events $E_1, \\dots, E_n$, $$ \\Pr\\!\\left[ ~\\bigcup_{i = 1}^{n} E_i~ \\right] ~\\leq~ \\sum_{i = 1}^n \\Pr[E_i]. $$ In our context, we want all $n$ coordinates to have valid upper bounds simultaneously. Let $E_i$ be the event that the UCB for coordinate $i$ fails, $$ E_i := \\left\\{\\delta_i \u003e \\hat{\\delta}_i + t_i\\right\\}, $$ applying the union bound gives $$ \\Pr\\!\\left[\\,\\exists i: \\delta_i \u003e \\hat\\delta_i + t_i\\,\\right] ~\\leq~ \\sum_{i=1}^n \\Pr[\\delta_i \u003e \\hat\\delta_i + t_i]. $$In words: the probability that at least one coordinate‚Äôs bound fails is no more than the sum of the individual failure probabilities.\nIf each coordinate‚Äôs bound fails with probability at most $\\beta$, then by the union bound the probability that any coordinate‚Äôs bound fails is at most $n\\beta$. If (by choice) we allocate half of the total error budget $\\alpha$ to this step, then we require $$ n\\beta \\leq \\frac{\\alpha}{2} \\quad\\implies\\quad \\beta \\leq \\frac{\\alpha}{2n}. $$Substituting this $\\beta$ into the expression for $t_i$ gives $$ t_i = \\sqrt{\\frac{\\ln(1/\\beta)}{2|S_i|}} = \\sqrt{\\frac{\\ln\\!\\left(\\frac{2n}{\\alpha}\\right)}{2|S_i|}}. $$From the one-sided Hoeffding bound earlier, we can construct a valid UCB on $\\delta_i$ by taking the empirical rate and adding the margin: $$ U_i := \\hat\\delta_i + t_i. $$To enforce our relabeling convention $\\delta_i \\in [0, \\tfrac{1}{2}]$, we take $$ U_i := \\min\\left\\{ \\tfrac{1}{2}, \\hat\\delta_i + t_i \\right\\}. $$ This cap at $\\tfrac{1}{2}$ reflects our per-basis relabeling convention: for each basis, we flip Bob‚Äôs outcomes if necessary so that the mismatch probability is at most $\\tfrac{1}{2}$; values above $\\tfrac{1}{2}$ are operationally equivalent to their complement and therefore replaced by $\\tfrac{1}{2}$.\nTherefore, for all coordinates $i \\in [n]$, we have established a upper confidence bound on the per-coordinate true error rate $\\delta_i$, and by the union bound all $n$ inequalities $\\delta_i \\leq U_i$ hold simultaneously with probability at least $1 - \\tfrac{\\alpha}{2}$. Let‚Äôs now translate this into a lower confidence bound on the global fidelity.\nLCB on the global fidelity $F_n$ By the single-pair fidelity-error relation, for each coordinate $i \\in [N]$ we have $$ F(\\rho_i, \\Phi) \\geq \\sqrt{1 - 2\\delta_i}. $$Squaring both sides and substituting the upper confidence bound $U_i$ for $\\delta_i$ yields $$ F(\\rho_i, \\Phi)^2 \\geq 1 - 2\\delta_i \\geq 1 - 2U_i. $$Multiplying over all coordinates, $$ F(\\varrho, \\Phi^{\\otimes n})^2 ~=~ \\prod_{i=1}^n F(\\rho_i, \\Phi)^2 ~\\geq~ \\prod_{i=1}^n \\bigl(1 - 2U_i\\bigr). $$We define the lower confidence bound (LCB) on the global fidelity as $$ \\widehat{F}_{\\text{LCB}}^{\\,2} := \\prod_{i=1}^n \\bigl(1 - 2U_i\\bigr), $$ which is non-negative by construction, since $U_i \\leq \\tfrac{1}{2}$ from our definition.\nTherefore, from the union bound construction above, all $n$ inequalities $\\delta_i \\leq U_i$ hold simultaneously with probability at least $1 - \\tfrac{\\alpha}{2}$. On this event, $$ \\widehat{F}_{\\text{LCB}}^{\\,2} \\leq F(\\varrho, \\Phi^{\\otimes n})^2, $$so $\\widehat{F}_{\\text{LCB}}^{\\,2}$ is a valid lower confidence bound on the global fidelity $F_n^2$ with probability at least $1 - \\tfrac{\\alpha}{2}$.\n(In the final theorem, this will combine with the separate high-probability guarantee from the ‚Äúenough matches‚Äù step to give an overall probability of at least $1 - \\alpha$.)\nWith this LCB on the global fidelity established, we now need to define a decision rule for the test.\nDecision rule and correctness proof Define the cutoff $$ \\tau := 1 - \\frac{\\varepsilon_1^2 + \\varepsilon_2^2}{2}. $$ Then we accept iff $\\widehat{F}_{\\text{LCB}}^{\\,2} \\geq \\tau$:\n$$ \\textbf{Decision rule (medium case)} = \\begin{cases} \\text{‚Äúclose‚Äù} \u0026 \\text{if } \\widehat{F}_{\\text{LCB}}^{\\,2} \\geq \\tau,\\\\[4pt] \\text{‚Äúfar‚Äù} \u0026 \\text{if } \\widehat{F}_{\\text{LCB}}^{\\,2} \u003c \\tau. \\end{cases} $$ We need to prove the correctness of our decision rule, conditioned on the good event $\\mathcal{G}$. Correctness includes completeness (close $\\Rightarrow$ accept) and soundness (far $\\Rightarrow$ reject). But before we get into that, what exactly is the good event in the medium case?\n[write what the good event is]\nAfter this line, everything below is not fully correct\nAs in the i.i.d. case, define the function $$ f(\\varepsilon) := \\tfrac{1}{2}\\!\\left[1 - (1 - \\varepsilon^2)^{1/n}\\right], $$ the thresholds $$ \\delta_{\\text{close}} := f(\\varepsilon_1), \\quad \\delta_{\\text{far}} := f(\\varepsilon_2), $$ the (midpoint) cutoff $$ \\kappa := \\tfrac{1}{2}(\\delta_{\\text{close}} + \\delta_{\\text{far}}), $$ and set the margin $$ t := \\tfrac{1}{2}(\\delta_{\\text{far}} - \\delta_{\\text{close}}). $$ (As before, $\\delta_{\\text{far}} - \\delta_{\\text{close}} = \\Delta_\\delta \\geq \\frac{\\varepsilon_2^2-\\varepsilon_1^2}{2n}$.)\n$$ \\textbf{Decision rule (medium case)} = \\begin{cases} \\text{‚Äúclose‚Äù} \u0026 \\text{if } \\max_{i \\in [n]} \\hat\\delta_i \u003c \\kappa,\\\\ \\text{‚Äúfar‚Äù} \u0026 \\text{if } \\max_{i \\in [n]} \\hat\\delta_i \\geq \\kappa. \\end{cases} $$ In other words, we accept if and only if the worst-case error rate is strictly less than our cutoff $\\kappa$, meaning all our error rates $\\hat\\delta_i$ has to pass the cutoff test.\nDefine the good event $$ \\mathcal G ~:=~ \\bigcap_{i=1}^n \\left\\{\\,|\\hat\\delta_i - \\delta_i| \u003c t\\,\\right\\}, $$ i.e. every column concentrates within the margin $t$. We will set the number of blocks $N$ so that $\\Pr[\\mathcal G] \\geq 1 - \\alpha$ using concentration bounds.\nLet‚Äôs quickly show completeness and soundness of our decision rule.\nCompleteness (close $\\Rightarrow$ accept). If every coordinate is close i.e. $\\delta_i \\leq \\delta_{\\text{close}}$ for all $i$, then on the good event $\\mathcal{G}$, $$ \\hat\\delta_i \u003c \\delta_i + t ~\\le~ \\delta_{\\text{close}} + t ~=~ \\kappa \\quad\\implies\\quad \\max_i \\hat\\delta_i \u003c \\kappa, $$ so we accept.\nSoundness (far $\\Rightarrow$ reject). This requires some work. If the global state $\\varrho = \\otimes_{i=1}^n \\rho_i$ is far i.e. $D(\\varrho, \\Phi^{\\otimes n}) \\geq \\varepsilon_2$, then by the (right-hand) Fuchs‚Äìvan de Graaf inequality, the global fidelity, $F_n$, satisfies $$ F_n := F(\\varrho, \\Phi^{\\otimes n}) \\leq \\sqrt{1 - \\varepsilon_2^2}. $$ Fidelity is multiplicative even for heterogeneous products: $$ F_n = \\prod_{i=1}^n F_i, \\quad\\text{where } F_i := F(\\rho_i,\\Phi). $$ Let $\\tau := (1 - \\varepsilon_2^2)^{1/(2n)}$, so $\\tau^n = \\sqrt{1 - \\varepsilon_2^2}$. If every coordinate satisfied $F_i \u003e \\tau$, then $$ F_n ~=~ \\prod_{i=1}^n F_i ~\u003e~ \\tau^n ~=~ \\sqrt{1 - \\varepsilon_2^2}, $$ contradicting the bound for $F_n$ above. Therefore, there has to exist some coordinate $i^\\star$ with $$ F_{i^\\star} ~\\leq~ \\tau ~=~ (1 - \\varepsilon_2^2)^{1/(2n)}. $$ Now use the single-pair link $F_i \\geq \\sqrt{1 - 2\\delta_i}$ from the lemma above. Rearranging $$ 1 - 2\\delta_{i^\\star} ~\\leq~ F_{i^\\star}^2 ~\\leq~ \\tau^2 = (1 - \\varepsilon_2^2)^{1/n} $$ gives $$ \\delta_{i^\\star} ~\\geq~ \\frac{1 - (1 - \\varepsilon_2^2)^{1/n}}{2} ~=~ f(\\varepsilon_2) ~=~ \\delta_{\\text{far}}. $$ On the good event $\\mathcal{G}$, $$ \\hat\\delta_{i^\\star} ~\u003e~ \\delta_{i^\\star} - t ~\\geq~ \\delta_{\\text{far}} - t ~=~ \\kappa, $$ so $$ \\max_i \\hat\\delta_i ~\\geq~ \\hat\\delta_{i^\\star} ~\u003e~ \\kappa, $$ and we reject.\nSo all we owe now is to make the good event $\\mathcal{G}$ hold with probability at least $1 - \\alpha$ using a concentration bound.\nConcentration: all coordinates at once Complete writeup\nTheorem (Finite-sample tolerant EPR identity test, independent, non-identical pairs).\nLet $n \\geq 2$ and suppose the global state is $\\varrho = \\rho_1 \\otimes \\rho_2 \\otimes \\dots \\otimes \\rho_n$ for bipartite states $\\rho_i$. Fix global trace-distance tolerances $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$ and failure probability $\\alpha \\in (0,1)$. Define $$ \\begin{aligned} \u0026f(\\varepsilon) = \\frac{1}{2}\\!\\left[1 - (1 - \\varepsilon^2)^{1/n}\\right], \u0026 \u0026 \\delta_{\\text{close}} = f(\\varepsilon_1), \\\\[6pt] \u0026\\delta_{\\text{far}} = f(\\varepsilon_2), \u0026 \u0026 \\kappa = \\frac{\\delta_{\\text{close}} + \\delta_{\\text{far}}}{2}. \\end{aligned} $$Protocol. Prepare $N$ (i.i.d.) blocks of $\\varrho$. For each block $j \\in [N]$ and coordinate $i \\in [n]$, make one call to $\\mathbb{O}(\\rho_i)$, obtaining $(M_{(j,i)}, Y_{(j,i)})$. For each coordinate $i$, define $$ S_i := \\{\\, j \\in [N] ~:~ M_{(j,i)} = 1 \\,\\} $$ and compute $$ \\hat{\\delta}_i := \\frac{1}{|S_i|} \\sum_{j \\in S_i} Y_{(j,i)}, $$ where $Y_{(j,i)} \\in \\{0,1\\}$ for all $(j,i) \\in S_i$.\nDecision rule. Accept iff $\\max_{i \\in [n]} \\hat{\\delta}_i \u003c \\kappa$.\nIf $$ N ~~\\geq~~ \\frac{32\\,n^2}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2}\\,\\ln\\!\\frac{4n}{\\alpha}, \\qquad\\left[= O\\!\\left(n^2 \\log n \\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^{-2}\\right)\\right] $$ equivalently, the number of oracle calls, $$ T = n \\cdot N ~~\\geq~~ \\frac{32\\,n^3}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2}\\,\\ln\\!\\frac{4n}{\\alpha}, \\qquad\\left[= O\\!\\left(n^3 \\log n \\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^{-2}\\right)\\right] $$ then the following statements are true:\nCompleteness. If $D(\\bigotimes_{i=1}^n \\rho_i, \\Phi^{\\otimes n}) \\leq \\varepsilon_1$, the test accepts with probability at least $1 - \\alpha$. Soundness. If $D(\\bigotimes_{i=1}^n \\rho_i, \\Phi^{\\otimes n}) \\geq \\varepsilon_2$, the test rejects with probability at least $1 - \\alpha$. Promise gap. If $\\varepsilon_1 \u003c D(\\bigotimes_{i=1}^n \\rho_i, \\Phi^{\\otimes n}) \u003c \\varepsilon_2$, no guarantee is made; the test may accept or reject. Note. In the medium case, the $\\delta_i$ may differ across coordinates, so each $\\hat{\\delta}_i$ must be estimated separately. The union bound over all $n$ coordinates yields the $\\log(n)$ factor in the sample complexity.\n","wordCount":"6784","inLanguage":"en","datePublished":"2025-08-08T17:42:31+01:00","dateModified":"2025-08-08T17:42:31+01:00","author":{"@type":"Person","name":"Howard Cheung"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://teaegg.net/research/urss/n-epr-test/"},"publisher":{"@type":"Organization","name":"ùóßùóòùóî‚Ä¢ùóòùóöùóö","logo":{"@type":"ImageObject","url":"https://teaegg.net/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://teaegg.net/ title=Home>ùóßùóòùóî‚Ä¢ùóòùóöùóö</a><div class=logo-switches><button id=theme-toggle title="Toggle theme" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://teaegg.net/aboutme/ title="About Me"><span>About Me</span></a></li><li><a href=https://teaegg.net/journal/ title=Journal><span>Journal</span></a></li><li><a href=https://teaegg.net/research/ title=Research><span>Research</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://teaegg.net/>üè† Home</a>&nbsp;¬ª&nbsp;<a href=https://teaegg.net/research/>üî¨ Research</a>&nbsp;¬ª&nbsp;<a href=https://teaegg.net/research/urss/>üîêüí° Undergraduate Research Support Scheme (URSS)</a></div><h1 class="post-title entry-hint-parent">Classical tolerant identity test for multiple EPR states</h1><div class=post-meta><span title='2025-08-08 17:42:31 +0100 +0100'>August 8, 2025</span>&nbsp;¬∑&nbsp;32 min&nbsp;¬∑&nbsp;Howard Cheung</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#change-in-notation aria-label="Change in notation">Change in notation</a><ul><li><a href=#single-pair-oracle aria-label="Single-pair oracle $\mathbb{O}(\rho_{AB})$">Single-pair oracle $\mathbb{O}(\rho_{AB})$</a></li><li><a href=#single-pair-protocol-post-processing-over--oracle-calls aria-label="Single-pair protocol (post-processing over $N$ oracle calls)">Single-pair protocol (post-processing over $N$ oracle calls)</a></li></ul></li><li><a href=#do-re-mi- aria-label="do-rE-MI ‚ô´">do-rE-MI ‚ô´</a></li><li><a href=#easy-case-iid-pairs aria-label="Easy case (i.i.d. pairs)">Easy case (i.i.d. pairs)</a><ul><li><a href=#a-na%c3%afve-per-pair-approach-using-trace-distance aria-label="A na√Øve per-pair approach using trace distance">A na√Øve per-pair approach using trace distance</a></li><li><a href=#global-block-test-using-fidelity aria-label="Global block test using fidelity">Global block test using fidelity</a><ul><li><a href=#translating-hypotheses aria-label="Translating hypotheses">Translating hypotheses</a></li><li><a href=#defining-the-error-rate-thresholds aria-label="Defining the error rate thresholds">Defining the error rate thresholds</a></li><li><a href=#bounding-the-promise-gap aria-label="Bounding the promise gap">Bounding the promise gap</a></li><li><a href=#decision-rule-and-sample-complexity aria-label="Decision rule and sample complexity">Decision rule and sample complexity</a></li></ul></li></ul></li><li><a href=#medium-case-independent-non-identical-pairs aria-label="Medium case (independent, non-identical pairs)">Medium case (independent, non-identical pairs)</a><ul><li><a href=#a-pipeline-for-the-decision-rule aria-label="A pipeline for the decision rule">A pipeline for the decision rule</a><ul><li><a href=#per-coordinate-ucb-on aria-label="Per-coordinate UCB on $\delta_i$">Per-coordinate UCB on $\delta_i$</a></li><li><a href=#lcb-on-the-global-fidelity aria-label="LCB on the global fidelity $F_n$">LCB on the global fidelity $F_n$</a></li><li><a href=#decision-rule-and-correctness-proof aria-label="Decision rule and correctness proof">Decision rule and correctness proof</a></li></ul></li><li><a href=#concentration-all-coordinates-at-once aria-label="Concentration: all coordinates at once">Concentration: all coordinates at once</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=change-in-notation>Change in notation<a hidden class=anchor aria-hidden=true href=#change-in-notation>#</a></h2><p>With the <a href=../epr-tolerant-identity-testing>tolerant identity test</a> for a single state $\rho_{AB}$ complete, we now turn to the problem of certifying multiple ($n$) EPR pairs at once. For brevity we write $\Phi = \ket{\text{EPR}}\bra{\text{EPR}}_{AB}$ throughout. The problem statement is as follows:</p><blockquote><p><strong>Problem.</strong></p><p>Given two trace distance tolerances $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$, a failure probability $\alpha \in (0, 1)$, and $N$ i.i.d. copies of an unknown $2n$-qubit global state $\varrho$ on $A^n B^n$ i.e. the source produces $\varrho^{\otimes N}$, how large must $N$ at least be so that, using only local $Z$/$X$ measurements and classical postprocessing, we can decide with at least confidence $1 - \alpha$ whether</p>$$
D\!\left[\,\varrho~,~ \Phi^{\otimes n}\,\right]
$$<p>is small ($\leq \varepsilon_1$) or large ($\geq \varepsilon_2$)?</p></blockquote><blockquote><p><strong>Definition (block).</strong>
A <em>block</em> is one i.i.d. copy of the $2n$-qubit global state $\varrho$, where we label the qubits as $(A_j, B_j)_{j=1}^n$ for convenience. We refer to each pair $(A_j, B_j)$ as a <em>coordinate</em> for convenience.</p></blockquote><p>Before analysing the multi-pair scenario, let&rsquo;s revisit the single-pair case first. It helps to reframe one round of the single-pair matching-outcomes protocol as a callable oracle $\mathbb{O}$ that consumes a fresh pair of $\rho_{AB}$ and outputs a classical bit when the bases match.</p><p>Suppose Alice and Bob share $N$ i.i.d. copies of an unknown pair $\rho_{AB}$. We package one measurement round into a callable <strong>oracle</strong> $\mathbb{O}(\rho_{AB})$ and then do simple classical post-processing. Combining $N$ oracle calls and doing the simple classical post-processing is equivalent to the $N$-round protocol!</p><h3 id=single-pair-oracle>Single-pair oracle $\mathbb{O}(\rho_{AB})$<a hidden class=anchor aria-hidden=true href=#single-pair-oracle>#</a></h3><p><strong>Input:</strong> one fresh pair of the bipartite state $\rho_{AB}$.</p><p><strong>Procedure:</strong></p><ol><li>Pick two independent basis bits $\theta \in \{ 0, 1 \}$ and $\tilde{\theta} \in \{ 0, 1 \}$ uniformly at random. Here $\theta = 0$ means &ldquo;standard basis ($Z$)&rdquo; and $\theta = 1$ means &ldquo;Hadamard basis ($X$)&rdquo;.</li><li>Measure the $A$ subsystem of $\rho_{AB}$ in basis $\theta$ to obtain $x \in \{0, 1\}$ and the $B$ subsystem in basis $\tilde{\theta}$ to obtain $\tilde{x} \in \{0, 1\}$.</li><li>If $\theta = \tilde{\theta}$ (matching bases), set $M = 1$ and $Y = \mathbf{1}[x \neq \tilde x] \in \{0, 1\}$; otherwise $\theta \neq \tilde{\theta}$ (mismatched bases), set $M = 0$ and $Y = \bot$.</li></ol><p><strong>Output:</strong> a pair $(M, Y)$ with $M \in \{0, 1\}$ and $Y \in \{\bot, 0, 1\}$.</p><p>The oracle hides the two-party details: one call consumes one fresh pair $\rho_{AB}$. When it emits a bit (i.e. $Y \neq \bot$), that bit is a Bernoulli trial with mean $\delta$, which is the <em>true</em> matching-basis mismatch probability:</p>$$
\mathbb{E}[\,Y \mid M = 1\,] = \delta \in[0, \tfrac{1}{2}] \quad\text{(after the standard relabelling per basis)}.
$$<p>(We relabel Bob&rsquo;s outcomes per basis so each per-basis mismatch rate is $\leq 1/2$; see the convention below.)</p><p>This oracle $\mathbb{O}$ encapsulates the entire procedure of basis selection, local measurement, and comparison for a single coordinate $(A_j, B_j)$ of a block. A block has $n$ coordinates, we call $\mathbb{O}$ once per coordinate so $n$ times in total (either sequentially or in parallel). We then keep only the calls where the bases matched and do simple classical post-processing (count mismatches). Over $N$ blocks, this amounts to $n \cdot N$ oracle calls in total.</p><blockquote><p><strong>Remark.</strong> &ldquo;Sequential&rdquo; vs &ldquo;parallel&rdquo; only affects implementation. Equivalently one can run many calls (measure many coordinates) in parallel and reveal bases afterwards over a classical channel; the distribution of $(M, Y)$ is identical.</p></blockquote><h3 id=single-pair-protocol-post-processing-over--oracle-calls>Single-pair protocol (post-processing over $N$ oracle calls)<a hidden class=anchor aria-hidden=true href=#single-pair-protocol-post-processing-over--oracle-calls>#</a></h3><p>In our single-pair case, the number of coordinates $n = 1$, so trivially we would call the oracle $N$ times as we&rsquo;re given $N$ blocks.</p><ol><li>Make $N$ independent calls to $\mathbb{O}(\rho_{AB})$. From those $N$ calls we obtain $(M_1, Y_1), \ldots, (M_N, Y_N)$.</li><li>Define the set of matching-basis rounds
$$
S = \bigl\{i \in \{1, \dots, N\} : M_i = 1 \bigr\} \subseteq \bigl\{ 1, \dots, N \bigr\}.
$$
If by rare chance $S = \varnothing$ (no matching bases at all), simply rerun the whole protocol as the probability of $S = \varnothing$ is $2^{-N}$, which is negligible for modest $N$.</li><li>Compute the <strong>observed error rate</strong>
$$
\hat{\delta} = \frac{1}{|S|}\sum_{i\in S} Y_i.
$$
which represents the mismatch fraction conditioned on matching-basis rounds.</li></ol><blockquote><p><strong>Note.</strong> This is exactly equivalent to the usual BB84-style &ldquo;announce bases and outcomes over a classical authenticated channel (CAC) and keep only the matching bases&rdquo; description; we&rsquo;ve just folded that bookkeeping into $(M_i, Y_i)$.</p></blockquote><p>With this, we can provide an alternative but mathematically equivalent tolerant identity test for one EPR state ($n = 1$).</p><blockquote><p><strong>Theorem (Finite-sample classical tolerant identity test for the EPR state).</strong></p><p>Given $N$ (i.i.d.) blocks of $\varrho = \rho_{AB}$, fix two trace-distance tolerances</p>$$
0 \leq \varepsilon_1 < \varepsilon_2 \leq 1,
$$<p>and the desired maximum failure probability $\alpha \in (0, 1)$. Set the cutoff</p>$$
c = \frac{\varepsilon_1^2 + \varepsilon_2^2}{4}.
$$<p>Consider the reformulated matching protocol above where we make $N$ independent calls to $\mathbb{O}(\varrho)$ (one per block), and compute the observed error rate $\hat{\delta}$. For the test, let the decision rule be to accept <em><strong>iff</strong></em> $\hat{\delta} \leq c$:</p>$$
\text{Decision} =
\begin{cases}
\text{‚Äúclose‚Äù}, & \hat{\delta} \leq c,\\
\text{‚Äúfar‚Äù}, & \hat{\delta} > c.
\end{cases}
$$<p>Then if</p>$$
N \geq \frac{32\,\ln(2/\alpha)}{(\varepsilon_2^2 - \varepsilon_1^2)^2} \qquad\left( = O\Bigl((\varepsilon_2^2 - \varepsilon_1^2)^{-2}\Bigr) \right),
$$<p>after running the test, the following holds:</p><ul><li><strong>Completeness.</strong> If $D(\varrho, \Phi) \leq \varepsilon_1$, then the test <strong>accepts</strong> (outputs &ldquo;close&rdquo;) with confidence at least $1 - \alpha$.</li><li><strong>Soundness</strong> If $D(\varrho, \Phi) \geq \varepsilon_2$, then the test <strong>rejects</strong> (outputs &ldquo;far&rdquo;) with confidence at least $1 - \alpha$.</li><li><strong>Promise gap.</strong> If $\varepsilon_1 < D(\varrho, \Phi) < \varepsilon_2$, no guarantee is made on the outcome; the test may go either way (accept or reject).</li></ul></blockquote><p>Note that we call the oracle $N$ times in this case only because $n = 1$. In general $n \geq 2$ so this is not true; the number of oracle calls is $n \cdot N$.</p><p>With the notations established and the single-pair scenario ($n = 1$) as a reference, we now turn to analysing the number of blocks needed to certify multiple EPR pairs for $n \geq 2$ as per the problem statement.</p><hr><h2 id=do-re-mi->do-rE-MI ‚ô´<a hidden class=anchor aria-hidden=true href=#do-re-mi->#</a></h2><p>For brevity we write $\rho = \rho_{AB}$ throughout. In particular, we will show how the same matching-outcomes protocol extends in three settings of increasing generality and difficulty:</p><ol><li><p><strong>Easy (i.i.d. pairs).</strong></p><p>All $n$ pairs are identical:</p>$$
\varrho = \rho^{\otimes n}\quad\text{vs.}\quad\Phi^{\otimes n}.
$$</li><li><p><strong>Medium (independent, non-identical pairs).</strong></p><p>Each pair may differ but remains uncorrelated:</p>$$
\varrho = \rho_1\otimes\rho_2\otimes\dots\otimes\rho_n
\quad\text{vs.}\quad
\Phi^{\otimes n}.
$$</li><li><p><strong>Hard (arbitrary adversary).</strong></p><p>The most general case allows an arbitrary $2n$-qubit state $\varrho$, possibly entangled across pairs, against which we still wish to test closeness to $\Phi^{\otimes n}$.</p></li></ol><p>We will analyse $N$, the number of blocks (i.i.d. copies) of the $2n$-qubit state $\varrho$ required to decide closeness to $\Phi^{\otimes n}$. As we&rsquo;ve seen, each block contains $n$ pairs and therefore induces $n$ calls to the single-pair oracle $\mathbb{O}$ (once per coordinate), so the total number of oracle calls is $n \cdot N$. We state all bounds in terms of the number blocks needed, $N$, as the primary resource, and convert to total oracle calls by multiplying by $n$ when helpful. (The measurement bases match with probability $1/2$ independently per coordinate.)</p><p>Why do we count blocks? This is because the physical source hands us i.i.d. <em>blocks</em> - full $2n$-qubit copies of $\varrho$. Block complexity answers the operational question &ldquo;how many copies of $\varrho$ must we request to decide &lsquo;close&rsquo; vs &lsquo;far&rsquo;?&rdquo;. Inside each block we make $n$ single‚Äëpair measurements (one per coordinate), i.e. $n$ <em>oracle calls</em>, so the total number of calls is $T = n \cdot N$. While oracle‚Äëcall counts are useful for estimating raw measurement time or hardware throughput, <strong>the fundamental resource is the number of i.i.d. copies of $\varrho$</strong>, i.e. the number of blocks $N$.</p><blockquote><p><strong>Note.</strong> In the context of BB84, these three scenarios correspond directly to the class of attacks that an eavesdropper (Eve) might do:</p><ul><li><p><strong>Easy (i.i.d. pairs)</strong>:
Eve applies the same attack channel to each transmitted qubit independently, with no memory from one round to the next. Every round she starts from scratch, so her joint state is $\varrho = \rho^{\otimes n}$.</p></li><li><p><strong>Medium (independent, non-identical pairs)</strong>:
Eve still treats each qubit independently and measures immediately, but she may choose a different attack in each round. Her overall state is the product $\varrho = \rho_{1}\otimes\rho_{2}\otimes\dots\otimes\rho_{n}$.</p></li><li><p><strong>Hard (arbitrary adversary)</strong>:
Eve may entangle her systems across rounds and defer all measurements until the end. There is no tensor-product structure, so her state is an arbitrary $2n$-qubit $\varrho$.</p></li></ul><p>By proving security in each model, starting with the easiest and working up to the fully coherent setting, we obtain a hierarchy of BB84 security guarantees that mirror the increasing power of potential attack by Eve.</p></blockquote><p>We begin with the i.i.d. case as it&rsquo;s both the simplest to analyse and a useful building block for the more challenging scenarios.</p><hr><h2 id=easy-case-iid-pairs>Easy case (i.i.d. pairs)<a hidden class=anchor aria-hidden=true href=#easy-case-iid-pairs>#</a></h2><h3 id=a-na√Øve-per-pair-approach-using-trace-distance>A na√Øve per-pair approach using trace distance<a hidden class=anchor aria-hidden=true href=#a-na√Øve-per-pair-approach-using-trace-distance>#</a></h3><p>A first idea is to ignore the joint state and run the <strong>single-pair</strong> tolerant test on each of the $n$ coordinates <strong>separately</strong>, then accept only if every coordinate passes. Equivalently, one could tally the per-pair/per-coordinate (which is the same under the independent assumption of i.i.d.) mismatch indicators into a total error count and compare that sum against a scaled threshold, thanks to the i.i.d. assumption.</p><p>Let $D_1 = D(\rho, \Phi)$ and $D_n = D(\rho^{\otimes n}, \Phi^{\otimes n})$. By subadditivity,</p>$$
D_n \leq n\,D_1.
$$<p>To guarantee $D_n \leq \varepsilon_1$, it suffices to enforce the <strong>per-pair</strong> condition $D_1 \leq \varepsilon_1/n$. Thus at the per-pair level the tolerances become $\varepsilon_1/n$ vs. $\varepsilon_2/n$. Since the single-pair sample complexity scales like $(\varepsilon_2^2 - \varepsilon_1^2)^{-2}$, replacing $\varepsilon_j \mapsto \varepsilon_j/n$ shrinks the squared gap by $n^2$, and the <strong>per-coordinate</strong> number of <strong>blocks</strong> needed inflates by $n^4$:</p>$$
N_{\text{per-coord}}
~\gtrsim~
\frac{32\,n^4}{(\varepsilon_2^2 - \varepsilon_1^2)^2}\,\ln\!\frac{2}{\alpha}.
$$<p>We need <strong>all $n$ coordinates</strong> to pass simultaneously with total failure probability $\alpha$. A union bound replaces $\alpha$ by $\alpha/n$, contributing an extra $\log n$ factor:</p>$$
N_{\text{na√Øve (blocks)}}
~\gtrsim~
\frac{32\,n^4}{(\varepsilon_2^2 - \varepsilon_1^2)^2}\,\ln\!\frac{2n}{\alpha}.
$$<p><strong>Takeaway.</strong> The na√Øve per-pair route costs $O(n^4\log n)$ blocks, whereas the collective (fidelity-based) test from the next section needs only $O(n)$ blocks (up to the same $(\varepsilon_2^2 - \varepsilon_1^2)^{-2}$ and $\log(1/\alpha)$ factors). The huge gap in our na√Øve method comes from shrinking tolerances by $1/n$ at the per-pair level (which explodes sample size by $n^4$); the union bound adds only the mild $\log n$. At first glance the na√Øve method seems reasonably efficient, but a closer look shows it is actually markedly worse than the collective strategy developed below.</p><p><strong>Remark.</strong> In the easy and medium cases, &ldquo;per-coordinate&rdquo; and &ldquo;per-pair&rdquo; are interchangeable because <strong>within each block</strong> the state <em>factorises across coordinates</em>: easy: $\varrho = \rho^{\otimes n}$; medium: $\varrho = \bigotimes_{i=1}^n \rho_i$. In particular, there is no cross-coordinate entanglement inside a block (pairs may be identical in the easy case and merely different in the medium case). In the hard case, $\varrho$ may be arbitrarily entangled across coordinates, so we use <strong>per-coordinate</strong> language exclusively there to be precise.</p><hr><h3 id=global-block-test-using-fidelity>Global block test using fidelity<a hidden class=anchor aria-hidden=true href=#global-block-test-using-fidelity>#</a></h3><p>Given a global state $\varrho = \rho^{\otimes n}$, for a single pair $\rho$:</p>$$
F_1 ~=~ F(\rho,\Phi),
\quad
D_1 ~=~ D(\rho,\Phi),
$$<p>and in the $n$-pair i.i.d. case we have the rules</p>$$
F_n ~:=~ F\bigl(\rho^{\otimes n},\,\Phi^{\otimes n}\bigr) ~=~ F_1^{n},
\qquad
D_n ~:=~ D\bigl(\rho^{\otimes n},\,\Phi^{\otimes n}\bigr) ~\leq~ n\,D_1.
$$<p>This means we can express the $n$-pair (block) closeness conditions entirely in terms of the single-pair fidelity $F_1$, thanks to the exact tensor-product multiplicativity rule $F(\rho^{\otimes n},\Phi^{\otimes n}) = F(\rho,\Phi)^n$ (or equivalently $F_n = F_1^n$). Working directly with fidelity avoids the looser trace-distance bound $D(\rho^{\otimes n},\Phi^{\otimes n}) \leq n\,D(\rho,\Phi)$, which would give a much weaker bound than the tight scaling we get from fidelity.</p><h4 id=translating-hypotheses>Translating hypotheses<a hidden class=anchor aria-hidden=true href=#translating-hypotheses>#</a></h4><p>Our goal is to distinguish</p>$$
\begin{cases}
~\mathbf{H_0}: &D_n \,\leq\,\varepsilon_1
\quad\iff\quad \rho^{\otimes n}\text{ is ‚Äúclose‚Äù to }\Phi^{\otimes n},\\[6pt]
~\mathbf{H_1}: &D_n \,\geq\,\varepsilon_2
\quad\iff\quad \rho^{\otimes n}\text{ is ‚Äúfar‚Äù from }\Phi^{\otimes n},
\end{cases}
$$<p>with $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$. By Fuchs‚Äìvan de Graaf,</p>$$
1 - F_n ~\leq~ D_n ~\leq~ \sqrt{1 - F_n^{2}},
$$<p>so controlling $F_n$ tightly leads to a corresponding control on $D_n$. Since $F_n = F_1^{n}$, we can use this and the upper bound of Fuchs‚Äìvan de Graaf to rewrite the hypotheses as fidelity conditions per-pair:</p>$$
\begin{cases}
~\mathbf{H_0}: \quad &D_n \,\leq\,\varepsilon_1 &\impliedby &F_n^2 ~\geq~ 1 - \varepsilon_1^2
&\iff
&F_1 ~\geq~ (1 - \varepsilon_1^2)^{1/(2n)}
\\[4pt]
~\mathbf{H_1}: \quad &D_n \,\geq\,\varepsilon_2 &\implies &F_n^2 ~\leq~ 1 - \varepsilon_2^2
&\iff
&F_1 ~\leq~ (1 - \varepsilon_2^2)^{1/(2n)}
\end{cases}\quad.
$$<p>You might be wondering why we need a <u>sufficient</u> condition for $\mathbf{H_0}$ and a <u>necessary</u> condition for $\mathbf{H_1}$. This is because we need to guarantee that accepted states are truly close (requiring a sufficient condition) and that far states are rejected (requiring a necessary condition) to prevent <strong>false accepts</strong>.</p><ul><li><p><strong>Soundness of acceptance (Accept $\Rightarrow$ Close; avoid false accepts).</strong>
Why do we use a &ldquo;sufficient&rdquo; $F\!\to\!D$ direction? We want &ldquo;if the test accepts, the global state is close&rdquo;, i.e. no false accept. That needs an <em>upper</em> bound on distance from fidelity, which comes from the <em>right-hand</em> FvG:</p>$$
D_n \leq \sqrt{1 - F_n^2}.
$$<p>So we enforce $F_n \geq \sqrt{1 - \varepsilon_1^2}$ (equivalently $F_1 \geq (1 - \varepsilon_1^2)^{1/(2n)}$), which <em>forces</em> $D_n \leq \varepsilon_1$.
If instead you used the left-hand side $1 - F_n \leq D_n$ with a threshold $F_n \geq 1-\varepsilon_1$, you could falsely accept a far state. Example: take $\varepsilon_1 = 0.1$ and a state with $F_n = 0.90$. The right-hand FvG still allows $D_n$ to be as high as $\sqrt{1 - 0.9^2} \approx 0.436 > 0.1$, so the state could be far from the target yet would be accepted by this flawed rule.</p></li><li><p><strong>Soundness of rejection (Far $\Rightarrow$ Reject; again avoid false accepts).</strong>
Why do we use a &ldquo;necessary&rdquo; $D\!\to\!F$ direction? We want every far state to be rejected, i.e. no false accept. We start from &ldquo;far $\Rightarrow$ small fidelity&rdquo;, and again consider the <em>right-hand</em> FvG:</p>$$
D_n \geq \varepsilon_2 \implies F_n \leq \sqrt{1 - \varepsilon_2^2}.
$$<p>Together with $\sqrt{1 - 2\delta} \leq F_1$, this yields $\delta \geq \delta_{\text{far}} = \frac{1}{2}[1 - (1 - \varepsilon_2^2)^{1/n}]$. Any simpler rule like &ldquo;reject if $F_n \leq \tau$&rdquo; with $\tau < \sqrt{1 - \varepsilon_2^2}$ will falsely accept some far states. Example: $\varepsilon_2 = 0.8 \implies \sqrt{1 - \varepsilon_2^2} = 0.6$; a state with $F_n = 0.55$ has $D_n = \sqrt{1 - 0.55^2} \approx 0.835 > \varepsilon_2$ yet would be accepted by $\tau = 0.4$.</p></li></ul><p><strong>What about completeness?</strong> We will soon see that the proof for completeness (avoiding <strong>false rejects</strong> of close states) is not a <em>deterministic</em> guarantee, but a <em>statistical</em> one. It&rsquo;s the promise that if you are given a good state, your experiment will correctly identify it with very high confidence $1 - \alpha$. This guarantee comes from the power of the Chernoff-Hoeffding concentration bound, and we will see the full reasoning below.</p><blockquote><p><strong>Remark.</strong> You might notice that this explicit discussion of sufficient and necessary conditions was not needed for the single-pair test. This is because the single-pair proof is more direct - in that case, the Asymptotic EPR Identity Bound ($\delta \geq \varepsilon^2/2$) provides a single powerful link between the trace distance $\varepsilon$ and the error rate $\delta$, without needing to use fidelity as an intermediary, so it implicitly contains both the necessary and sufficient logic needed to construct the test. In contrast, the multi-pair proof uses the asymmetric Fuchs-van de Graaf inequalities, forcing us to explicitly analyse the logical direction for each guarantee.</p></blockquote><p>Let&rsquo;s quickly verify that $F_n^2 \geq 1 - \varepsilon_1^2$ is a sufficient condition for $D_n \leq \varepsilon_1$ ($\mathbf{H_0}$):</p>$$
F_n^2 \geq 1 - \varepsilon_1^2 \quad\iff\quad 1 - F_n^2 \leq \varepsilon_1^2
$$<p>by rearranging. Substituting this into the upper bound of Fuchs‚Äìvan de Graaf yields</p>$$
D_n ~\leq~ \sqrt{1 - F_n^2} ~\leq~ \sqrt{\varepsilon_1^2} ~=~ \varepsilon_1
$$<p>so indeed $[F_n^2 \geq 1 - \varepsilon_1^2] \implies [D_n \leq \varepsilon_1]$. Similarly we can verify that $F_n^2 \leq 1 - \varepsilon_2^2$ is a necessary condition for $D_n \geq \varepsilon_2$ ($\mathbf{H_1}$) by plugging $\mathbf{H_1}$ into the upper bound of Fuchs‚Äìvan de Graaf:</p>$$
\varepsilon_2 \leq D_n \quad\implies\quad \varepsilon_2 ~\leq~ D_n ~\leq~ \sqrt{1 - F_n^2}.
$$<p>Rearranging</p>$$
\varepsilon_2 \leq \sqrt{1 - F_n^2} \quad\iff\quad F_n^2 \leq 1 - \varepsilon_2^2
$$<p>immediately shows that $[D_n \geq \varepsilon_2] \implies [F_n^2 \leq 1 - \varepsilon_2^2]$ as required.</p><h4 id=defining-the-error-rate-thresholds>Defining the error rate thresholds<a hidden class=anchor aria-hidden=true href=#defining-the-error-rate-thresholds>#</a></h4><p><strong>Lemma (single-pair oracle asymptotic link).</strong> For one call to $\mathbb{O}(\rho_{AB})$, with $\delta = \Pr[Y = 1 \mid M = 1]$, we have $F(\rho_{AB}, \Phi) \geq \sqrt{1 - 2\delta}$.</p><p><strong>Proof sketch.</strong> This lemma is a direct consequence of the Asymptotic EPR Identity Bound established in the single-pair analysis. Since the oracle $\mathbb{O}(\rho_{AB})$ is simply a procedural reframing of a single round of that protocol, the fundamental relationship between the true error rate $\delta$ and the fidelity $F$ remains unchanged. $\quad\square$</p><p>Using this lemma directly, the link between fidelity $F_1$ and true error rate $\delta$ is</p>$$
F_1 \geq \sqrt{1 - 2\delta} \quad\iff\quad \delta \geq \frac{1 - F_1^2}{2}.
$$<p>We will use this relation to define thresholds on $\delta$.</p><blockquote><p><strong>Convention.</strong> For each basis, we relabel Bob&rsquo;s outcomes if needed so the mismatch rate is $\leq 1/2$ (i.e. replace $\delta_b$ by $\min \{\delta_b, 1 - \delta_b\}$). With this standard symmetrisation, the aggregated $\delta \in [0, 1/2]$ and the bound $F_1 \geq \sqrt{1 - 2\delta}$ is always meaningful.</p></blockquote><p>Concretely, let</p>$$
f(\varepsilon) := \frac{1 - (1 - \varepsilon^2)^{1/n}}{2},
$$<p>and</p>$$
\qquad \delta_{\text{close}} := \frac{1 - (1 - \varepsilon_1^2)^{1/n}}{2} = f(\varepsilon_1),
\qquad \delta_{\text{far}} := \frac{1 - (1 - \varepsilon_2^2)^{1/n}}{2} = f(\varepsilon_2).
$$<p>These choices are justified as follows:</p><ul><li><p>(<strong>Close</strong>) If $\delta \leq \delta_{\text{close}}$, then $F_1 \geq \sqrt{1 - 2\delta} \geq \sqrt{1-2\delta_{\text{close}}}$, hence</p>$$
F_n \geq (1 - 2\delta_{\text{close}})^{n/2} = \sqrt{1 - \varepsilon_1^{2}},
$$<p>so from above $D_n \leq \varepsilon_1$.</p></li><li><p>(<strong>Far</strong>) If $D_n \geq \varepsilon_2$, then $F_n \leq \sqrt{1 - \varepsilon_2^{2}}$, i.e. $F_1 \leq (1 - \varepsilon_2^{2})^{1/(2n)}$. Combining with $\sqrt{1 - 2\delta} \leq F_1$ forces</p>$$
1 - 2\delta \leq (1 - \varepsilon_2^{2})^{1/n} \quad\implies\quad \delta \geq \delta_{\text{far}}.
$$</li></ul><h4 id=bounding-the-promise-gap>Bounding the promise gap<a hidden class=anchor aria-hidden=true href=#bounding-the-promise-gap>#</a></h4><p>The promise gap in $\delta$ is</p>$$
\Delta_{\delta} ~=~ \delta_{\text{far}} - \delta_{\text{close}} ~=~ f(\varepsilon_2) - f(\varepsilon_1).
$$<p>To get a lower bound on the promise gap, we first note that</p>$$
f(\varepsilon) = \frac{1 - (1 - \varepsilon^2)^{1/n}}{2}
$$<p>is continuous on $[0, 1]$ for any $n \geq 2$; we only consider $n \geq 2$ since $n$ is the number of EPR pairs and so $n = 1$ reduces to the single-pair test. Indeed, $f$ is built by composing several maps on $[0, 1]$:</p><ul><li>$\varepsilon \mapsto \varepsilon^2$ (continuous),</li><li>$x \mapsto 1 - x$ (continuous),</li><li>$y \mapsto y^{1/n}$ (continuous for $y \geq 0$).</li></ul><p>Each of these components is continuous on the domain $[0, 1]$. Hence their composition, $f$, is also continuous on the closed interval $[0, 1]$.</p><p>By the fundamental theorem of calculus,</p>$$
\Delta_\delta
= f(\varepsilon_2)-f(\varepsilon_1)
= \int_{\varepsilon_1}^{\varepsilon_2} f'(\varepsilon)\,d\varepsilon.
$$<p>For $n\ge2$, differentiating $f(\varepsilon)$ gives</p>$$
f'(\varepsilon) = \frac{\varepsilon}{n}(1 - \varepsilon^2)^{\frac{1}{n} - 1}.
$$<p>Since $0 \leq \varepsilon < 1$ implies $1 - \varepsilon^2 \in (0, 1]$ and $\frac{1}{n} - 1 \leq 0$ as $n \geq 2$, we have</p>$$
(1 - \varepsilon^2)^{\frac{1}{n} - 1} \geq 1 \qquad\left[\,\forall \varepsilon \in [0, 1)\,\right].
$$<p>Multiplying through by $\varepsilon/n$ we get</p>$$
f'(\varepsilon) \geq \frac{\varepsilon}{n}.
$$<p>Therefore,</p>$$
\Delta_\delta = \int_{\varepsilon_1}^{\varepsilon_2} f'(\varepsilon)\,d\varepsilon
~\geq~ \int_{\varepsilon_1}^{\varepsilon_2}\frac{\varepsilon}{n}\,d\varepsilon
=\frac{\varepsilon_2^2 - \varepsilon_1^2}{2n}.
$$<p>Taking $\varepsilon_2\to 1^{-}$ (and using continuity of $f$) shows the same bound holds when $\varepsilon_2 = 1$. Hence, for all $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$,</p>$$
\Delta_\delta \geq \frac{\varepsilon_2^2 - \varepsilon_1^2}{2n}.
$$<blockquote><p><strong>Note.</strong> At $\varepsilon=1$, the factor $(1 - \varepsilon^2)^{\frac{1}{n} - 1}$ diverges (for $n > 2$), which only strengthens $(1 - \varepsilon^2)^{\frac{1}{n} - 1} \geq 1$ and $f'(\varepsilon) \geq \varepsilon/n$. The integral is interpreted as a limit <em>from below</em> when the upper limit is $1$.</p></blockquote><h4 id=decision-rule-and-sample-complexity>Decision rule and sample complexity<a hidden class=anchor aria-hidden=true href=#decision-rule-and-sample-complexity>#</a></h4><p>Define a margin</p>$$
t := \frac{\Delta_{\delta}}{2} = \frac{\delta_{\text{far}} - \delta_{\text{close}}}{2}.
$$<p>Pick a single cutoff inside the gap (the midpoint):</p>$$
\kappa := \frac{\delta_{\text{close}} + \delta_{\text{far}}}{2} = \frac{f(\varepsilon_1) + f(\varepsilon_2)}{2}.
$$<p>In the easy (i.i.d.) case the true mismatch rate is identical across coordinates, so we <strong>pool</strong> all matching‚Äëbasis trials across all coordinates and blocks; let $S$ denote the set of all matching‚Äëbasis indices among the total $T = n \cdot N$ calls.</p><p>After running the protocol and computing the empirical mismatch rate $\hat\delta$ on the matching-basis rounds $S$, we define the decision rule as</p><blockquote>$$
\textbf{Decision rule (easy case)} =
\begin{cases}
\text{‚Äúclose‚Äù} & \text{if } \hat\delta \leq \kappa,\\
\text{‚Äúfar‚Äù} & \text{if } \hat\delta > \kappa.
\end{cases}
$$</blockquote><p>On matching-basis rounds, the indicators $\{ Y_i \}_{i \in S}$ are i.i.d. Bernoulli random variables with mean $\delta$. Chernoff‚ÄìHoeffding gives, for any $t > 0$,</p>$$
\Pr\!\left[|\hat\delta - \delta| \geq t\right] \leq 2e^{-2|S|t^2}.
$$<ul><li><p><strong>Completeness</strong> ($\delta \leq \delta_{\text{close}}$):
If the <em>good</em> event $|\hat\delta - \delta| < t$ holds, then
$\hat\delta \leq \delta_{\text{close}} + t = \kappa \Rightarrow$ accept.</p></li><li><p><strong>Soundness</strong> ($\delta \geq \delta_{\text{far}}$):
If $|\hat\delta-\delta| < t$, then
$\hat\delta > \delta_{\text{far}} - t = \kappa \Rightarrow$ reject.</p></li></ul><p>Therefore, each error (completeness or soundness) occurs only if $|\hat\delta-\delta|\geq t$ (the bad event). To make this probability $\leq \alpha$, it suffices that</p>$$
2e^{-2|S|t^2} \leq \alpha
\quad\iff\quad
|S| \geq \frac{2}{\Delta_\delta^{2}}\,\ln\!\frac{2}{\alpha} \qquad (t = \Delta_\delta/2).
$$<p>The bound on $\Delta_\delta$ from the integral earlier states that</p>$$
\Delta_\delta \geq \frac{\varepsilon_2^2 - \varepsilon_1^2}{2n}.
$$<p>From this, we can derive that</p>$$
\begin{aligned}
\Delta_\delta ~~\geq~~ \frac{\varepsilon_2^2 - \varepsilon_1^2}{2n} &{\quad\iff\quad} \Delta_\delta^2 ~~\geq~~ \left(\frac{\varepsilon_2^2 - \varepsilon_1^2}{2n}\right)^2
\\[10pt]&{\quad\iff\quad} \Delta_\delta^2 ~~\geq~~ \frac{\left(\varepsilon_2^2 - \varepsilon_1^2\right)^2}{4n^2}
\\[10pt]&{\quad\iff\quad} \frac{1}{\Delta_\delta^2} ~\leq~~ \frac{4n^2}{\left(\varepsilon_2^2 - \varepsilon_1^2\right)^2}
\\[15pt]&{\quad\iff\quad} \frac{2}{\Delta_\delta^2} \,\ln\! \frac{2}{\alpha} ~~\leq~~ \frac{8n^2}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2} \,\ln\! \frac{2}{\alpha} \quad[\,=: L\,].
\end{aligned}
$$<p>Since $\Delta_\delta \geq (\varepsilon_2^2 - \varepsilon_1^2)/(2n)$ and $\frac{2}{\Delta_\delta^2}\,\ln\!\frac{2}{\alpha}$ is strictly decreasing in $\Delta_\delta$, the true requirement is always at most $L$. Therefore, choosing $|S| \geq L$ guarantees the condition is satisfied for all admissible $\Delta_\delta$:</p>$$
|S| \geq \underbrace{\frac{8\,n^2}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2}\,\ln\!\frac{2}{\alpha}}_{\text{Our choice (worst-case }L\text{)}}
\quad\geq\quad
\underbrace{\frac{2}{\Delta_\delta^{2}}\,\ln\!\frac{2}{\alpha}}_{\text{What we actually need}}.
$$<p>In other words, a sufficient condition for $|S|$ is:</p>$$
|S| ~~\geq~~ \frac{8\,n^2}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2}\,\ln\!\frac{2}{\alpha}.
$$<p>Let $T := n \cdot N$ be the total number of single‚Äëpair measurements (oracle calls). Since a call has matching bases with probability $1/2$, a Chernoff bound shows that choosing $T = 4|S|$ (equivalently, $N = 4|S|/n$ blocks) makes the event of getting fewer than $|S|$ matches have probability at most $e^{-|S|/4}$, which is negligibly small for moderate $|S|$. Therefore,</p>$$
N ~=~ \frac{4|S|}{n} ~~\geq~~ \frac{32\,n}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2}\,\ln\!\frac{2}{\alpha}
\qquad\left[= O\!\left(n\,(\varepsilon_2^2 - \varepsilon_1^2)^{-2}\right)\right],
$$<p>and equivalently (in terms of total oracle calls)</p>$$
T = n \cdot N \geq \frac{32\,n^2}{(\varepsilon_2^2 - \varepsilon_1^2)^2}\,\ln\!\frac{2}{\alpha}.
$$<p>So it turns out that extending the test from a single pair to $n$ i.i.d. pairs is <strong>not</strong> free: the sample cost grows linearly in the number of blocks (equivalently, quadratically in the total number of oracle calls). This is because certifying that the entire collection of $n$ states is globally $\varepsilon$-close is much stricter than certifying a single state. A small imperfection in each pair, when compounded over the tensor product, can cause a large global deviation.</p><p>To keep the global fidelity $F_n = F_1^n$ high, each single-pair fidelity $F_1$ must be extremely close to $1$. Since the true error rate $\delta$ measures per-pair imperfection, this requirement forces $\delta$ to be much smaller than in the single-pair case. Consequently, the promise gap $\Delta_\delta$ (the separation between the &ldquo;close&rdquo; and &ldquo;far&rdquo; thresholds) shrinks by about a factor of $n$, compressing the relevant error-rate range into a tiny window near zero.</p><p>A core principle of statistics is that the uncertainty of an estimated average is proportional to the inverse square root of the number of samples (in our case, this is $1 / \sqrt{|S|}$). To reliably measure a promise gap that is $n$ times smaller, our estimate for $\Delta_\delta$ must be $n$ times more precise. Achieving this $n$-fold increase in precision requires an $n^2$-fold increase in the <strong>number of pooled calls</strong> (hence $O(n^2)$ total single‚Äëpair measurements) which, when grouped as blocks of size $n$, translates to an $O(n)$ growth in the <strong>number of blocks</strong> $N$.</p><blockquote><p><strong>Theorem (Finite-sample tolerant EPR identity test, i.i.d. product version).</strong></p><p>Let $n \geq 2$ and suppose the global state $\rho^{\otimes n}$ for some bipartite state $\rho$.
Fix global trace-distance tolerances $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$ and failure probability $\alpha \in (0,1)$.
Define</p>$$
\begin{aligned}
&f(\varepsilon) = \frac{1}{2}\!\left[1 - (1 - \varepsilon^2)^{1/n}\right]&,&
&\delta_{\text{close}} = f(\varepsilon_1),
\\[10pt]&\delta_{\text{far}} = f(\varepsilon_2)&,&
\qquad &\kappa = \frac{\delta_{\text{close}} + \delta_{\text{far}}}{2}.
\end{aligned}
$$<p><strong>Protocol.</strong> Prepare $N$ (i.i.d.) blocks of $\rho^{\otimes n}$.
For each block $j \in [N]$ and coordinate $i \in [n]$, make one call to $\mathbb{O}(\rho)$, obtaining $(M_{(j,i)}, Y_{(j,i)})$.
Let</p>$$
S := \{\, (j,i) \in [N] \times [n] ~:~ M_{(j,i)} = 1 \,\}
$$<p>be the set of calls with matching bases. Define the <em>pooled</em> empirical mismatch rate as</p>$$
\hat{\delta} := \frac{1}{|S|} \sum_{(j,i) \in S} Y_{(j,i)},
$$<p>where $Y_{(j,i)} \in \{0,1\}$ for all $(j,i) \in S$.</p><p><strong>Decision rule.</strong> Accept <em><strong>iff</strong></em> $\hat{\delta} \leq \kappa$.</p><p>If</p>$$
N ~~\geq~~ \frac{32\,n}{(\varepsilon_2^2 - \varepsilon_1^2)^2} \,\ln\!\frac{2}{\alpha}, \qquad\left[= O\!\left(n\left(\varepsilon_2^2 - \varepsilon_1^2\right)^{-2}\right)\right]
$$<p>equivalently, the number of oracle calls,</p>$$
T = n \cdot N ~~\geq~~ \frac{32\,n^2}{(\varepsilon_2^2 - \varepsilon_1^2)^2}\,\ln\!\frac{2}{\alpha}, \qquad\left[= O\!\left(n^2\left(\varepsilon_2^2 - \varepsilon_1^2\right)^{-2}\right)\right]
$$<p>then the following statements are true:</p><ul><li><strong>Completeness.</strong> If $D(\rho^{\otimes n}, \Phi^{\otimes n}) \leq \varepsilon_1$, the test accepts with probability at least $1 - \alpha$.</li><li><strong>Soundness.</strong> If $D(\rho^{\otimes n}, \Phi^{\otimes n}) \geq \varepsilon_2$, the test rejects with probability at least $1 - \alpha$.</li><li><strong>Promise gap.</strong> If $\varepsilon_1 < D(\rho^{\otimes n},\Phi^{\otimes n}) < \varepsilon_2$, no guarantee is made; the test may accept or reject.</li></ul><p><em>Note.</em> In the i.i.d. case, all coordinates $i \in [n]$ have the same true mismatch rate, so pooling over $S$ is valid. Matching bases occur with probability $1/2$ independently per coordinate; the constants above already account (via Chernoff-Hoeffding bounds) for obtaining enough matches with high probability.</p></blockquote><p>That completes the &ldquo;easy&rdquo; i.i.d. case. Next, we&rsquo;ll remove the identical-pair assumption.</p><hr><h2 id=medium-case-independent-non-identical-pairs>Medium case (independent, non-identical pairs)<a hidden class=anchor aria-hidden=true href=#medium-case-independent-non-identical-pairs>#</a></h2><p>Here the joint state is a product of possibly different single-pair states</p>$$
\varrho = \rho_{1}\otimes\rho_{2}\otimes\dots\otimes\rho_{n},
\quad
\text{vs. } ~
\Phi^{\otimes n}.
$$<p>with no entanglement across copies but with potentially different single-pair states $\rho_i$. In the context of BB84, each copy is attacked &ldquo;from scratch&rdquo; (no cross-round entanglement) but Eve may prepare a different state in every round.</p><p>Exactly as before, we want a single classical test that, with failure probability at most $\alpha$, distinguishes</p>$$
\begin{cases}
~\text{H}_0\text{ (‚Äúclose‚Äù)} &: D_n \leq \varepsilon_1,\\[6pt]
~\text{H}_1\text{ (‚Äúfar‚Äù)} &: D_n \geq \varepsilon_2,
\end{cases}
\qquad
0 \leq \varepsilon_1 < \varepsilon_2 \leq 1,
$$<p>where $D_n := D(\rho_1 \otimes \dots \otimes \rho_n, \Phi^{\otimes n})$.</p><p>For each coordinate $i$ (i.e. each position in the $n$-tuple of pairs), let</p>$$
\delta_i := \Pr[\text{mismatch} \mid \text{matching bases on coordinate } i]
$$<p>be the <em>true</em> mismatch probability for that coordinate, and let</p>$$
\hat{\delta}_i := \frac{\#\{\text{mismatches on coordinate } i\}}{\#\{\text{matching-basis trials on coordinate } i\}}
$$<p>be its <em>empirical</em> mismatch rate from the data.</p><p>In the easy case, all $\delta_i$ are identical because of the i.i.d. assumption. So pooling all matching-basis trials into a single $\hat{\delta}$ is equivalent to estimating $\delta_i$ for any $i$. And as we&rsquo;ve seen, we only need one concentration bound.</p><p>However, for our medium (independent, non-identical) case, the $\delta_i$ may differ. To certify <em>all</em> coordinates simultaneously, we need to guarantee that $|\hat{\delta}_i - \delta_i|$ is small <strong>for every</strong> $i$. This unfortunately forces us to run the test on each coordinate separately and then take a <strong>union bound</strong> over the $n$ coordinates, and we&rsquo;ll soon see that this adds an extra $n \log n$ factor in the sample complexity on top of the easy case.</p><p>Let&rsquo;s get started. First, we organise repeated i.i.d. copies of the <em>entire</em> $n$-tuple into <em>blocks</em> using the definition from near the very beginning of this post. As a reminder, in the context of the medium case, a block is one i.i.d. copy of the global product state $\varrho$. Note that in the medium case (in fact, for all three cases) we are still given i.i.d. copies of</p>$$
\varrho = \rho_1 \otimes \rho_2 \otimes \cdots \otimes \rho_n,
$$<p>but within $\varrho$, the individual $\rho_i$ may be different.</p><p>After preparing a block, we make independent calls to the single-pair oracle $\mathbb{O}$ on <em>each</em> coordinate $i = 1, \dots, n$. The block then outputs</p>$$
\bigl\{ (M_{(j, i)},\,Y_{(j, i)}) \bigr\}_{i=1}^n,
$$<p>where $j$ indexes the block. Explicitly, in block $j$ we obtain for each coordinate $i$:</p><ul><li>a matching indicator $M_{(j, i)} \in \{0, 1\}$, which is $1$ if Alice&rsquo;s and Bob&rsquo;s bases matched for that pair;</li><li>and, if $M_{(j, i)} = 1$, a mismatch bit $Y_{(j, i)} \in \{0, 1\}$ with $\mathbb{E}[Y_{(j,i)} \mid M_{(j,i)} = 1] = \delta_i$.</li></ul><p>We repeat this procedure over $N$ independent blocks. The entire dataset forms an $N \times n$ table:</p>$$
\begin{array}{c|cccc}
\text{block } j & i=1 & i=2 & \cdots & i=n \\ \hline
1 & (M_{(1,1)}, Y_{(1,1)}) & (M_{(1,2)}, Y_{(1,2)}) & \cdots & (M_{(1,n)}, Y_{(1,n)}) \\
2 & (M_{(2,1)}, Y_{(2,1)}) & (M_{(2,2)}, Y_{(2,2)}) & \cdots & (M_{(2,n)}, Y_{(2,n)}) \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
N & (M_{(N,1)}, Y_{(N,1)}) & (M_{(N,2)}, Y_{(N,2)}) & \cdots & (M_{(N,n)}, Y_{(N,n)})
\end{array}
$$<p>where each cell comes from a single call to $\mathbb{O}(\rho_i)$. In total, we have made $T = n \cdot N$ calls to the oracle. In this table:</p><ul><li><strong>Rows</strong> (fixed $j$): contain all $n$ coordinates in the same block, prepared together as one copy of $\varrho$. The $\rho_i$ can be different, so entries in the same row are generally <em>not</em> identically distributed.</li><li><strong>Columns</strong> (fixed $i$): contain the same coordinate across $N$ i.i.d. blocks. These entries <em>are</em> i.i.d. samples from $\rho_i$, since each block contains a fresh copy of it in position $i$.</li></ul><p>Therefore, when analysing each coordinate ($i$) separately, the $N$ entries in a column are independent and identically distributed. The union bound will later account for all $n$ coordinates at once.</p><h3 id=a-pipeline-for-the-decision-rule>A pipeline for the decision rule<a hidden class=anchor aria-hidden=true href=#a-pipeline-for-the-decision-rule>#</a></h3><p>For our decision rule, we must reason directly with the <strong>product fidelity</strong></p>$$
F_n^2 ~=~ \prod_{i=1}^n F_i^2,
$$<p>since this is what determines the global trace distance in $\mathbf{H_0}$ and $\mathbf{H_1}$. Any aggregate statistic of the per-coordinate error rates (such as $\max_i\hat\delta_i$ or an average) can misclassify states: even if one coordinate has a relatively large mismatch rate $\delta_i$ (and thus a lower $F_i$), the remaining coordinates may have fidelities close to $1$, so that the product fidelity $F_n$ still satisfies the global acceptance condition. In this case, a per‚Äêcoordinate max rule would incorrectly reject such a state. To align the test with the global criterion, we instead construct <strong>upper confidence bounds</strong> $U_i$ such that, with high probability, $\delta_i \leq U_i$ for all $i$ simultaneously. These bounds give</p>$$
F_i^2 ~\geq~ 1 - 2U_i
$$<p>and hence a <strong>lower confidence bound</strong> on the product fidelity,</p>$$
\widehat{F}_{\text{LCB}}^{\,2} := \prod_{i=1}^n (1 - 2U_i) ~\leq~ F_n^2.
$$<p>We then accept iff $\widehat{F}_{\text{LCB}}^{\,2}$ exceeds a threshold, so the decision rule targets the global fidelity condition directly.</p><p>In short, we would first establish a per-coordinate UCB on $\delta_i$, use that to establish a LCB on the global fidelity $F_n$, then we can derive a decision rule. Let&rsquo;s break down the pipeline step by step.</p><h4 id=per-coordinate-ucb-on>Per-coordinate UCB on $\delta_i$<a hidden class=anchor aria-hidden=true href=#per-coordinate-ucb-on>#</a></h4><p>For each coordinate $i \in [n]$, define the matching-basis index set across blocks (columns)</p>$$
S_i := \{\, j \in [N] : M_{(j, i)} = 1 \,\}.
$$<p>The empirical mismatch rate on coordinate $i$ is</p>$$
\hat\delta_i ~=~ \frac{1}{|S_i|} \sum_{j \in S_i} Y_{(j, i)} \quad\text{(defined when }|S_i| > 0\text{)}.
$$<p>Recall the per-coordinate true error rate $\delta_i = \Pr[Y = 1 \mid M = 1]$.</p><p>The random variables $\{Y_{(j,i)}\}_{j\in S_i}$ are i.i.d. Bernoulli with mean $\delta_i$. For any $t > 0$, we have the one-sided Hoeffding bound</p>$$
\Pr\!\left[\delta_i - \hat\delta_i \geq t\right] \leq e^{-2|S_i|t^2}.
$$<p>Compared to the two-sided Hoeffding bound used earlier, the absolute value on the left-hand side has been dropped. Intuitively, the two-sided version accounts for both deviations above and below the mean, each equally likely, which introduces the extra factor of $2$ in front of the exponential. In the one-sided case, we only consider one direction of deviation, so this factor disappears.</p><p>To turn the Hoeffding bound into a high-confidence margin, we pick $t$ so that the bad event $\delta_i > \hat{\delta}_i + t$ occurs with probability at most a chosen budget $\beta$:</p>$$
e^{-2|S_i|t^2} \leq \beta.
$$<p>Taking logarithms and rearranging gives</p>$$
t^2 \geq \frac{\ln(1/\beta)}{2|S_i|}
\quad\implies\quad
t \geq \sqrt{\frac{\ln(1/\beta)}{2|S_i|}}.
$$<p>Since $|S_i|$ can be different for each coordinate, the margin for $t$ will in general depend on $i$. Therefore, we write it as $t_i$. In practice, choosing $t_i$ larger than necessary would make the bound looser by increasing the UCB $U_i$.
To keep the bound as tight as possible, we take the smallest $t_i$ that satisfies the inequality (i.e. set it by taking the equality) and set</p>$$
t_i = \sqrt{\frac{\ln(1/\beta)}{2|S_i|}}.
$$<p>This choice guarantees that</p>$$
\Pr[\delta_i > \hat{\delta}_i + t_i] \leq \beta
$$<p>for the given coordinate $i$.</p><p>By the union bound, for any events $E_1, \dots, E_n$,</p>$$
\Pr\!\left[ ~\bigcup_{i = 1}^{n} E_i~ \right] ~\leq~ \sum_{i = 1}^n \Pr[E_i].
$$<p>In our context, we want all $n$ coordinates to have valid upper bounds simultaneously. Let $E_i$ be the event that the UCB for coordinate $i$ fails,</p>$$
E_i := \left\{\delta_i > \hat{\delta}_i + t_i\right\},
$$<p>applying the union bound gives</p>$$
\Pr\!\left[\,\exists i: \delta_i > \hat\delta_i + t_i\,\right] ~\leq~ \sum_{i=1}^n \Pr[\delta_i > \hat\delta_i + t_i].
$$<p>In words: the probability that at least one coordinate&rsquo;s bound fails is no more than the sum of the individual failure probabilities.</p><p>If each coordinate&rsquo;s bound fails with probability at most $\beta$, then by the union bound the probability that <em>any</em> coordinate&rsquo;s bound fails is at most $n\beta$. If (by choice) we allocate half of the total error budget $\alpha$ to this step, then we require</p>$$
n\beta \leq \frac{\alpha}{2} \quad\implies\quad \beta \leq \frac{\alpha}{2n}.
$$<p>Substituting this $\beta$ into the expression for $t_i$ gives</p>$$
t_i = \sqrt{\frac{\ln(1/\beta)}{2|S_i|}} = \sqrt{\frac{\ln\!\left(\frac{2n}{\alpha}\right)}{2|S_i|}}.
$$<p>From the one-sided Hoeffding bound earlier, we can construct a valid UCB on $\delta_i$ by taking the empirical rate and adding the margin:</p>$$
U_i := \hat\delta_i + t_i.
$$<p>To enforce our relabeling convention $\delta_i \in [0, \tfrac{1}{2}]$, we take</p>$$
U_i := \min\left\{ \tfrac{1}{2}, \hat\delta_i + t_i \right\}.
$$<p>This cap at $\tfrac{1}{2}$ reflects our per-basis relabeling convention: for each basis, we flip Bob&rsquo;s outcomes if necessary so that the mismatch probability is at most $\tfrac{1}{2}$; values above $\tfrac{1}{2}$ are operationally equivalent to their complement and therefore replaced by $\tfrac{1}{2}$.</p><p>Therefore, for all coordinates $i \in [n]$, we have established a upper confidence bound on the per-coordinate true error rate $\delta_i$, and by the union bound all $n$ inequalities $\delta_i \leq U_i$ hold <em>simultaneously</em> with probability at least $1 - \tfrac{\alpha}{2}$. Let&rsquo;s now translate this into a lower confidence bound on the global fidelity.</p><h4 id=lcb-on-the-global-fidelity>LCB on the global fidelity $F_n$<a hidden class=anchor aria-hidden=true href=#lcb-on-the-global-fidelity>#</a></h4><p>By the single-pair fidelity-error relation, for each coordinate $i \in [N]$ we have</p>$$
F(\rho_i, \Phi) \geq \sqrt{1 - 2\delta_i}.
$$<p>Squaring both sides and substituting the upper confidence bound $U_i$ for $\delta_i$ yields</p>$$
F(\rho_i, \Phi)^2 \geq 1 - 2\delta_i \geq 1 - 2U_i.
$$<p>Multiplying over all coordinates,</p>$$
F(\varrho, \Phi^{\otimes n})^2
~=~ \prod_{i=1}^n F(\rho_i, \Phi)^2
~\geq~ \prod_{i=1}^n \bigl(1 - 2U_i\bigr).
$$<p>We define the lower confidence bound (LCB) on the global fidelity as</p>$$
\widehat{F}_{\text{LCB}}^{\,2} := \prod_{i=1}^n \bigl(1 - 2U_i\bigr),
$$<p>which is non-negative by construction, since $U_i \leq \tfrac{1}{2}$ from our definition.</p><p>Therefore, from the union bound construction above, all $n$ inequalities $\delta_i \leq U_i$ hold simultaneously with probability at least $1 - \tfrac{\alpha}{2}$. On this event,</p>$$
\widehat{F}_{\text{LCB}}^{\,2} \leq F(\varrho, \Phi^{\otimes n})^2,
$$<p>so $\widehat{F}_{\text{LCB}}^{\,2}$ is a valid lower confidence bound on the global fidelity $F_n^2$ with probability at least $1 - \tfrac{\alpha}{2}$.</p><p>(In the final theorem, this will combine with the separate high-probability guarantee from the &ldquo;enough matches&rdquo; step to give an overall probability of at least $1 - \alpha$.)</p><p>With this LCB on the global fidelity established, we now need to define a decision rule for the test.</p><h4 id=decision-rule-and-correctness-proof>Decision rule and correctness proof<a hidden class=anchor aria-hidden=true href=#decision-rule-and-correctness-proof>#</a></h4><p>Define the cutoff</p>$$
\tau := 1 - \frac{\varepsilon_1^2 + \varepsilon_2^2}{2}.
$$<p>Then we accept <em><strong>iff</strong></em> $\widehat{F}_{\text{LCB}}^{\,2} \geq \tau$:</p><blockquote>$$
\textbf{Decision rule (medium case)} =
\begin{cases}
\text{‚Äúclose‚Äù} & \text{if } \widehat{F}_{\text{LCB}}^{\,2} \geq \tau,\\[4pt]
\text{‚Äúfar‚Äù} & \text{if } \widehat{F}_{\text{LCB}}^{\,2} < \tau.
\end{cases}
$$</blockquote><p>We need to prove the correctness of our decision rule, conditioned on the <em>good event</em> $\mathcal{G}$. Correctness includes completeness (close $\Rightarrow$ accept) and soundness (far $\Rightarrow$ reject). But before we get into that, what exactly is the good event in the medium case?</p><p>[write what the good event is]</p><hr><p>After this line, everything below is not fully correct</p><hr><p>As in the i.i.d. case, define the function</p>$$
f(\varepsilon) := \tfrac{1}{2}\!\left[1 - (1 - \varepsilon^2)^{1/n}\right],
$$<p>the thresholds</p>$$
\delta_{\text{close}} := f(\varepsilon_1), \quad \delta_{\text{far}} := f(\varepsilon_2),
$$<p>the (midpoint) cutoff</p>$$
\kappa := \tfrac{1}{2}(\delta_{\text{close}} + \delta_{\text{far}}),
$$<p>and set the margin</p>$$
t := \tfrac{1}{2}(\delta_{\text{far}} - \delta_{\text{close}}).
$$<p>(As before, $\delta_{\text{far}} - \delta_{\text{close}} = \Delta_\delta \geq \frac{\varepsilon_2^2-\varepsilon_1^2}{2n}$.)</p><blockquote>$$
\textbf{Decision rule (medium case)} =
\begin{cases}
\text{‚Äúclose‚Äù} & \text{if } \max_{i \in [n]} \hat\delta_i < \kappa,\\
\text{‚Äúfar‚Äù} & \text{if } \max_{i \in [n]} \hat\delta_i \geq \kappa.
\end{cases}
$$</blockquote><p>In other words, we accept if and only if the worst-case error rate is strictly less than our cutoff $\kappa$, meaning all our error rates $\hat\delta_i$ has to pass the cutoff test.</p><p>Define the <strong>good event</strong></p>$$
\mathcal G ~:=~ \bigcap_{i=1}^n \left\{\,|\hat\delta_i - \delta_i| < t\,\right\},
$$<p>i.e. <em>every</em> column concentrates within the margin $t$. We will set the number of blocks $N$ so that $\Pr[\mathcal G] \geq 1 - \alpha$ using concentration bounds.</p><p>Let&rsquo;s quickly show completeness and soundness of our decision rule.</p><p><strong>Completeness (close $\Rightarrow$ accept).</strong> If every coordinate is close i.e. $\delta_i \leq \delta_{\text{close}}$ for all $i$, then on the <em>good</em> event $\mathcal{G}$,</p>$$
\hat\delta_i < \delta_i + t ~\le~ \delta_{\text{close}} + t ~=~ \kappa
\quad\implies\quad
\max_i \hat\delta_i < \kappa,
$$<p>so we accept.</p><p><strong>Soundness (far $\Rightarrow$ reject).</strong> This requires some work. If the global state $\varrho = \otimes_{i=1}^n \rho_i$ is far i.e. $D(\varrho, \Phi^{\otimes n}) \geq \varepsilon_2$, then by the (right-hand) Fuchs‚Äìvan de Graaf inequality, the global fidelity, $F_n$, satisfies</p>$$
F_n := F(\varrho, \Phi^{\otimes n}) \leq \sqrt{1 - \varepsilon_2^2}.
$$<p>Fidelity is multiplicative even for <em>heterogeneous</em> products:</p>$$
F_n = \prod_{i=1}^n F_i, \quad\text{where } F_i := F(\rho_i,\Phi).
$$<p>Let $\tau := (1 - \varepsilon_2^2)^{1/(2n)}$, so $\tau^n = \sqrt{1 - \varepsilon_2^2}$. If <strong>every</strong> coordinate satisfied $F_i > \tau$, then</p>$$
F_n ~=~ \prod_{i=1}^n F_i ~>~ \tau^n ~=~ \sqrt{1 - \varepsilon_2^2},
$$<p>contradicting the bound for $F_n$ above. Therefore, there has to exist some coordinate $i^\star$ with</p>$$
F_{i^\star} ~\leq~ \tau ~=~ (1 - \varepsilon_2^2)^{1/(2n)}.
$$<p>Now use the single-pair link $F_i \geq \sqrt{1 - 2\delta_i}$ from the lemma above. Rearranging</p>$$
1 - 2\delta_{i^\star} ~\leq~ F_{i^\star}^2 ~\leq~ \tau^2 = (1 - \varepsilon_2^2)^{1/n}
$$<p>gives</p>$$
\delta_{i^\star} ~\geq~ \frac{1 - (1 - \varepsilon_2^2)^{1/n}}{2} ~=~ f(\varepsilon_2) ~=~ \delta_{\text{far}}.
$$<p>On the good event $\mathcal{G}$,</p>$$
\hat\delta_{i^\star} ~>~ \delta_{i^\star} - t ~\geq~ \delta_{\text{far}} - t ~=~ \kappa,
$$<p>so</p>$$
\max_i \hat\delta_i ~\geq~ \hat\delta_{i^\star} ~>~ \kappa,
$$<p>and we reject.</p><p>So all we owe now is to make the <em>good event</em> $\mathcal{G}$ hold with probability at least $1 - \alpha$ using a concentration bound.</p><hr><h3 id=concentration-all-coordinates-at-once>Concentration: all coordinates at once<a hidden class=anchor aria-hidden=true href=#concentration-all-coordinates-at-once>#</a></h3><p><code>Complete writeup</code></p><hr><blockquote><p><strong>Theorem (Finite-sample tolerant EPR identity test, independent, non-identical pairs).</strong></p><p>Let $n \geq 2$ and suppose the global state is $\varrho = \rho_1 \otimes \rho_2 \otimes \dots \otimes \rho_n$ for bipartite states $\rho_i$.
Fix global trace-distance tolerances $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$ and failure probability $\alpha \in (0,1)$.
Define</p>$$
\begin{aligned}
&f(\varepsilon) = \frac{1}{2}\!\left[1 - (1 - \varepsilon^2)^{1/n}\right], & &
\delta_{\text{close}} = f(\varepsilon_1), \\[6pt]
&\delta_{\text{far}} = f(\varepsilon_2), & &
\kappa = \frac{\delta_{\text{close}} + \delta_{\text{far}}}{2}.
\end{aligned}
$$<p><strong>Protocol.</strong> Prepare $N$ (i.i.d.) blocks of $\varrho$.
For each block $j \in [N]$ and coordinate $i \in [n]$, make one call to $\mathbb{O}(\rho_i)$, obtaining $(M_{(j,i)}, Y_{(j,i)})$.
For each coordinate $i$, define</p>$$
S_i := \{\, j \in [N] ~:~ M_{(j,i)} = 1 \,\}
$$<p>and compute</p>$$
\hat{\delta}_i := \frac{1}{|S_i|} \sum_{j \in S_i} Y_{(j,i)},
$$<p>where $Y_{(j,i)} \in \{0,1\}$ for all $(j,i) \in S_i$.</p><p><strong>Decision rule.</strong> Accept <em><strong>iff</strong></em> $\max_{i \in [n]} \hat{\delta}_i < \kappa$.</p><p>If</p>$$
N ~~\geq~~ \frac{32\,n^2}{(\varepsilon_2^2 - \varepsilon_1^2)^2}\,\ln\!\frac{4n}{\alpha}, \qquad\left[= O\!\left(n^2 \log n \left(\varepsilon_2^2 - \varepsilon_1^2\right)^{-2}\right)\right]
$$<p>equivalently, the number of oracle calls,</p>$$
T = n \cdot N ~~\geq~~ \frac{32\,n^3}{(\varepsilon_2^2 - \varepsilon_1^2)^2}\,\ln\!\frac{4n}{\alpha}, \qquad\left[= O\!\left(n^3 \log n \left(\varepsilon_2^2 - \varepsilon_1^2\right)^{-2}\right)\right]
$$<p>then the following statements are true:</p><ul><li><strong>Completeness.</strong> If $D(\bigotimes_{i=1}^n \rho_i, \Phi^{\otimes n}) \leq \varepsilon_1$, the test accepts with probability at least $1 - \alpha$.</li><li><strong>Soundness.</strong> If $D(\bigotimes_{i=1}^n \rho_i, \Phi^{\otimes n}) \geq \varepsilon_2$, the test rejects with probability at least $1 - \alpha$.</li><li><strong>Promise gap.</strong> If $\varepsilon_1 < D(\bigotimes_{i=1}^n \rho_i, \Phi^{\otimes n}) < \varepsilon_2$, no guarantee is made; the test may accept or reject.</li></ul><p><em>Note.</em> In the medium case, the $\delta_i$ may differ across coordinates, so each $\hat{\delta}_i$ must be estimated separately. The union bound over all $n$ coordinates yields the $\log(n)$ factor in the sample complexity.</p></blockquote></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://teaegg.net/research/urss/epr-tolerant-identity-testing/><span class=title>¬´ Prev</span><br><span>Classical tolerant identity test for the EPR state</span></a></nav></footer></article></main><footer class=footer><span>¬© 2025 ∆¨·òø·ó© ·òø·òú·òú ‚ñ∂Ô∏é ‚Ä¢·Åä·Åä||·Åä|·Åã|||| | ¬∑ Built by Howard ìÜ©ìÇÄìÜ™
<span class=only-desktop>¬∑ Powered by
<a href=https://gohugo.io>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod>PaperMod</a></span></span></footer><a href=#top aria-label="go to top" title="Go to Top" class=top-link id=top-link><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){const n=document.getElementById("greeting");if(!n)return;const e=(new Date).getHours();let t;e>=6&&e<12?t="ÍßÅ …¢÷Ö÷Ö÷Ö…ñ  ç÷Ö Ä’º…®’º…¢! üåª ÍßÇ":e>=12&&e<18?t="ùêÜùê®ùê®ùêù ùêöùêüùê≠ùêûùê´ùêßùê®ùê®ùêß. ‚òÄÔ∏èüå≥‚òï":e>=18&&e<22?t="ùòéùò∞ùò∞ùò• ùò¶ùò∑ùò¶ùòØùò™ùòØùò®. üåÑüõãÔ∏èüìñ":t="ùïôùïñùï™ ùïüùïöùïòùïôùï• ùï†ùï®ùïù... ü¶âüåôüåÉ",n.textContent=t})()</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>