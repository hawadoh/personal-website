<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Classical tolerant identity test for multiple EPR states | ùóßùóòùóî‚Ä¢ùóòùóöùóö</title><meta name=keywords content><meta name=description content="Change in notation
With the tolerant identity test for a single state $\rho_{AB}$ complete, we now turn to the problem of certifying multiple EPR pairs. Before analysing the multi-pair scenarios, it helps to reframe one round of the single-pair matching-outcomes protocol as a callable oracle $\mathbb{O}$ that consumes a fresh pair of $\rho_{AB}$ and outputs a classical bit when the bases match.
Suppose Alice and Bob share a number of independent pairs of an unknown state $\rho_{AB}$. We package one measurement round into a callable oracle $\mathbb{O}(\rho_{AB})$ and then do simple classical post-processing. Combining $N$ oracle calls and doing the simple classical post-processing is equivalent to the $N$-round protocol!"><meta name=author content="Howard Cheung"><link rel=canonical href=https://teaegg.net/research/urss/n-epr-test/><link crossorigin=anonymous href=/assets/css/stylesheet.12d2e5fe7e7a6b449beaee7514d9f08063da1272468eea14524da628ddfaabb5.css integrity="sha256-EtLl/n56a0Sb6u51FNnwgGPaEnJGjuoUUk2mKN36q7U=" rel="preload stylesheet" as=style><link rel=icon href=https://teaegg.net/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://teaegg.net/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://teaegg.net/favicon-32x32.png><link rel=apple-touch-icon href=https://teaegg.net/apple-touch-icon.png><link rel=mask-icon href=https://teaegg.net/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://teaegg.net/research/urss/n-epr-test/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}]})})</script><link rel=icon type=image/png href=/favicon/favicon-96x96.png sizes=96x96><link rel=icon type=image/svg+xml href=/favicon/favicon.svg><link rel="shortcut icon" href=/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/favicon/apple-touch-icon.png><meta name=apple-mobile-web-app-title content="Teaegg"><link rel=manifest href=/favicon/site.webmanifest><meta property="og:url" content="https://teaegg.net/research/urss/n-epr-test/"><meta property="og:site_name" content="ùóßùóòùóî‚Ä¢ùóòùóöùóö"><meta property="og:title" content="Classical tolerant identity test for multiple EPR states"><meta property="og:description" content="Change in notation With the tolerant identity test for a single state $\rho_{AB}$ complete, we now turn to the problem of certifying multiple EPR pairs. Before analysing the multi-pair scenarios, it helps to reframe one round of the single-pair matching-outcomes protocol as a callable oracle $\mathbb{O}$ that consumes a fresh pair of $\rho_{AB}$ and outputs a classical bit when the bases match.
Suppose Alice and Bob share a number of independent pairs of an unknown state $\rho_{AB}$. We package one measurement round into a callable oracle $\mathbb{O}(\rho_{AB})$ and then do simple classical post-processing. Combining $N$ oracle calls and doing the simple classical post-processing is equivalent to the $N$-round protocol!"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="research"><meta property="article:published_time" content="2025-08-08T17:42:31+01:00"><meta property="article:modified_time" content="2025-08-08T17:42:31+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Classical tolerant identity test for multiple EPR states"><meta name=twitter:description content="Change in notation
With the tolerant identity test for a single state $\rho_{AB}$ complete, we now turn to the problem of certifying multiple EPR pairs. Before analysing the multi-pair scenarios, it helps to reframe one round of the single-pair matching-outcomes protocol as a callable oracle $\mathbb{O}$ that consumes a fresh pair of $\rho_{AB}$ and outputs a classical bit when the bases match.
Suppose Alice and Bob share a number of independent pairs of an unknown state $\rho_{AB}$. We package one measurement round into a callable oracle $\mathbb{O}(\rho_{AB})$ and then do simple classical post-processing. Combining $N$ oracle calls and doing the simple classical post-processing is equivalent to the $N$-round protocol!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"üî¨ Research","item":"https://teaegg.net/research/"},{"@type":"ListItem","position":2,"name":"üîêüí° Undergraduate Research Support Scheme (URSS)","item":"https://teaegg.net/research/urss/"},{"@type":"ListItem","position":3,"name":"Classical tolerant identity test for multiple EPR states","item":"https://teaegg.net/research/urss/n-epr-test/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Classical tolerant identity test for multiple EPR states","name":"Classical tolerant identity test for multiple EPR states","description":"Change in notation With the tolerant identity test for a single state $\\rho_{AB}$ complete, we now turn to the problem of certifying multiple EPR pairs. Before analysing the multi-pair scenarios, it helps to reframe one round of the single-pair matching-outcomes protocol as a callable oracle $\\mathbb{O}$ that consumes a fresh pair of $\\rho_{AB}$ and outputs a classical bit when the bases match.\nSuppose Alice and Bob share a number of independent pairs of an unknown state $\\rho_{AB}$. We package one measurement round into a callable oracle $\\mathbb{O}(\\rho_{AB})$ and then do simple classical post-processing. Combining $N$ oracle calls and doing the simple classical post-processing is equivalent to the $N$-round protocol!\n","keywords":[],"articleBody":"Change in notation With the tolerant identity test for a single state $\\rho_{AB}$ complete, we now turn to the problem of certifying multiple EPR pairs. Before analysing the multi-pair scenarios, it helps to reframe one round of the single-pair matching-outcomes protocol as a callable oracle $\\mathbb{O}$ that consumes a fresh pair of $\\rho_{AB}$ and outputs a classical bit when the bases match.\nSuppose Alice and Bob share a number of independent pairs of an unknown state $\\rho_{AB}$. We package one measurement round into a callable oracle $\\mathbb{O}(\\rho_{AB})$ and then do simple classical post-processing. Combining $N$ oracle calls and doing the simple classical post-processing is equivalent to the $N$-round protocol!\nOracle $\\mathbb{O}(\\rho_{AB})$ Input: one fresh pair of the bipartite state $\\rho_{AB}$.\nProcedure:\nPick two independent basis bits $\\theta \\in \\{ 0, 1 \\}$ and $\\tilde{\\theta} \\in \\{ 0, 1 \\}$ uniformly at random. Here $\\theta = 0$ means ‚Äústandard basis ($Z$)‚Äù and $\\theta = 1$ means ‚ÄúHadamard basis ($X$)‚Äù. Measure the $A$ subsystem of $\\rho_{AB}$ in basis $\\theta$ to obtain $x \\in \\{0, 1\\}$ and the $B$ subsystem in basis $\\tilde{\\theta}$ to obtain $\\tilde{x} \\in \\{0, 1\\}$. If $\\theta = \\tilde{\\theta}$ (matching bases), set $M = 1$ and $Y = \\mathbf{1}[x \\neq \\tilde x] \\in \\{0, 1\\}$; otherwise $\\theta \\neq \\tilde{\\theta}$ (mismatched bases), set $M = 0$ and $Y = \\bot$. Output: a pair $(M, Y)$ with $M \\in \\{0, 1\\}$ and $Y \\in \\{\\bot, 0, 1\\}$.\nThe oracle hides the two-party details: one call consumes one fresh pair $\\rho_{AB}$. When it emits a bit (i.e. $Y \\neq \\bot$), that bit is a Bernoulli trial with mean $\\delta$, which is the true matching-basis mismatch probability: $$ \\mathbb{E}[\\,Y \\mid M = 1\\,] = \\delta \\in[0, \\tfrac{1}{2}] \\quad\\text{(after the standard relabelling per basis)}. $$(We relabel Bob‚Äôs outcomes per basis so each per-basis mismatch rate is $\\leq 1/2$; see the convention below.)\nThis oracle encapsulates the entire procedure of basis selection, local measurement, and comparison. Each call to the oracle is statistically identical to one round of the original protocol. This formalism is particularly useful for the medium and hard cases below, as it allows us to reason about the statistical properties of the test without getting bogged down in the implementation details of each round.\nRemark. ‚ÄúSequential‚Äù vs ‚Äúparallel‚Äù only affects implementation. Equivalently one can run many calls (measure many pairs) in parallel and reveal bases afterwards over a classical channel; the distribution of $(M, Y)$ is identical.\nSingle-pair protocol (post-processing over $N$ oracle calls) Make $N$ independent calls to $\\mathbb{O}(\\rho_{AB})$, where $N \\in \\mathbb{N}$ will be bounded by the analysis below. From those $N$ calls we obtain $(M_1, Y_1), \\ldots, (M_N, Y_N)$. Define the set of matching-basis rounds $$ S = \\bigl\\{i \\in \\{1, \\dots, N\\} : M_i = 1 \\bigr\\} \\subseteq \\bigl\\{ 1, \\dots, N \\bigr\\}. $$ If by rare chance $S = \\varnothing$ (no matching bases at all), simply rerun the whole protocol as the probability of $S = \\varnothing$ is $2^{-N}$, which is negligible for modest $N$. Compute the observed error rate $$ \\hat{\\delta} = \\frac{1}{|S|}\\sum_{i\\in S} Y_i. $$ which represents the mismatch fraction conditioned on matching-basis rounds. Note. This is exactly equivalent to the usual BB84-style ‚Äúannounce bases and outcomes over a classical authenticated channel (CAC) and keep only the matching bases‚Äù description; we‚Äôve just folded that bookkeeping into $(M_i, Y_i)$.\nWith this, we can provide an alternative but mathematically equivalent tolerant identity test for one EPR state.\nTheorem (Finite-sample classical tolerant identity test for the EPR state).\nGiven i.i.d. pairs of $\\rho_{AB}$, fix two trace-distance tolerances $$ 0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1, $$ and the desired maximum failure probability $\\alpha \\in (0, 1)$. Set the cutoff $$ c = \\frac{\\varepsilon_1^2 + \\varepsilon_2^2}{4}. $$ Make $$ N \\geq \\frac{32\\,\\ln(2/\\alpha)}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2} \\qquad\\left( = O\\Bigl((\\varepsilon_2^2 - \\varepsilon_1^2)^{-2}\\Bigr) \\right) $$ independent calls to $\\mathbb{O}(\\rho_{AB})$, and compute the observed error rate $\\hat{\\delta}$. Let the decision rule be to accept iff $\\hat{\\delta} \\leq c$: $$ \\text{Decision} = \\begin{cases} \\text{‚Äúclose‚Äù}, \u0026 \\hat{\\delta} \\leq c,\\\\ \\text{‚Äúfar‚Äù}, \u0026 \\hat{\\delta} \u003e c. \\end{cases} $$ Then the test, with sample cost $N$, provides the following guarantees:\nIf $D(\\rho_{AB}, \\ket{\\text{EPR}} \\bra{\\text{EPR}}_{AB}) \\leq \\varepsilon_1$, then the test accepts (outputs ‚Äúclose‚Äù) with confidence at least $1 - \\alpha$. If $D(\\rho_{AB}, \\ket{\\text{EPR}} \\bra{\\text{EPR}}_{AB}) \\geq \\varepsilon_2$, then the test rejects (outputs ‚Äúfar‚Äù) with confidence at least $1 - \\alpha$. If $\\varepsilon_1 \u003c D(\\rho_{AB}, \\ket{\\text{EPR}} \\bra{\\text{EPR}}_{AB}) \u003c \\varepsilon_2$, no guarantee is made on the outcome; the test may go either way (accept or reject). do-rE-MI ‚ô´ For brevity we write $$ \\rho = \\rho_{AB}, \\qquad \\Phi = \\ket{\\text{EPR}}\\bra{\\text{EPR}}_{AB} $$ throughout. We introduce the global symbol $\\varrho$ only when forming an $n$-pair tensor product. In particular, we will show how the same matching-outcomes protocol extends in three settings of increasing generality and difficulty:\nEasy (i.i.d. pairs).\nAll $n$ pairs are identical: $$ \\varrho = \\rho^{\\otimes n}\\quad\\text{vs.}\\quad\\Phi^{\\otimes n}. $$ Medium (independent, non-identical pairs).\nEach pair may differ but remains uncorrelated: $$ \\varrho = \\rho_1\\otimes\\rho_2\\otimes\\dots\\otimes\\rho_n \\quad\\text{vs.}\\quad \\Phi^{\\otimes n}. $$ Hard (arbitrary adversary).\nThe most general case allows an arbitrary $2n$-qubit state $\\Sigma$, possibly entangled across pairs, against which we still wish to test closeness to $\\Phi^{\\otimes n}$.\nWe will analyse $N$, the number of oracle calls to $\\mathbb{O}$ for the single-pair protocol run needed when testing an $n$-pair hypothesis. It‚Äôs very important to keep in mind that $N$ counts the pairs consumed (oracle calls), not ‚Äúblocks‚Äù. We will only introduce ‚Äúblocks‚Äù in the medium case, where they are actually needed.\nNote. In the context of BB84, these three scenarios correspond directly to the class of attacks that an eavesdropper (Eve) might do:\nEasy (i.i.d. pairs): Eve applies the same attack channel to each transmitted qubit independently, with no memory from one round to the next. Every round she starts from scratch, so her joint state is $\\varrho = \\rho^{\\otimes n}$.\nMedium (independent, non-identical pairs): Eve still treats each qubit independently and measures immediately, but she may choose a different attack in each round. Her overall state is the product $\\varrho = \\rho_{1}\\otimes\\rho_{2}\\otimes\\dots\\otimes\\rho_{n}$.\nHard (arbitrary adversary): Eve may entangle her systems across rounds and defer all measurements until the end. There is no tensor-product structure, so her state is an arbitrary $2n$-qubit $\\Sigma$.\nBy proving security in each model, starting with the easiest and working up to the fully coherent setting, we obtain a hierarchy of BB84 security guarantees that mirror the increasing power of potential attack by Eve. From the sample complexity, we will see that a fully coherent attack (hard case) isn‚Äôt more difficult to detect than a simple i.i.d. tensor product state (easy case)! \u003c- not sure about this yet\nWe begin with the i.i.d. case as it‚Äôs both the simplest to analyse and a useful building block for the more challenging scenarios.\nEasy case (i.i.d. pairs) A na√Øve per-pair approach using trace distance A first idea is to ignore the joint state altogether and simply run the single-pair tolerant test on each of the $n$ pairs separately, then accept only if every individual test passes. Equivalently, one could tally the per-pair mismatch indicators into a total error count and compare that sum against a scaled threshold (thanks to the i.i.d. assumption). At first glance this seems painless, but a closer look shows it is actually worse than the collective strategy developed below.\nRecall for a single pair $\\rho$: $$ D_1 ~=~ D(\\rho, \\Phi), $$ and in the $n$-pair i.i.d. case we have the bound $$ D_n ~:=~ D\\bigl(\\rho^{\\otimes n},\\,\\Phi^{\\otimes n}\\bigr) ~\\leq~ n\\,D_1. $$ A sufficient per-pair condition is to shrink the tolerance. To guarantee that the full product state $\\varrho = \\rho^{\\otimes n}$ satisfies $D(\\rho^{\\otimes n}, \\Phi^{\\otimes n}) \\leq \\varepsilon_1$, the trace-distance of each pair must be at most $\\varepsilon_1/n$; otherwise the sub-additivity bound $D_n\\leq nD_1$ could exceed $\\varepsilon_1$. Promise gap narrows by a factor $n$. Replacing $\\varepsilon_j$ by $\\varepsilon_j/n$ shrinks the gap $\\varepsilon_2^2 - \\varepsilon_1^2$ by $n^{2}$. For the single-pair test the sample size scales as the inverse square of that gap, so one pair now needs $$ O\\bigl(n^{4}(\\varepsilon_2^2-\\varepsilon_1^2)^{-2}\\bigr) $$ samples, or equivalently oracle calls. Replicated testing scales linearly. Running $n$ such tests and combining them multiplies the sample cost by $n$. Hence by a very high-level analysis, we obtain a cost for the na√Øve strategy $$ N_{\\text{na√Øve}} ~=~ O\\bigl(n^{5}(\\varepsilon_2^2-\\varepsilon_1^2)^{-2}\\bigr), $$ which is three full powers of $n$ ($n^{5}$ vs. $n^{2}$) worse than the collective $n$-pair analysis we develop below. The lesson is that testing each pair in isolation achieves a stronger (per-pair) guarantee than we need and pays a steep statistical price; exploiting the product structure directly using just one global test is markedly more efficient.\nGlobal $n$-pair test using fidelity Given a global state $\\varrho = \\rho^{\\otimes n}$, for a single pair $\\rho$: $$ F_1 ~=~ F(\\rho,\\Phi), \\quad D_1 ~=~ D(\\rho,\\Phi), $$ and in the $n$-pair i.i.d. case we have the rules $$ F_n ~:=~ F\\bigl(\\rho^{\\otimes n},\\,\\Phi^{\\otimes n}\\bigr) ~=~ F_1^{n}, \\qquad D_n ~:=~ D\\bigl(\\rho^{\\otimes n},\\,\\Phi^{\\otimes n}\\bigr) ~\\leq~ n\\,D_1. $$ This means we can express the $n$-pair closeness conditions entirely in terms of the single-pair fidelity $F_1$, thanks to the exact tensor-product rule $F(\\rho^{\\otimes n},\\Phi^{\\otimes n}) = F(\\rho,\\Phi)^n$ (or equivalently $F_n = F_1^n$). Working directly with fidelity avoids the looser trace-distance bound $D(\\rho^{\\otimes n},\\Phi^{\\otimes n}) \\leq n\\,D(\\rho,\\Phi)$, which would give a much weaker bound than the tight scaling we get from fidelity.\nTranslating hypotheses Our goal is to distinguish $$ \\begin{cases} ~\\mathbf{H_0}: \u0026D_n \\,\\leq\\,\\varepsilon_1 \\quad\\iff\\quad \\rho^{\\otimes n}\\text{ is ‚Äúclose‚Äù to }\\Phi^{\\otimes n},\\\\[6pt] ~\\mathbf{H_1}: \u0026D_n \\,\\geq\\,\\varepsilon_2 \\quad\\iff\\quad \\rho^{\\otimes n}\\text{ is ‚Äúfar‚Äù from }\\Phi^{\\otimes n}, \\end{cases} $$ with $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$. By Fuchs‚Äìvan de Graaf, $$ 1 - F_n ~\\leq~ D_n ~\\leq~ \\sqrt{1 - F_n^{2}}, $$ so controlling $F_n$ tightly leads to a corresponding control on $D_n$. Since $F_n = F_1^{n}$, we can use this and the upper bound of Fuchs‚Äìvan de Graaf to rewrite the hypotheses as fidelity conditions per-pair: $$ \\begin{cases} ~\\mathbf{H_0}: \\quad \u0026D_n \\,\\leq\\,\\varepsilon_1 \u0026\\impliedby \u0026F_n^2 ~\\geq~ 1 - \\varepsilon_1^2 \u0026\\iff \u0026F_1 ~\\geq~ (1 - \\varepsilon_1^2)^{1/(2n)} \\\\[4pt] ~\\mathbf{H_1}: \\quad \u0026D_n \\,\\geq\\,\\varepsilon_2 \u0026\\implies \u0026F_n^2 ~\\leq~ 1 - \\varepsilon_2^2 \u0026\\iff \u0026F_1 ~\\leq~ (1 - \\varepsilon_2^2)^{1/(2n)} \\end{cases}\\quad. $$You might be wondering why we need a sufficient condition for $\\mathbf{H_0}$ and a necessary condition for $\\mathbf{H_1}$. This is because we need to guarantee that accepted states are truly close (requiring a sufficient condition) and that far states are rejected (requiring a necessary condition) to prevent false accepts.\nSoundness of acceptance (Accept $\\Rightarrow$ Close; avoid false accepts). Why do we use a ‚Äúsufficient‚Äù $F\\!\\to\\!D$ direction? We want ‚Äúif the test accepts, the global state is close‚Äù, i.e. no false accept. That needs an upper bound on distance from fidelity, which comes from the right-hand FvG: $$ D_n \\leq \\sqrt{1 - F_n^2}. $$ So we enforce $F_n \\geq \\sqrt{1 - \\varepsilon_1^2}$ (equivalently $F_1 \\geq (1 - \\varepsilon_1^2)^{1/(2n)}$), which forces $D_n \\leq \\varepsilon_1$. If instead you used the left-hand side $1 - F_n \\leq D_n$ with a threshold $F_n \\geq 1-\\varepsilon_1$, you could falsely accept a far state. Example: take $\\varepsilon_1 = 0.1$ and a state with $F_n = 0.90$. The right-hand FvG still allows $D_n$ to be as high as $\\sqrt{1 - 0.9^2} \\approx 0.436 \u003e 0.1$, so the state could be far from the target yet would be accepted by this flawed rule.\nSoundness of rejection (Far $\\Rightarrow$ Reject; again avoid false accepts). Why do we use a ‚Äúnecessary‚Äù $D\\!\\to\\!F$ direction? We want every far state to be rejected, i.e. no false accept. We start from ‚Äúfar $\\Rightarrow$ small fidelity‚Äù, and again consider the right-hand FvG: $$ D_n \\geq \\varepsilon_2 \\implies F_n \\leq \\sqrt{1 - \\varepsilon_2^2}. $$ Together with $\\sqrt{1 - 2\\delta} \\leq F_1$, this yields $\\delta \\geq \\delta_{\\text{far}} = \\frac{1}{2}[1 - (1 - \\varepsilon_2^2)^{1/n}]$. Any simpler rule like ‚Äúreject if $F_n \\leq \\tau$‚Äù with $\\tau \u003c \\sqrt{1 - \\varepsilon_2^2}$ will falsely accept some far states. Example: $\\varepsilon_2 = 0.8 \\implies \\sqrt{1 - \\varepsilon_2^2} = 0.6$; a state with $F_n = 0.55$ has $D_n = \\sqrt{1 - 0.55^2} \\approx 0.835 \u003e \\varepsilon_2$ yet would be accepted by $\\tau = 0.4$.\nWhat about completeness? We will soon see that the proof for completeness (avoiding false rejects of close states) is not a deterministic guarantee, but a statistical one. It‚Äôs the promise that if you are given a good state, your experiment will correctly identify it with very high confidence $1 - \\alpha$. This guarantee comes from the power of the Chernoff-Hoeffding concentration bound, and we will see the full reasoning below.\nRemark. You might notice that this explicit discussion of sufficient and necessary conditions was not needed for the single-pair test. This is because the single-pair proof is more direct - in that case, the Asymptotic EPR Identity Bound ($\\delta \\geq \\varepsilon^2/2$) provides a single powerful link between the trace distance $\\varepsilon$ and the error rate $\\delta$, without needing to use fidelity as an intermediary, so it implicitly contains both the necessary and sufficient logic needed to construct the test. In contrast, the multi-pair proof uses the asymmetric Fuchs-van de Graaf inequalities, forcing us to explicitly analyse the logical direction for each guarantee.\nLet‚Äôs quickly verify that $F_n^2 \\geq 1 - \\varepsilon_1^2$ is a sufficient condition for $D_n \\leq \\varepsilon_1$ ($\\mathbf{H_0}$): $$ F_n^2 \\geq 1 - \\varepsilon_1^2 \\quad\\iff\\quad 1 - F_n^2 \\leq \\varepsilon_1^2 $$ by rearranging. Substituting this into the upper bound of Fuchs‚Äìvan de Graaf yields $$ D_n ~\\leq~ \\sqrt{1 - F_n^2} ~\\leq~ \\sqrt{\\varepsilon_1^2} ~=~ \\varepsilon_1 $$ so indeed $[F_n^2 \\geq 1 - \\varepsilon_1^2] \\implies [D_n \\leq \\varepsilon_1]$. Similarly we can verify that $F_n^2 \\leq 1 - \\varepsilon_2^2$ is a necessary condition for $D_n \\geq \\varepsilon_2$ ($\\mathbf{H_1}$) by plugging $\\mathbf{H_1}$ into the upper bound of Fuchs‚Äìvan de Graaf: $$ \\varepsilon_2 \\leq D_n \\quad\\implies\\quad \\varepsilon_2 ~\\leq~ D_n ~\\leq~ \\sqrt{1 - F_n^2}. $$ Rearranging $$ \\varepsilon_2 \\leq \\sqrt{1 - F_n^2} \\quad\\iff\\quad F_n^2 \\leq 1 - \\varepsilon_2^2 $$ immediately shows that $[D_n \\geq \\varepsilon_2] \\implies [F_n^2 \\leq 1 - \\varepsilon_2^2]$ as required.\nDefining the error rate thresholds Lemma (single-pair oracle asymptotic link). For one call to $\\mathbb{O}(\\rho_{AB})$, with $\\delta = \\Pr[Y = 1 \\mid M = 1]$, we have $F(\\rho_{AB}, \\Phi) \\geq \\sqrt{1 - 2\\delta}$.\nProof sketch. This lemma is a direct consequence of the Asymptotic EPR Identity Bound established in the single-pair analysis. Since the oracle $\\mathbb{O}(\\rho_{AB})$ is simply a procedural reframing of a single round of that protocol, the fundamental relationship between the true error rate $\\delta$ and the fidelity $F$ remains unchanged. $\\quad\\square$\nUsing this lemma directly, the link between fidelity $F_1$ and true error rate $\\delta$ is $$ F_1 \\geq \\sqrt{1 - 2\\delta} \\quad\\iff\\quad \\delta \\geq \\frac{1 - F_1^2}{2}. $$ We will use this relation to define thresholds on $\\delta$.\nConvention. For each basis, we relabel Bob‚Äôs outcomes if needed so the mismatch rate is $\\leq 1/2$ (i.e. replace $\\delta_b$ by $\\min \\{\\delta_b, 1 - \\delta_b\\}$). With this standard symmetrisation, the aggregated $\\delta \\in [0, 1/2]$ and the bound $F_1 \\geq \\sqrt{1-2\\delta}$ is always meaningful.\nConcretely, let $$ f(\\varepsilon) := \\frac{1 - (1 - \\varepsilon^2)^{1/n}}{2}, $$ and $$ \\qquad \\delta_{\\text{close}} := \\frac{1 - (1 - \\varepsilon_1^2)^{1/n}}{2} = f(\\varepsilon_1), \\qquad \\delta_{\\text{far}} := \\frac{1 - (1 - \\varepsilon_2^2)^{1/n}}{2} = f(\\varepsilon_2). $$These choices are justified as follows:\n(Close) If $\\delta \\leq \\delta_{\\text{close}}$, then $F_1 \\geq \\sqrt{1 - 2\\delta} \\geq \\sqrt{1-2\\delta_{\\text{close}}}$, hence $$ F_n \\geq (1 - 2\\delta_{\\text{close}})^{n/2} = \\sqrt{1 - \\varepsilon_1^{2}}, $$ so from above $D_n \\leq \\varepsilon_1$.\n(Far) If $D_n \\geq \\varepsilon_2$, then $F_n \\leq \\sqrt{1 - \\varepsilon_2^{2}}$, i.e. $F_1 \\leq (1 - \\varepsilon_2^{2})^{1/(2n)}$. Combining with $\\sqrt{1 - 2\\delta} \\leq F_1$ forces $$ 1 - 2\\delta \\leq (1 - \\varepsilon_2^{2})^{1/n} \\quad\\implies\\quad \\delta \\geq \\delta_{\\text{far}}. $$ Bounding the promise gap The promise gap in $\\delta$ is $$ \\Delta_{\\delta} ~=~ \\delta_{\\text{far}} - \\delta_{\\text{close}} ~=~ f(\\varepsilon_2) - f(\\varepsilon_1). $$ To get a lower bound on the promise gap, we first note that $$ f(\\varepsilon) = \\frac{1 - (1 - \\varepsilon^2)^{1/n}}{2} $$ is continuous on $[0, 1]$ for any $n \\geq 2$; we only consider $n \\geq 2$ since $n$ is the number of EPR pairs and so $n = 1$ reduces to the single-pair test. Indeed, $f$ is built by composing several maps on $[0, 1]$:\n$\\varepsilon \\mapsto \\varepsilon^2$ (continuous), $x \\mapsto 1 - x$ (continuous), $y \\mapsto y^{1/n}$ (continuous for $y \\geq 0$). Each of these components is continuous on the domain $[0, 1]$. Hence their composition, $f$, is also continuous on the closed interval $[0, 1]$. By the fundamental theorem of calculus, $$ \\Delta_\\delta = f(\\varepsilon_2)-f(\\varepsilon_1) = \\int_{\\varepsilon_1}^{\\varepsilon_2} f'(\\varepsilon)\\,d\\varepsilon. $$ For $n\\ge2$, differentiating $f(\\varepsilon)$ gives $$ f'(\\varepsilon) = \\frac{\\varepsilon}{n}(1 - \\varepsilon^2)^{\\frac{1}{n} - 1}. $$ Since $0 \\leq \\varepsilon \u003c 1$ implies $1 - \\varepsilon^2 \\in (0, 1]$ and $\\frac{1}{n} - 1 \\leq 0$ as $n \\geq 2$, we have $$ (1 - \\varepsilon^2)^{\\frac{1}{n} - 1} \\geq 1 \\qquad\\left[\\,\\forall \\varepsilon \\in [0, 1)\\,\\right]. $$ Multiplying through by $\\varepsilon/n$ we get $$ f'(\\varepsilon) \\geq \\frac{\\varepsilon}{n}. $$ Therefore, $$ \\Delta_\\delta = \\int_{\\varepsilon_1}^{\\varepsilon_2} f'(\\varepsilon)\\,d\\varepsilon ~\\geq~ \\int_{\\varepsilon_1}^{\\varepsilon_2}\\frac{\\varepsilon}{n}\\,d\\varepsilon =\\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n}. $$Taking $\\varepsilon_2\\to 1^{-}$ (and using continuity of $f$) shows the same bound holds when $\\varepsilon_2 = 1$. Hence, for all $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$, $$ \\Delta_\\delta \\geq \\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n}. $$ Note. At $\\varepsilon=1$, the factor $(1 - \\varepsilon^2)^{\\frac{1}{n} - 1}$ diverges (for $n \u003e 2$), which only strengthens $(1 - \\varepsilon^2)^{\\frac{1}{n} - 1} \\geq 1$ and $f'(\\varepsilon) \\geq \\varepsilon/n$. The integral is interpreted as a limit from below when the upper limit is $1$.\nDecision rule and sample complexity Define a margin $$ t := \\frac{\\Delta_{\\delta}}{2} = \\frac{\\delta_{\\text{far}} - \\delta_{\\text{close}}}{2}. $$ Pick a single cutoff inside the gap (the midpoint): $$ \\kappa := \\frac{\\delta_{\\text{close}} + \\delta_{\\text{far}}}{2} = \\frac{f(\\varepsilon_1) + f(\\varepsilon_2)}{2}. $$ After running the protocol and computing the empirical mismatch rate $\\hat\\delta$ on the matching-basis rounds $S$, we define the decision rule as\n$$ \\textbf{Decision rule (easy case)} = \\begin{cases} \\text{‚Äúclose‚Äù} \u0026 \\text{if } \\hat\\delta \\leq \\kappa,\\\\ \\text{‚Äúfar‚Äù} \u0026 \\text{if } \\hat\\delta \u003e \\kappa. \\end{cases} $$ On matching-basis rounds, the indicators $\\{ Y_i \\}_{i \\in S}$ are i.i.d. Bernoulli random variables with mean $\\delta$. Chernoff‚ÄìHoeffding gives, for any $t \u003e 0$, $$ \\Pr\\!\\left[|\\hat\\delta - \\delta| \\geq t\\right] \\leq 2e^{-2|S|t^2}. $$ Completeness ($\\delta \\leq \\delta_{\\text{close}}$): If the good event $|\\hat\\delta - \\delta| \u003c t$ holds, then $\\hat\\delta \\leq \\delta_{\\text{close}} + t = \\kappa \\Rightarrow$ accept.\nSoundness ($\\delta \\geq \\delta_{\\text{far}}$): If $|\\hat\\delta-\\delta| \u003c t$, then $\\hat\\delta \u003e \\delta_{\\text{far}} - t = \\kappa \\Rightarrow$ reject.\nTherefore, each error (completeness or soundness) occurs only if $|\\hat\\delta-\\delta|\\geq t$ (the bad event). To make this probability $\\leq \\alpha$, it suffices that $$ 2e^{-2|S|t^2} \\leq \\alpha \\quad\\iff\\quad |S| \\geq \\frac{2}{\\Delta_\\delta^{2}}\\,\\ln\\!\\frac{2}{\\alpha} \\qquad (t = \\Delta_\\delta/2). $$ The bound on $\\Delta_\\delta$ from the integral earlier states that $$ \\Delta_\\delta \\geq \\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n}. $$ From this, we can derive that $$ \\begin{aligned} \\Delta_\\delta ~\\geq~ \\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n} \u0026{\\quad\\iff\\quad} \\Delta_\\delta^2 ~\\geq~ \\left(\\frac{\\varepsilon_2^2 - \\varepsilon_1^2}{2n}\\right)^2 \\\\[10pt]\u0026{\\quad\\iff\\quad} \\Delta_\\delta^2 ~\\geq~ \\frac{\\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^2}{4n^2} \\\\[10pt]\u0026{\\quad\\iff\\quad} \\frac{1}{\\Delta_\\delta^2} ~\\leq~ \\frac{4n^2}{\\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^2} \\\\[15pt]\u0026{\\quad\\iff\\quad} \\frac{2}{\\Delta_\\delta^2} \\ln \\frac{2}{\\alpha} ~\\leq~ \\frac{8n^2}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2} \\ln \\frac{2}{\\alpha} \\quad[\\,=: L\\,]. \\end{aligned} $$ Since $\\Delta_\\delta \\geq (\\varepsilon_2^2 - \\varepsilon_1^2)/(2n)$ and $\\frac{2}{\\Delta_\\delta^2}\\,\\ln\\!\\frac{2}{\\alpha}$ is strictly decreasing in $\\Delta_\\delta$, the true requirement is always at most $L$. Therefore, choosing $|S| \\geq L$ guarantees the condition is satisfied for all admissible $\\Delta_\\delta$: $$ |S| \\geq \\underbrace{\\frac{8\\,n^2}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2}\\,\\ln\\!\\frac{2}{\\alpha}}_{\\text{Our choice (worst-case }L\\text{)}} \\quad\\geq\\quad \\underbrace{\\frac{2}{\\Delta_\\delta^{2}}\\,\\ln\\!\\frac{2}{\\alpha}}_{\\text{What we actually need}}. $$ In other words, a sufficient condition for $|S|$ is: $$ |S| ~\\geq~ \\frac{8\\,n^2}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2}\\,\\ln\\!\\frac{2}{\\alpha}. $$ As before, only about half of the $N$ rounds are matching-basis. Taking $N = 4|S|$ (by the same argument from the single-pair case), $$ N ~\\geq~ \\frac{32\\,n^2}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2}\\,\\ln\\!\\frac{2}{\\alpha} \\qquad\\left[= O\\left(n^2\\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^{-2}\\right)\\right]. $$So it turns out that extending the test from a single pair to $n$ i.i.d. pairs is not free: the price is a quadratic blow-up in sample complexity, which is intuitive and expected when you consider the difference in the guarantees. Certifying that the entire collection of $n$ states is globally $\\varepsilon$-close is a much stricter requirement than certifying a single state. This is because a tiny imperfection in each pair, when compounded over the tensor product of all $n$ states, can result in a large global deviation. To compensate for this, the required fidelity of each pair must be much higher. This in turn forces the promise gap $\\Delta_\\delta$ for the true error rate $\\delta$ to become approximately $n$ times narrower, squeezing the thresholds for ‚Äúclose‚Äù and ‚Äúfar‚Äù states into a much smaller window near zero.\nThe reason for this is that our promise is about the global state ($\\varrho$) of all $n$ pairs. For the global state to be nearly perfect (i.e. have a high global fidelity $F_n = F_1^n$), the fidelity of each single pair ($F_1$) must be extremely close to $1$. Since the true error rate $\\delta$ is a direct measure of the imperfection in a single pair, this extremely high fidelity requirement forces $\\delta$ to be (comparatively) much smaller than it would be in the single-pair test. As a result, this effectively ‚Äúsqueezes‚Äù the entire range of relevant error rates into a tiny window near zero, which makes the absolute gap between our $\\delta_{\\text{close}}$ and $\\delta_{\\text{far}}$ thresholds narrower.\nA core principle of statistics is that the uncertainty of an estimated average is proportional to the inverse square root of the number of samples (in our case, this is $1 / \\sqrt{|S|}$). To reliably measure a promise gap that is $n$ times smaller, our estimate for $\\Delta_\\delta$ must be $n$ times more precise. Achieving this $n$-fold increase in precision requires an $n^2$-fold increase in the number of samples, which leads directly to the $O(n^2)$ scaling in complexity we‚Äôre seeing. Putting everything together succinctly:\nTheorem (Finite-sample tolerant EPR identity test, i.i.d. product version).\nFor brevity, write $$ \\rho = \\rho_{AB},\\qquad \\Phi = \\ket{\\text{EPR}}\\bra{\\text{EPR}}_{AB}. $$ Fix $n \\geq 2$. There are two i.i.d. notions here, and we use both:\nWithin-state (coordinate-wise) i.i.d. - the global hypotheses are tensor powers $\\rho^{\\otimes n}$ vs. $\\Phi^{\\otimes n}$ (identical across the $n$ coordinates); Across-trials (time-wise) i.i.d. - each call to the oracle $\\mathbb{O}(\\rho)$ uses a fresh, independent preparation of $\\rho$. Fix global trace-distance tolerances $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$ and confidence $1 - \\alpha$. Define $$ \\begin{aligned} \u0026f(\\varepsilon) = \\frac{1}{2}\\!\\left[1 - (1 - \\varepsilon^2)^{1/n}\\right]\u0026,\u0026 \u0026\\delta_{\\text{close}} = f(\\varepsilon_1), \\\\[10pt]\u0026\\delta_{\\text{far}} = f(\\varepsilon_2)\u0026,\u0026 \\qquad \u0026\\kappa = \\frac{\\delta_{\\text{close}} + \\delta_{\\text{far}}}{2}. \\end{aligned} $$ Make $$ N ~\\geq~ \\frac{32\\,n^2}{\\left( \\varepsilon_2^2 - \\varepsilon_1^2 \\right)^2}\\,\\ln\\!\\frac{2}{\\alpha} \\qquad\\left[= O\\left(n^2\\left(\\varepsilon_2^2 - \\varepsilon_1^2\\right)^{-2}\\right)\\right] $$ independent calls to $\\mathbb{O}(\\rho)$, and compute the observed error rate $\\hat{\\delta}$. Let the decision rule be to accept iff $\\hat{\\delta} \\leq \\kappa$. Then, with sample cost $N$:\nIf $D(\\rho^{\\otimes n},\\Phi^{\\otimes n}) \\leq \\varepsilon_1$, the test accepts with probability $\\geq 1 - \\alpha$. If $D(\\rho^{\\otimes n},\\Phi^{\\otimes n}) \\geq \\varepsilon_2$, the test rejects with probability $\\geq 1 - \\alpha$. If $\\varepsilon_1 \u003c D(\\rho^{\\otimes n},\\Phi^{\\otimes n}) \u003c \\varepsilon_2$, no guarantee is provided; the test may accept or reject. That completes the ‚Äúeasy‚Äù i.i.d. case. Next, we‚Äôll remove the identical-pair assumption.\nMedium case (independent, non-identical pairs) Here the joint state is a product of possibly different single-pair states $$ \\varrho = \\rho_{1}\\otimes\\rho_{2}\\otimes\\dots\\otimes\\rho_{n}, \\quad \\text{vs. } ~ \\Phi^{\\otimes n}. $$ with no entanglement across copies but with potentially different single-pair states $\\rho_i$. In the context of BB84, each copy is attacked ‚Äúfrom scratch‚Äù (no cross-round entanglement) but Eve may prepare a different state in every round.\nExactly as before, we want a single classical test that, with failure probability at most $\\alpha$, distinguishes $$ \\begin{cases} ~\\text{H}_0\\text{ (‚Äúclose‚Äù)} \u0026: D_n \\leq \\varepsilon_1,\\\\[6pt] ~\\text{H}_1\\text{ (‚Äúfar‚Äù)} \u0026: D_n \\geq \\varepsilon_2, \\end{cases} \\qquad 0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1, $$ where $D_n := D(\\rho_1 \\otimes \\dots \\otimes \\rho_n, \\Phi^{\\otimes n})$.\nFor each coordinate $i$ (i.e. each position in the $n$-tuple of pairs), let $$ \\delta_i := \\Pr[\\text{mismatch} \\mid \\text{matching bases on coordinate } i] $$ be the true mismatch probability for that coordinate, and let $$ \\hat{\\delta}_i := \\frac{\\#\\{\\text{mismatches on coordinate } i\\}}{\\#\\{\\text{matching-basis trials on coordinate } i\\}} $$ be its empirical mismatch rate from the data.\nIn the easy case, all $\\delta_i$ are identical because of the i.i.d. assumption. So pooling all matching-basis trials into a single $\\hat{\\delta}$ is equivalent to estimating $\\delta_i$ for any $i$. And as we‚Äôve seen, we only need one concentration bound.\nHowever, for our medium (independent, non-identical) case, the $\\delta_i$ may differ. To certify all coordinates simultaneously, we need to guarantee that $|\\hat{\\delta}_i - \\delta_i|$ is small for every $i$. This unfortunately forces us to run the test on each coordinate separately and then take a union bound over the $n$ coordinates, and we‚Äôll soon see that this adds an extra $n \\log n$ factor in the sample complexity on top of the easy case.\nLet‚Äôs get started. First, we organise repeated i.i.d. copies of the entire $n$-tuple into blocks. Note that in the medium case (in fact, for all three cases) we are still given i.i.d. copies of $$ \\varrho = \\rho_1 \\otimes \\rho_2 \\otimes \\cdots \\otimes \\rho_n, $$ but within $\\varrho$, the individual $\\rho_i$ may be different.\nDefinition (block). A block is one i.i.d. copy of the product state $$ \\varrho = \\rho_1 \\otimes \\rho_2 \\otimes \\cdots \\otimes \\rho_n. $$ In other words, a block is the basic unit of data for the $n$-pair test: after preparing a block, we make independent calls to the single-pair oracle $\\mathbb{O}$ on each coordinate $i = 1, \\dots, n$. The block then outputs $$ \\bigl\\{ (M_{(j, i)},\\,Y_{(j, i)}) \\bigr\\}_{i=1}^n, $$ where $j$ indexes the block. Explicitly, in block $j$ we obtain for each coordinate $i$:\na matching indicator $M_{(j, i)} \\in \\{0, 1\\}$, which is $1$ if Alice‚Äôs and Bob‚Äôs bases matched for that pair; and, if $M_{(j, i)} = 1$, a mismatch bit $Y_{(j, i)} \\in \\{0, 1\\}$ with $\\mathbb{E}[Y_{(j,i)} \\mid M_{(j,i)} = 1] = \\delta_i$. We repeat this procedure over $R$ independent blocks. The entire dataset forms an $R \\times n$ table: $$ \\begin{array}{c|cccc} \\text{block } j \u0026 i=1 \u0026 i=2 \u0026 \\cdots \u0026 i=n \\\\ \\hline 1 \u0026 (M_{(1,1)}, Y_{(1,1)}) \u0026 (M_{(1,2)}, Y_{(1,2)}) \u0026 \\cdots \u0026 (M_{(1,n)}, Y_{(1,n)}) \\\\ 2 \u0026 (M_{(2,1)}, Y_{(2,1)}) \u0026 (M_{(2,2)}, Y_{(2,2)}) \u0026 \\cdots \u0026 (M_{(2,n)}, Y_{(2,n)}) \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ R \u0026 (M_{(R,1)}, Y_{(R,1)}) \u0026 (M_{(R,2)}, Y_{(R,2)}) \u0026 \\cdots \u0026 (M_{(R,n)}, Y_{(R,n)}) \\end{array} $$where each cell comes from a single call to $\\mathbb{O}(\\rho_i)$. In total, we have made $N = n \\cdot R$ calls to the oracle. In this table:\nRows (fixed $j$): contain all $n$ coordinates in the same block, prepared together as one copy of $\\varrho$. The $\\rho_i$ can be different, so entries in the same row are generally not identically distributed. Columns (fixed $i$): contain the same coordinate across $R$ i.i.d. blocks. These entries are i.i.d. samples from $\\rho_i$, since each block contains a fresh copy of it in position $i$. Therefore, when analysing each coordinate ($i$) separately, the $R$ entries in a column are independent and identically distributed. The union bound will later account for all $n$ coordinates at once.\nPer-coordinate estimator and decision rule For each coordinate $i$, define the set of matching-basis rounds across blocks (columns) $$ S_i := \\{\\, j \\in \\{1, \\dots, R\\} : M_{(j, i)} = 1 \\,\\}. $$The empirical mismatch rate on coordinate $i$ is $$ \\hat\\delta_i ~=~ \\frac{1}{|S_i|} \\sum_{j \\in S_i} Y_{(j, i)} \\quad\\text{(defined when }|S_i| \u003e 0\\text{)}. $$Recall the per-coordinate true parameters $\\delta_i = \\Pr[\\text{mismatch} \\mid \\text{match on }i]$.\nAs in the i.i.d. case, define the function $$ f(\\varepsilon) := \\tfrac{1}{2}\\!\\left[1 - (1 - \\varepsilon^2)^{1/n}\\right], $$ the thresholds $$ \\delta_{\\text{close}} := f(\\varepsilon_1), \\quad \\delta_{\\text{far}} := f(\\varepsilon_2), $$ the (midpoint) cutoff $$ \\kappa := \\tfrac{1}{2}(\\delta_{\\text{close}} + \\delta_{\\text{far}}), $$ and set the margin $$ t := \\tfrac{1}{2}(\\delta_{\\text{far}} - \\delta_{\\text{close}}). $$ (As before, $\\delta_{\\text{far}} - \\delta_{\\text{close}} = \\Delta_\\delta \\geq \\frac{\\varepsilon_2^2-\\varepsilon_1^2}{2n}$.)\nDecision rule (medium case).\nAccept iff $$ \\max_{i \\in [n]} \\hat\\delta_i \u003c \\kappa. $$ In other words, we accept if and only if the worst-case error rate is strictly less than our cutoff $\\kappa$, meaning all our error rates $\\hat\\delta_i$ has to pass the cutoff test.\nDefine the good event $$ \\mathcal G ~:=~ \\bigcap_{i=1}^n \\left\\{\\,|\\hat\\delta_i - \\delta_i| \u003c t\\,\\right\\}, $$ i.e. every column concentrates within the margin $t$. We will set $R$ (hence total oracle calls $N = nR$) so that $\\Pr[\\mathcal G] \\geq 1 - \\alpha$ using concentration bounds.\nLet‚Äôs quickly show completeness and soundness of our decision rule.\nCompleteness (close $\\Rightarrow$ accept). If every coordinate is close i.e. $\\delta_i \\leq \\delta_{\\text{close}}$ for all $i$, then on the good event $\\mathcal{G}$, $$ \\hat\\delta_i \u003c \\delta_i + t ~\\le~ \\delta_{\\text{close}} + t ~=~ \\kappa \\quad\\implies\\quad \\max_i \\hat\\delta_i \u003c \\kappa, $$ so we accept.\nSoundness (far $\\Rightarrow$ reject). This requires some work. If the global state $\\varrho = \\otimes_{i=1}^n \\rho_i$ is far i.e. $D(\\varrho, \\Phi^{\\otimes n}) \\geq \\varepsilon_2$, then by the (right-hand) Fuchs‚Äìvan de Graaf inequality, the global fidelity, $F_n$, satisfies $$ F_n := F(\\varrho, \\Phi^{\\otimes n}) \\leq \\sqrt{1 - \\varepsilon_2^2}. $$ Fidelity is multiplicative even for heterogeneous products: $$ F_n = \\prod_{i=1}^n F_i, \\quad\\text{where } F_i := F(\\rho_i,\\Phi). $$ Let $\\tau := (1 - \\varepsilon_2^2)^{1/(2n)}$, so $\\tau^n = \\sqrt{1 - \\varepsilon_2^2}$. If every coordinate satisfied $F_i \u003e \\tau$, then $$ F_n ~=~ \\prod_{i=1}^n F_i ~\u003e~ \\tau^n ~=~ \\sqrt{1 - \\varepsilon_2^2}, $$ contradicting the bound for $F_n$ above. Therefore, there has to exist some coordinate $i^\\star$ with $$ F_{i^\\star} ~\\leq~ \\tau ~=~ (1 - \\varepsilon_2^2)^{1/(2n)}. $$ Now use the single-pair link $F_i \\geq \\sqrt{1 - 2\\delta_i}$ from the lemma above. Rearranging $$ 1 - 2\\delta_{i^\\star} ~\\leq~ F_{i^\\star}^2 ~\\leq~ \\tau^2 = (1 - \\varepsilon_2^2)^{1/n} $$ gives $$ \\delta_{i^\\star} ~\\geq~ \\frac{1 - (1 - \\varepsilon_2^2)^{1/n}}{2} ~=~ f(\\varepsilon_2) ~=~ \\delta_{\\text{far}}. $$ On the good event $\\mathcal{G}$, $$ \\hat\\delta_{i^\\star} ~\u003e~ \\delta_{i^\\star} - t ~\\geq~ \\delta_{\\text{far}} - t ~=~ \\kappa, $$ so $$ \\max_i \\hat\\delta_i \\geq \\hat\\delta_{i^\\star} \u003e \\kappa, $$ and we reject.\nSo all we owe now is to make the good event $\\mathcal{G}$ hold with probability at least $1 - \\alpha$ using a concentration bound.\nConcentration: all coordinates at once Complete writeup\nTheorem (Finite-sample tolerant test, medium case)\nLet $\\varrho = \\rho_1 \\otimes \\cdots \\otimes \\rho_n$. Fix $0 \\leq \\varepsilon_1 \u003c \\varepsilon_2 \\leq 1$ and failure probability $\\alpha \\in (0, 1)$. Define $$ \\begin{aligned} \u0026f(\\varepsilon) = \\frac{1}{2}\\!\\left[1 - (1 - \\varepsilon^2)^{1/n}\\right]\u0026,\u0026 \u0026\\delta_{\\text{close}} = f(\\varepsilon_1), \\\\[10pt]\u0026\\delta_{\\text{far}} = f(\\varepsilon_2)\u0026,\u0026 \\qquad \u0026\\kappa = \\frac{\\delta_{\\text{close}} + \\delta_{\\text{far}}}{2}. \\end{aligned} $$ Repeat $R$ times: prepare one block (index $j$), and for each coordinate $i \\in [n]$ make one call to $\\mathbb{O}(\\rho_i)$, yielding $(M_{(j,i)},Y_{(j,i)})$. For each $i$, let $S_i = \\{j: M_{(j, i)} = 1\\}$ and compute $$ \\hat\\delta_i = \\frac{1}{|S_i|} \\sum_{j\\ in S_i} Y_{(j, i)} \\qquad(|S_i| \u003e 0). $$ In total we have called the oracle $N$ times. For the test, accept iff $$ \\max_{i \\in [n]} \\hat\\delta_i \u003c \\kappa. $$If the sample complexity $$ R ~=~ \\frac{32\\,n^{2}}{(\\varepsilon_2^2 - \\varepsilon_1^2)^2}\\,\\ln\\!\\frac{4n}{\\alpha} \\quad\\iff\\quad N = nR ~\\geq~ \\frac{32\\,n^3}{(\\varepsilon_2^2-\\varepsilon_1^2)^2}\\,\\ln\\!\\frac{4n}{\\alpha}, $$ then:\n(Completeness) If $D(\\varrho, \\Phi^{\\otimes n}) \\leq \\varepsilon_1$, then the test accepts with probability at least $1 - \\alpha$. (Soundness) If $D(\\varrho, \\Phi^{\\otimes n}) \\geq \\varepsilon_2$, the test rejects with probability at least $1 - \\alpha$. No guarantee can be made in the promise gap $\\varepsilon_1 \u003c D(\\varrho, \\Phi^{\\otimes n}) \u003c \\varepsilon_2$; the test may accept or reject. A quick sanity check (why it‚Äôs costlier than the i.i.d. case): The global closeness promise forces every coordinate‚Äôs fidelity to be extremely high. That squeezes each per-coordinate mismatch threshold to a gap of width $\\Delta_\\delta=\\Theta\\big((\\varepsilon_2^2-\\varepsilon_1^2)/n\\big)$. Estimating $n$ such parameters uniformly within that tiny gap costs $\\tilde\\Theta(n^2)$ matching samples per coordinate (hence $R=\\tilde\\Theta(n^2)$ blocks) and therefore $N=nR=\\tilde\\Theta(n^3)$ total oracle calls, with the extra $\\ln n$ from the union bound across coordinates.\n","wordCount":"5214","inLanguage":"en","datePublished":"2025-08-08T17:42:31+01:00","dateModified":"2025-08-08T17:42:31+01:00","author":{"@type":"Person","name":"Howard Cheung"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://teaegg.net/research/urss/n-epr-test/"},"publisher":{"@type":"Organization","name":"ùóßùóòùóî‚Ä¢ùóòùóöùóö","logo":{"@type":"ImageObject","url":"https://teaegg.net/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://teaegg.net/ title=Home>ùóßùóòùóî‚Ä¢ùóòùóöùóö</a><div class=logo-switches><button id=theme-toggle title="Toggle theme" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://teaegg.net/aboutme/ title="About Me"><span>About Me</span></a></li><li><a href=https://teaegg.net/journal/ title=Journal><span>Journal</span></a></li><li><a href=https://teaegg.net/research/ title=Research><span>Research</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://teaegg.net/>üè† Home</a>&nbsp;¬ª&nbsp;<a href=https://teaegg.net/research/>üî¨ Research</a>&nbsp;¬ª&nbsp;<a href=https://teaegg.net/research/urss/>üîêüí° Undergraduate Research Support Scheme (URSS)</a></div><h1 class="post-title entry-hint-parent">Classical tolerant identity test for multiple EPR states</h1><div class=post-meta><span title='2025-08-08 17:42:31 +0100 +0100'>August 8, 2025</span>&nbsp;¬∑&nbsp;25 min&nbsp;¬∑&nbsp;Howard Cheung</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#change-in-notation aria-label="Change in notation">Change in notation</a><ul><li><a href=#oracle aria-label="Oracle $\mathbb{O}(\rho_{AB})$">Oracle $\mathbb{O}(\rho_{AB})$</a></li><li><a href=#single-pair-protocol-post-processing-over--oracle-calls aria-label="Single-pair protocol (post-processing over $N$ oracle calls)">Single-pair protocol (post-processing over $N$ oracle calls)</a></li></ul></li><li><a href=#do-re-mi- aria-label="do-rE-MI ‚ô´">do-rE-MI ‚ô´</a></li><li><a href=#easy-case-iid-pairs aria-label="Easy case (i.i.d. pairs)">Easy case (i.i.d. pairs)</a><ul><li><a href=#a-na%c3%afve-per-pair-approach-using-trace-distance aria-label="A na√Øve per-pair approach using trace distance">A na√Øve per-pair approach using trace distance</a></li><li><a href=#global--pair-test-using-fidelity aria-label="Global $n$-pair test using fidelity">Global $n$-pair test using fidelity</a><ul><li><a href=#translating-hypotheses aria-label="Translating hypotheses">Translating hypotheses</a></li><li><a href=#defining-the-error-rate-thresholds aria-label="Defining the error rate thresholds">Defining the error rate thresholds</a></li><li><a href=#bounding-the-promise-gap aria-label="Bounding the promise gap">Bounding the promise gap</a></li><li><a href=#decision-rule-and-sample-complexity aria-label="Decision rule and sample complexity">Decision rule and sample complexity</a></li></ul></li></ul></li><li><a href=#medium-case-independent-non-identical-pairs aria-label="Medium case (independent, non-identical pairs)">Medium case (independent, non-identical pairs)</a><ul><li><a href=#per-coordinate-estimator-and-decision-rule aria-label="Per-coordinate estimator and decision rule">Per-coordinate estimator and decision rule</a></li><li><a href=#concentration-all-coordinates-at-once aria-label="Concentration: all coordinates at once">Concentration: all coordinates at once</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=change-in-notation>Change in notation<a hidden class=anchor aria-hidden=true href=#change-in-notation>#</a></h2><p>With the <a href=../epr-tolerant-identity-testing>tolerant identity test</a> for a single state $\rho_{AB}$ complete, we now turn to the problem of certifying multiple EPR pairs. Before analysing the multi-pair scenarios, it helps to reframe one round of the single-pair matching-outcomes protocol as a callable oracle $\mathbb{O}$ that consumes a fresh pair of $\rho_{AB}$ and outputs a classical bit when the bases match.</p><p>Suppose Alice and Bob share a number of independent pairs of an unknown state $\rho_{AB}$. We package one measurement round into a callable <strong>oracle</strong> $\mathbb{O}(\rho_{AB})$ and then do simple classical post-processing. Combining $N$ oracle calls and doing the simple classical post-processing is equivalent to the $N$-round protocol!</p><h3 id=oracle>Oracle $\mathbb{O}(\rho_{AB})$<a hidden class=anchor aria-hidden=true href=#oracle>#</a></h3><p><strong>Input:</strong> one fresh pair of the bipartite state $\rho_{AB}$.</p><p><strong>Procedure:</strong></p><ol><li>Pick two independent basis bits $\theta \in \{ 0, 1 \}$ and $\tilde{\theta} \in \{ 0, 1 \}$ uniformly at random. Here $\theta = 0$ means &ldquo;standard basis ($Z$)&rdquo; and $\theta = 1$ means &ldquo;Hadamard basis ($X$)&rdquo;.</li><li>Measure the $A$ subsystem of $\rho_{AB}$ in basis $\theta$ to obtain $x \in \{0, 1\}$ and the $B$ subsystem in basis $\tilde{\theta}$ to obtain $\tilde{x} \in \{0, 1\}$.</li><li>If $\theta = \tilde{\theta}$ (matching bases), set $M = 1$ and $Y = \mathbf{1}[x \neq \tilde x] \in \{0, 1\}$; otherwise $\theta \neq \tilde{\theta}$ (mismatched bases), set $M = 0$ and $Y = \bot$.</li></ol><p><strong>Output:</strong> a pair $(M, Y)$ with $M \in \{0, 1\}$ and $Y \in \{\bot, 0, 1\}$.</p><p>The oracle hides the two-party details: one call consumes one fresh pair $\rho_{AB}$. When it emits a bit (i.e. $Y \neq \bot$), that bit is a Bernoulli trial with mean $\delta$, which is the <em>true</em> matching-basis mismatch probability:</p>$$
\mathbb{E}[\,Y \mid M = 1\,] = \delta \in[0, \tfrac{1}{2}] \quad\text{(after the standard relabelling per basis)}.
$$<p>(We relabel Bob&rsquo;s outcomes per basis so each per-basis mismatch rate is $\leq 1/2$; see the convention below.)</p><p>This oracle encapsulates the entire procedure of basis selection, local measurement, and comparison. Each call to the oracle is statistically identical to one round of the original protocol. This formalism is particularly useful for the medium and hard cases below, as it allows us to reason about the statistical properties of the test without getting bogged down in the implementation details of each round.</p><blockquote><p><strong>Remark.</strong> &ldquo;Sequential&rdquo; vs &ldquo;parallel&rdquo; only affects implementation. Equivalently one can run many calls (measure many pairs) in parallel and reveal bases afterwards over a classical channel; the distribution of $(M, Y)$ is identical.</p></blockquote><h3 id=single-pair-protocol-post-processing-over--oracle-calls>Single-pair protocol (post-processing over $N$ oracle calls)<a hidden class=anchor aria-hidden=true href=#single-pair-protocol-post-processing-over--oracle-calls>#</a></h3><ol><li>Make $N$ independent calls to $\mathbb{O}(\rho_{AB})$, where $N \in \mathbb{N}$ will be bounded by the analysis below. From those $N$ calls we obtain $(M_1, Y_1), \ldots, (M_N, Y_N)$.</li><li>Define the set of matching-basis rounds
$$
S = \bigl\{i \in \{1, \dots, N\} : M_i = 1 \bigr\} \subseteq \bigl\{ 1, \dots, N \bigr\}.
$$
If by rare chance $S = \varnothing$ (no matching bases at all), simply rerun the whole protocol as the probability of $S = \varnothing$ is $2^{-N}$, which is negligible for modest $N$.</li><li>Compute the <strong>observed error rate</strong>
$$
\hat{\delta} = \frac{1}{|S|}\sum_{i\in S} Y_i.
$$
which represents the mismatch fraction conditioned on matching-basis rounds.</li></ol><blockquote><p><strong>Note.</strong> This is exactly equivalent to the usual BB84-style &ldquo;announce bases and outcomes over a classical authenticated channel (CAC) and keep only the matching bases&rdquo; description; we&rsquo;ve just folded that bookkeeping into $(M_i, Y_i)$.</p></blockquote><p>With this, we can provide an alternative but mathematically equivalent tolerant identity test for one EPR state.</p><blockquote><p><strong>Theorem (Finite-sample classical tolerant identity test for the EPR state).</strong></p><p>Given i.i.d. pairs of $\rho_{AB}$, fix two trace-distance tolerances</p>$$
0 \leq \varepsilon_1 < \varepsilon_2 \leq 1,
$$<p>and the desired maximum failure probability $\alpha \in (0, 1)$. Set the cutoff</p>$$
c = \frac{\varepsilon_1^2 + \varepsilon_2^2}{4}.
$$<p>Make</p>$$
N \geq \frac{32\,\ln(2/\alpha)}{(\varepsilon_2^2 - \varepsilon_1^2)^2} \qquad\left( = O\Bigl((\varepsilon_2^2 - \varepsilon_1^2)^{-2}\Bigr) \right)
$$<p>independent calls to $\mathbb{O}(\rho_{AB})$, and compute the observed error rate $\hat{\delta}$. Let the decision rule be to accept <em><strong>iff</strong></em> $\hat{\delta} \leq c$:</p>$$
\text{Decision} =
\begin{cases}
\text{‚Äúclose‚Äù}, & \hat{\delta} \leq c,\\
\text{‚Äúfar‚Äù}, & \hat{\delta} > c.
\end{cases}
$$<p>Then the test, with sample cost $N$, provides the following guarantees:</p><ul><li>If $D(\rho_{AB}, \ket{\text{EPR}} \bra{\text{EPR}}_{AB}) \leq \varepsilon_1$, then the test <strong>accepts</strong> (outputs &ldquo;close&rdquo;) with confidence at least $1 - \alpha$.</li><li>If $D(\rho_{AB}, \ket{\text{EPR}} \bra{\text{EPR}}_{AB}) \geq \varepsilon_2$, then the test <strong>rejects</strong> (outputs &ldquo;far&rdquo;) with confidence at least $1 - \alpha$.</li><li>If $\varepsilon_1 < D(\rho_{AB}, \ket{\text{EPR}} \bra{\text{EPR}}_{AB}) < \varepsilon_2$, no guarantee is made on the outcome; the test may go either way (accept or reject).</li></ul></blockquote><hr><h2 id=do-re-mi->do-rE-MI ‚ô´<a hidden class=anchor aria-hidden=true href=#do-re-mi->#</a></h2><p>For brevity we write</p>$$
\rho = \rho_{AB},
\qquad
\Phi = \ket{\text{EPR}}\bra{\text{EPR}}_{AB}
$$<p>throughout. We introduce the global symbol $\varrho$ only when forming an $n$-pair tensor product. In particular, we will show how the same matching-outcomes protocol extends in three settings of increasing generality and difficulty:</p><ol><li><p><strong>Easy (i.i.d. pairs).</strong></p><p>All $n$ pairs are identical:</p>$$
\varrho = \rho^{\otimes n}\quad\text{vs.}\quad\Phi^{\otimes n}.
$$</li><li><p><strong>Medium (independent, non-identical pairs).</strong></p><p>Each pair may differ but remains uncorrelated:</p>$$
\varrho = \rho_1\otimes\rho_2\otimes\dots\otimes\rho_n
\quad\text{vs.}\quad
\Phi^{\otimes n}.
$$</li><li><p><strong>Hard (arbitrary adversary).</strong></p><p>The most general case allows an arbitrary $2n$-qubit state $\Sigma$, possibly entangled across pairs, against which we still wish to test closeness to $\Phi^{\otimes n}$.</p></li></ol><p>We will analyse $N$, the number of oracle calls to $\mathbb{O}$ for the single-pair protocol run needed when testing an $n$-pair hypothesis. It&rsquo;s very important to keep in mind that $N$ counts the <em>pairs consumed</em> (oracle calls), not &ldquo;blocks&rdquo;. We will only introduce &ldquo;blocks&rdquo; in the <strong>medium</strong> case, where they are actually needed.</p><blockquote><p><strong>Note.</strong> In the context of BB84, these three scenarios correspond directly to the class of attacks that an eavesdropper (Eve) might do:</p><ul><li><p><strong>Easy (i.i.d. pairs)</strong>:
Eve applies the same attack channel to each transmitted qubit independently, with no memory from one round to the next. Every round she starts from scratch, so her joint state is $\varrho = \rho^{\otimes n}$.</p></li><li><p><strong>Medium (independent, non-identical pairs)</strong>:
Eve still treats each qubit independently and measures immediately, but she may choose a different attack in each round. Her overall state is the product $\varrho = \rho_{1}\otimes\rho_{2}\otimes\dots\otimes\rho_{n}$.</p></li><li><p><strong>Hard (arbitrary adversary)</strong>:
Eve may entangle her systems across rounds and defer all measurements until the end. There is no tensor-product structure, so her state is an arbitrary $2n$-qubit $\Sigma$.</p></li></ul><p>By proving security in each model, starting with the easiest and working up to the fully coherent setting, we obtain a hierarchy of BB84 security guarantees that mirror the increasing power of potential attack by Eve. <del>From the sample complexity, we will see that a fully coherent attack (hard case) isn&rsquo;t more difficult to detect than a simple i.i.d. tensor product state (easy case)!</del> <code>&lt;- not sure about this yet</code></p></blockquote><p>We begin with the i.i.d. case as it&rsquo;s both the simplest to analyse and a useful building block for the more challenging scenarios.</p><hr><h2 id=easy-case-iid-pairs>Easy case (i.i.d. pairs)<a hidden class=anchor aria-hidden=true href=#easy-case-iid-pairs>#</a></h2><h3 id=a-na√Øve-per-pair-approach-using-trace-distance>A na√Øve per-pair approach using trace distance<a hidden class=anchor aria-hidden=true href=#a-na√Øve-per-pair-approach-using-trace-distance>#</a></h3><p>A first idea is to ignore the joint state altogether and simply run the <strong>single-pair</strong> tolerant test on each of the $n$ pairs <strong>separately</strong>, then accept only if every individual test passes. Equivalently, one could tally the per-pair mismatch indicators into a total error count and compare that sum against a scaled threshold (thanks to the i.i.d. assumption). At first glance this seems painless, but a closer look shows it is actually <em>worse</em> than the collective strategy developed below.</p><p>Recall for a single pair $\rho$:</p>$$
D_1 ~=~ D(\rho, \Phi),
$$<p>and in the $n$-pair i.i.d. case we have the bound</p>$$
D_n ~:=~ D\bigl(\rho^{\otimes n},\,\Phi^{\otimes n}\bigr) ~\leq~ n\,D_1.
$$<ul><li><strong>A sufficient per-pair condition is to shrink the tolerance.</strong>
To guarantee that the full product state $\varrho = \rho^{\otimes n}$ satisfies $D(\rho^{\otimes n}, \Phi^{\otimes n}) \leq \varepsilon_1$, the trace-distance of <em>each</em> pair must be at most $\varepsilon_1/n$; otherwise the sub-additivity bound $D_n\leq nD_1$ could exceed $\varepsilon_1$.</li><li><strong>Promise gap narrows by a factor $n$.</strong>
Replacing $\varepsilon_j$ by $\varepsilon_j/n$ shrinks the gap $\varepsilon_2^2 - \varepsilon_1^2$ by $n^{2}$. For the single-pair test the sample size scales as the inverse square of that gap, so one pair now needs
$$
O\bigl(n^{4}(\varepsilon_2^2-\varepsilon_1^2)^{-2}\bigr)
$$
samples, or equivalently oracle calls.</li><li><strong>Replicated testing scales linearly.</strong>
Running $n$ such tests and combining them multiplies the sample cost by $n$.</li></ul><p>Hence by a very high-level analysis, we obtain a cost for the na√Øve strategy</p>$$
N_{\text{na√Øve}} ~=~ O\bigl(n^{5}(\varepsilon_2^2-\varepsilon_1^2)^{-2}\bigr),
$$<p>which is three full powers of $n$ ($n^{5}$ vs. $n^{2}$) worse than the collective $n$-pair analysis we develop below. The lesson is that testing each pair in isolation achieves a <em>stronger</em> (per-pair) guarantee than we need and pays a steep statistical price; exploiting the product structure directly using just one global test is markedly more efficient.</p><hr><h3 id=global--pair-test-using-fidelity>Global $n$-pair test using fidelity<a hidden class=anchor aria-hidden=true href=#global--pair-test-using-fidelity>#</a></h3><p>Given a global state $\varrho = \rho^{\otimes n}$, for a single pair $\rho$:</p>$$
F_1 ~=~ F(\rho,\Phi),
\quad
D_1 ~=~ D(\rho,\Phi),
$$<p>and in the $n$-pair i.i.d. case we have the rules</p>$$
F_n ~:=~ F\bigl(\rho^{\otimes n},\,\Phi^{\otimes n}\bigr) ~=~ F_1^{n},
\qquad
D_n ~:=~ D\bigl(\rho^{\otimes n},\,\Phi^{\otimes n}\bigr) ~\leq~ n\,D_1.
$$<p>This means we can express the $n$-pair closeness conditions entirely in terms of the single-pair fidelity $F_1$, thanks to the exact tensor-product rule $F(\rho^{\otimes n},\Phi^{\otimes n}) = F(\rho,\Phi)^n$ (or equivalently $F_n = F_1^n$). Working directly with fidelity avoids the looser trace-distance bound $D(\rho^{\otimes n},\Phi^{\otimes n}) \leq n\,D(\rho,\Phi)$, which would give a much weaker bound than the tight scaling we get from fidelity.</p><h4 id=translating-hypotheses>Translating hypotheses<a hidden class=anchor aria-hidden=true href=#translating-hypotheses>#</a></h4><p>Our goal is to distinguish</p>$$
\begin{cases}
~\mathbf{H_0}: &D_n \,\leq\,\varepsilon_1
\quad\iff\quad \rho^{\otimes n}\text{ is ‚Äúclose‚Äù to }\Phi^{\otimes n},\\[6pt]
~\mathbf{H_1}: &D_n \,\geq\,\varepsilon_2
\quad\iff\quad \rho^{\otimes n}\text{ is ‚Äúfar‚Äù from }\Phi^{\otimes n},
\end{cases}
$$<p>with $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$. By Fuchs‚Äìvan de Graaf,</p>$$
1 - F_n ~\leq~ D_n ~\leq~ \sqrt{1 - F_n^{2}},
$$<p>so controlling $F_n$ tightly leads to a corresponding control on $D_n$. Since $F_n = F_1^{n}$, we can use this and the upper bound of Fuchs‚Äìvan de Graaf to rewrite the hypotheses as fidelity conditions per-pair:</p>$$
\begin{cases}
~\mathbf{H_0}: \quad &D_n \,\leq\,\varepsilon_1 &\impliedby &F_n^2 ~\geq~ 1 - \varepsilon_1^2
&\iff
&F_1 ~\geq~ (1 - \varepsilon_1^2)^{1/(2n)}
\\[4pt]
~\mathbf{H_1}: \quad &D_n \,\geq\,\varepsilon_2 &\implies &F_n^2 ~\leq~ 1 - \varepsilon_2^2
&\iff
&F_1 ~\leq~ (1 - \varepsilon_2^2)^{1/(2n)}
\end{cases}\quad.
$$<p>You might be wondering why we need a <u>sufficient</u> condition for $\mathbf{H_0}$ and a <u>necessary</u> condition for $\mathbf{H_1}$. This is because we need to guarantee that accepted states are truly close (requiring a sufficient condition) and that far states are rejected (requiring a necessary condition) to prevent <strong>false accepts</strong>.</p><ul><li><p><strong>Soundness of acceptance (Accept $\Rightarrow$ Close; avoid false accepts).</strong>
Why do we use a &ldquo;sufficient&rdquo; $F\!\to\!D$ direction? We want &ldquo;if the test accepts, the global state is close&rdquo;, i.e. no false accept. That needs an <em>upper</em> bound on distance from fidelity, which comes from the <em>right-hand</em> FvG:</p>$$
D_n \leq \sqrt{1 - F_n^2}.
$$<p>So we enforce $F_n \geq \sqrt{1 - \varepsilon_1^2}$ (equivalently $F_1 \geq (1 - \varepsilon_1^2)^{1/(2n)}$), which <em>forces</em> $D_n \leq \varepsilon_1$.
If instead you used the left-hand side $1 - F_n \leq D_n$ with a threshold $F_n \geq 1-\varepsilon_1$, you could falsely accept a far state. Example: take $\varepsilon_1 = 0.1$ and a state with $F_n = 0.90$. The right-hand FvG still allows $D_n$ to be as high as $\sqrt{1 - 0.9^2} \approx 0.436 > 0.1$, so the state could be far from the target yet would be accepted by this flawed rule.</p></li><li><p><strong>Soundness of rejection (Far $\Rightarrow$ Reject; again avoid false accepts).</strong>
Why do we use a &ldquo;necessary&rdquo; $D\!\to\!F$ direction? We want every far state to be rejected, i.e. no false accept. We start from &ldquo;far $\Rightarrow$ small fidelity&rdquo;, and again consider the <em>right-hand</em> FvG:</p>$$
D_n \geq \varepsilon_2 \implies F_n \leq \sqrt{1 - \varepsilon_2^2}.
$$<p>Together with $\sqrt{1 - 2\delta} \leq F_1$, this yields $\delta \geq \delta_{\text{far}} = \frac{1}{2}[1 - (1 - \varepsilon_2^2)^{1/n}]$. Any simpler rule like &ldquo;reject if $F_n \leq \tau$&rdquo; with $\tau < \sqrt{1 - \varepsilon_2^2}$ will falsely accept some far states. Example: $\varepsilon_2 = 0.8 \implies \sqrt{1 - \varepsilon_2^2} = 0.6$; a state with $F_n = 0.55$ has $D_n = \sqrt{1 - 0.55^2} \approx 0.835 > \varepsilon_2$ yet would be accepted by $\tau = 0.4$.</p></li></ul><p><strong>What about completeness?</strong>
We will soon see that the proof for completeness (avoiding <strong>false rejects</strong> of close states) is not a <em>deterministic</em> guarantee, but a <em>statistical</em> one. It&rsquo;s the promise that if you are given a good state, your experiment will correctly identify it with very high confidence $1 - \alpha$. This guarantee comes from the power of the Chernoff-Hoeffding concentration bound, and we will see the full reasoning below.</p><blockquote><p><strong>Remark.</strong> You might notice that this explicit discussion of sufficient and necessary conditions was not needed for the single-pair test. This is because the single-pair proof is more direct - in that case, the Asymptotic EPR Identity Bound ($\delta \geq \varepsilon^2/2$) provides a single powerful link between the trace distance $\varepsilon$ and the error rate $\delta$, without needing to use fidelity as an intermediary, so it implicitly contains both the necessary and sufficient logic needed to construct the test. In contrast, the multi-pair proof uses the asymmetric Fuchs-van de Graaf inequalities, forcing us to explicitly analyse the logical direction for each guarantee.</p></blockquote><p>Let&rsquo;s quickly verify that $F_n^2 \geq 1 - \varepsilon_1^2$ is a sufficient condition for $D_n \leq \varepsilon_1$ ($\mathbf{H_0}$):</p>$$
F_n^2 \geq 1 - \varepsilon_1^2 \quad\iff\quad 1 - F_n^2 \leq \varepsilon_1^2
$$<p>by rearranging. Substituting this into the upper bound of Fuchs‚Äìvan de Graaf yields</p>$$
D_n ~\leq~ \sqrt{1 - F_n^2} ~\leq~ \sqrt{\varepsilon_1^2} ~=~ \varepsilon_1
$$<p>so indeed $[F_n^2 \geq 1 - \varepsilon_1^2] \implies [D_n \leq \varepsilon_1]$. Similarly we can verify that $F_n^2 \leq 1 - \varepsilon_2^2$ is a necessary condition for $D_n \geq \varepsilon_2$ ($\mathbf{H_1}$) by plugging $\mathbf{H_1}$ into the upper bound of Fuchs‚Äìvan de Graaf:</p>$$
\varepsilon_2 \leq D_n \quad\implies\quad \varepsilon_2 ~\leq~ D_n ~\leq~ \sqrt{1 - F_n^2}.
$$<p>Rearranging</p>$$
\varepsilon_2 \leq \sqrt{1 - F_n^2} \quad\iff\quad F_n^2 \leq 1 - \varepsilon_2^2
$$<p>immediately shows that $[D_n \geq \varepsilon_2] \implies [F_n^2 \leq 1 - \varepsilon_2^2]$ as required.</p><h4 id=defining-the-error-rate-thresholds>Defining the error rate thresholds<a hidden class=anchor aria-hidden=true href=#defining-the-error-rate-thresholds>#</a></h4><p><strong>Lemma (single-pair oracle asymptotic link).</strong> For one call to $\mathbb{O}(\rho_{AB})$, with $\delta = \Pr[Y = 1 \mid M = 1]$, we have $F(\rho_{AB}, \Phi) \geq \sqrt{1 - 2\delta}$.</p><p><strong>Proof sketch.</strong> This lemma is a direct consequence of the Asymptotic EPR Identity Bound established in the single-pair analysis. Since the oracle $\mathbb{O}(\rho_{AB})$ is simply a procedural reframing of a single round of that protocol, the fundamental relationship between the true error rate $\delta$ and the fidelity $F$ remains unchanged. $\quad\square$</p><p>Using this lemma directly, the link between fidelity $F_1$ and true error rate $\delta$ is</p>$$
F_1 \geq \sqrt{1 - 2\delta} \quad\iff\quad \delta \geq \frac{1 - F_1^2}{2}.
$$<p>We will use this relation to define thresholds on $\delta$.</p><blockquote><p><strong>Convention.</strong> For each basis, we relabel Bob&rsquo;s outcomes if needed so the mismatch rate is $\leq 1/2$ (i.e. replace $\delta_b$ by $\min \{\delta_b, 1 - \delta_b\}$). With this standard symmetrisation, the aggregated $\delta \in [0, 1/2]$ and the bound $F_1 \geq \sqrt{1-2\delta}$ is always meaningful.</p></blockquote><p>Concretely, let</p>$$
f(\varepsilon) := \frac{1 - (1 - \varepsilon^2)^{1/n}}{2},
$$<p>and</p>$$
\qquad \delta_{\text{close}} := \frac{1 - (1 - \varepsilon_1^2)^{1/n}}{2} = f(\varepsilon_1),
\qquad \delta_{\text{far}} := \frac{1 - (1 - \varepsilon_2^2)^{1/n}}{2} = f(\varepsilon_2).
$$<p>These choices are justified as follows:</p><ul><li><p>(<strong>Close</strong>) If $\delta \leq \delta_{\text{close}}$, then $F_1 \geq \sqrt{1 - 2\delta} \geq \sqrt{1-2\delta_{\text{close}}}$, hence</p>$$
F_n \geq (1 - 2\delta_{\text{close}})^{n/2} = \sqrt{1 - \varepsilon_1^{2}},
$$<p>so from above $D_n \leq \varepsilon_1$.</p></li><li><p>(<strong>Far</strong>) If $D_n \geq \varepsilon_2$, then $F_n \leq \sqrt{1 - \varepsilon_2^{2}}$, i.e. $F_1 \leq (1 - \varepsilon_2^{2})^{1/(2n)}$. Combining with $\sqrt{1 - 2\delta} \leq F_1$ forces</p>$$
1 - 2\delta \leq (1 - \varepsilon_2^{2})^{1/n} \quad\implies\quad \delta \geq \delta_{\text{far}}.
$$</li></ul><h4 id=bounding-the-promise-gap>Bounding the promise gap<a hidden class=anchor aria-hidden=true href=#bounding-the-promise-gap>#</a></h4><p>The promise gap in $\delta$ is</p>$$
\Delta_{\delta} ~=~ \delta_{\text{far}} - \delta_{\text{close}} ~=~ f(\varepsilon_2) - f(\varepsilon_1).
$$<p>To get a lower bound on the promise gap, we first note that</p>$$
f(\varepsilon) = \frac{1 - (1 - \varepsilon^2)^{1/n}}{2}
$$<p>is continuous on $[0, 1]$ for any $n \geq 2$; we only consider $n \geq 2$ since $n$ is the number of EPR pairs and so $n = 1$ reduces to the single-pair test. Indeed, $f$ is built by composing several maps on $[0, 1]$:</p><ul><li>$\varepsilon \mapsto \varepsilon^2$ (continuous),</li><li>$x \mapsto 1 - x$ (continuous),</li><li>$y \mapsto y^{1/n}$ (continuous for $y \geq 0$).
Each of these components is continuous on the domain $[0, 1]$. Hence their composition, $f$, is also continuous on the closed interval $[0, 1]$.</li></ul><p>By the fundamental theorem of calculus,</p>$$
\Delta_\delta
= f(\varepsilon_2)-f(\varepsilon_1)
= \int_{\varepsilon_1}^{\varepsilon_2} f'(\varepsilon)\,d\varepsilon.
$$<p>For $n\ge2$, differentiating $f(\varepsilon)$ gives</p>$$
f'(\varepsilon) = \frac{\varepsilon}{n}(1 - \varepsilon^2)^{\frac{1}{n} - 1}.
$$<p>Since $0 \leq \varepsilon < 1$ implies $1 - \varepsilon^2 \in (0, 1]$ and $\frac{1}{n} - 1 \leq 0$ as $n \geq 2$, we have</p>$$
(1 - \varepsilon^2)^{\frac{1}{n} - 1} \geq 1 \qquad\left[\,\forall \varepsilon \in [0, 1)\,\right].
$$<p>Multiplying through by $\varepsilon/n$ we get</p>$$
f'(\varepsilon) \geq \frac{\varepsilon}{n}.
$$<p>Therefore,</p>$$
\Delta_\delta = \int_{\varepsilon_1}^{\varepsilon_2} f'(\varepsilon)\,d\varepsilon
~\geq~ \int_{\varepsilon_1}^{\varepsilon_2}\frac{\varepsilon}{n}\,d\varepsilon
=\frac{\varepsilon_2^2 - \varepsilon_1^2}{2n}.
$$<p>Taking $\varepsilon_2\to 1^{-}$ (and using continuity of $f$) shows the same bound holds when $\varepsilon_2 = 1$. Hence, for all $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$,</p>$$
\Delta_\delta \geq \frac{\varepsilon_2^2 - \varepsilon_1^2}{2n}.
$$<blockquote><p><strong>Note.</strong> At $\varepsilon=1$, the factor $(1 - \varepsilon^2)^{\frac{1}{n} - 1}$ diverges (for $n > 2$), which only strengthens $(1 - \varepsilon^2)^{\frac{1}{n} - 1} \geq 1$ and $f'(\varepsilon) \geq \varepsilon/n$. The integral is interpreted as a limit <em>from below</em> when the upper limit is $1$.</p></blockquote><h4 id=decision-rule-and-sample-complexity>Decision rule and sample complexity<a hidden class=anchor aria-hidden=true href=#decision-rule-and-sample-complexity>#</a></h4><p>Define a margin</p>$$
t := \frac{\Delta_{\delta}}{2} = \frac{\delta_{\text{far}} - \delta_{\text{close}}}{2}.
$$<p>Pick a single cutoff inside the gap (the midpoint):</p>$$
\kappa := \frac{\delta_{\text{close}} + \delta_{\text{far}}}{2} = \frac{f(\varepsilon_1) + f(\varepsilon_2)}{2}.
$$<p>After running the protocol and computing the empirical mismatch rate $\hat\delta$ on the matching-basis rounds $S$, we define the decision rule as</p><blockquote>$$
\textbf{Decision rule (easy case)} =
\begin{cases}
\text{‚Äúclose‚Äù} & \text{if } \hat\delta \leq \kappa,\\
\text{‚Äúfar‚Äù} & \text{if } \hat\delta > \kappa.
\end{cases}
$$</blockquote><p>On matching-basis rounds, the indicators $\{ Y_i \}_{i \in S}$ are i.i.d. Bernoulli random variables with mean $\delta$. Chernoff‚ÄìHoeffding gives, for any $t > 0$,</p>$$
\Pr\!\left[|\hat\delta - \delta| \geq t\right] \leq 2e^{-2|S|t^2}.
$$<ul><li><p><strong>Completeness</strong> ($\delta \leq \delta_{\text{close}}$):
If the <em>good</em> event $|\hat\delta - \delta| < t$ holds, then
$\hat\delta \leq \delta_{\text{close}} + t = \kappa \Rightarrow$ accept.</p></li><li><p><strong>Soundness</strong> ($\delta \geq \delta_{\text{far}}$):
If $|\hat\delta-\delta| < t$, then
$\hat\delta > \delta_{\text{far}} - t = \kappa \Rightarrow$ reject.</p></li></ul><p>Therefore, each error (completeness or soundness) occurs only if $|\hat\delta-\delta|\geq t$ (the bad event). To make this probability $\leq \alpha$, it suffices that</p>$$
2e^{-2|S|t^2} \leq \alpha
\quad\iff\quad
|S| \geq \frac{2}{\Delta_\delta^{2}}\,\ln\!\frac{2}{\alpha} \qquad (t = \Delta_\delta/2).
$$<p>The bound on $\Delta_\delta$ from the integral earlier states that</p>$$
\Delta_\delta \geq \frac{\varepsilon_2^2 - \varepsilon_1^2}{2n}.
$$<p>From this, we can derive that</p>$$
\begin{aligned}
\Delta_\delta ~\geq~ \frac{\varepsilon_2^2 - \varepsilon_1^2}{2n} &{\quad\iff\quad} \Delta_\delta^2 ~\geq~ \left(\frac{\varepsilon_2^2 - \varepsilon_1^2}{2n}\right)^2
\\[10pt]&{\quad\iff\quad} \Delta_\delta^2 ~\geq~ \frac{\left(\varepsilon_2^2 - \varepsilon_1^2\right)^2}{4n^2}
\\[10pt]&{\quad\iff\quad} \frac{1}{\Delta_\delta^2} ~\leq~ \frac{4n^2}{\left(\varepsilon_2^2 - \varepsilon_1^2\right)^2}
\\[15pt]&{\quad\iff\quad} \frac{2}{\Delta_\delta^2} \ln \frac{2}{\alpha} ~\leq~ \frac{8n^2}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2} \ln \frac{2}{\alpha} \quad[\,=: L\,].
\end{aligned}
$$<p>Since $\Delta_\delta \geq (\varepsilon_2^2 - \varepsilon_1^2)/(2n)$ and $\frac{2}{\Delta_\delta^2}\,\ln\!\frac{2}{\alpha}$ is strictly decreasing in $\Delta_\delta$, the true requirement is always at most $L$. Therefore, choosing $|S| \geq L$ guarantees the condition is satisfied for all admissible $\Delta_\delta$:</p>$$
|S| \geq \underbrace{\frac{8\,n^2}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2}\,\ln\!\frac{2}{\alpha}}_{\text{Our choice (worst-case }L\text{)}}
\quad\geq\quad
\underbrace{\frac{2}{\Delta_\delta^{2}}\,\ln\!\frac{2}{\alpha}}_{\text{What we actually need}}.
$$<p>In other words, a sufficient condition for $|S|$ is:</p>$$
|S| ~\geq~ \frac{8\,n^2}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2}\,\ln\!\frac{2}{\alpha}.
$$<p>As before, only about half of the $N$ rounds are matching-basis. Taking $N = 4|S|$ (by the same argument from the single-pair case),</p>$$
N ~\geq~ \frac{32\,n^2}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2}\,\ln\!\frac{2}{\alpha} \qquad\left[= O\left(n^2\left(\varepsilon_2^2 - \varepsilon_1^2\right)^{-2}\right)\right].
$$<p>So it turns out that extending the test from a single pair to $n$ i.i.d. pairs is <strong>not</strong> free: the price is a quadratic blow-up in sample complexity, which is intuitive and expected when you consider the difference in the guarantees. Certifying that the <em>entire collection</em> of $n$ states is globally $\varepsilon$-close is a much stricter requirement than certifying a single state. This is because a tiny imperfection in each pair, when compounded over the tensor product of all $n$ states, can result in a large global deviation. To compensate for this, the required fidelity of each pair must be much higher. This in turn forces the promise gap $\Delta_\delta$ for the true error rate $\delta$ to become approximately $n$ times narrower, squeezing the thresholds for &ldquo;close&rdquo; and &ldquo;far&rdquo; states into a much smaller window near zero.</p><p>The reason for this is that our promise is about the <strong>global state</strong> ($\varrho$) of all $n$ pairs. For the global state to be nearly perfect (i.e. have a high global fidelity $F_n = F_1^n$), the fidelity of each <strong>single pair</strong> ($F_1$) must be extremely close to $1$. Since the true error rate $\delta$ is a direct measure of the imperfection in a single pair, this extremely high fidelity requirement forces $\delta$ to be (comparatively) much smaller than it would be in the single-pair test. As a result, this effectively &ldquo;squeezes&rdquo; the entire range of relevant error rates into a tiny window near zero, which makes the absolute gap between our $\delta_{\text{close}}$ and $\delta_{\text{far}}$ thresholds narrower.</p><p>A core principle of statistics is that the uncertainty of an estimated average is proportional to the inverse square root of the number of samples (in our case, this is $1 / \sqrt{|S|}$). To reliably measure a promise gap that is $n$ times smaller, our estimate for $\Delta_\delta$ must be $n$ times more precise. Achieving this $n$-fold increase in precision requires an $n^2$-fold increase in the number of samples, which leads directly to the $O(n^2)$ scaling in complexity we&rsquo;re seeing. Putting everything together succinctly:</p><blockquote><p><strong>Theorem (Finite-sample tolerant EPR identity test, i.i.d. product version).</strong></p><p>For brevity, write</p>$$
\rho = \rho_{AB},\qquad \Phi = \ket{\text{EPR}}\bra{\text{EPR}}_{AB}.
$$<p>Fix $n \geq 2$. There are two i.i.d. notions here, and we use both:</p><ol><li>Within-state (coordinate-wise) i.i.d. - the global hypotheses are tensor powers $\rho^{\otimes n}$ vs. $\Phi^{\otimes n}$ (identical across the $n$ coordinates);</li><li>Across-trials (time-wise) i.i.d. - each call to the oracle $\mathbb{O}(\rho)$ uses a fresh, independent preparation of $\rho$.</li></ol><p>Fix global trace-distance tolerances $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$ and confidence $1 - \alpha$. Define</p>$$
\begin{aligned}
&f(\varepsilon) = \frac{1}{2}\!\left[1 - (1 - \varepsilon^2)^{1/n}\right]&,&
&\delta_{\text{close}} = f(\varepsilon_1),
\\[10pt]&\delta_{\text{far}} = f(\varepsilon_2)&,&
\qquad &\kappa = \frac{\delta_{\text{close}} + \delta_{\text{far}}}{2}.
\end{aligned}
$$<p>Make</p>$$
N ~\geq~ \frac{32\,n^2}{\left( \varepsilon_2^2 - \varepsilon_1^2 \right)^2}\,\ln\!\frac{2}{\alpha}
\qquad\left[= O\left(n^2\left(\varepsilon_2^2 - \varepsilon_1^2\right)^{-2}\right)\right]
$$<p>independent calls to $\mathbb{O}(\rho)$, and compute the observed error rate $\hat{\delta}$. Let the decision rule be to accept <em><strong>iff</strong></em> $\hat{\delta} \leq \kappa$. Then, with sample cost $N$:</p><ul><li>If $D(\rho^{\otimes n},\Phi^{\otimes n}) \leq \varepsilon_1$, the test accepts with probability $\geq 1 - \alpha$.</li><li>If $D(\rho^{\otimes n},\Phi^{\otimes n}) \geq \varepsilon_2$, the test rejects with probability $\geq 1 - \alpha$.</li><li>If $\varepsilon_1 < D(\rho^{\otimes n},\Phi^{\otimes n}) < \varepsilon_2$, no guarantee is provided; the test may accept or reject.</li></ul></blockquote><p>That completes the &ldquo;easy&rdquo; i.i.d. case. Next, we&rsquo;ll remove the identical-pair assumption.</p><hr><h2 id=medium-case-independent-non-identical-pairs>Medium case (independent, non-identical pairs)<a hidden class=anchor aria-hidden=true href=#medium-case-independent-non-identical-pairs>#</a></h2><p>Here the joint state is a product of possibly different single-pair states</p>$$
\varrho = \rho_{1}\otimes\rho_{2}\otimes\dots\otimes\rho_{n},
\quad
\text{vs. } ~
\Phi^{\otimes n}.
$$<p>with no entanglement across copies but with potentially different single-pair states $\rho_i$. In the context of BB84, each copy is attacked &ldquo;from scratch&rdquo; (no cross-round entanglement) but Eve may prepare a different state in every round.</p><p>Exactly as before, we want a single classical test that, with failure probability at most $\alpha$, distinguishes</p>$$
\begin{cases}
~\text{H}_0\text{ (‚Äúclose‚Äù)} &: D_n \leq \varepsilon_1,\\[6pt]
~\text{H}_1\text{ (‚Äúfar‚Äù)} &: D_n \geq \varepsilon_2,
\end{cases}
\qquad
0 \leq \varepsilon_1 < \varepsilon_2 \leq 1,
$$<p>where $D_n := D(\rho_1 \otimes \dots \otimes \rho_n, \Phi^{\otimes n})$.</p><p>For each coordinate $i$ (i.e. each position in the $n$-tuple of pairs), let</p>$$
\delta_i := \Pr[\text{mismatch} \mid \text{matching bases on coordinate } i]
$$<p>be the <em>true</em> mismatch probability for that coordinate, and let</p>$$
\hat{\delta}_i := \frac{\#\{\text{mismatches on coordinate } i\}}{\#\{\text{matching-basis trials on coordinate } i\}}
$$<p>be its <em>empirical</em> mismatch rate from the data.</p><p>In the easy case, all $\delta_i$ are identical because of the i.i.d. assumption. So pooling all matching-basis trials into a single $\hat{\delta}$ is equivalent to estimating $\delta_i$ for any $i$. And as we&rsquo;ve seen, we only need one concentration bound.</p><p>However, for our medium (independent, non-identical) case, the $\delta_i$ may differ. To certify <em>all</em> coordinates simultaneously, we need to guarantee that $|\hat{\delta}_i - \delta_i|$ is small <strong>for every</strong> $i$. This unfortunately forces us to run the test on each coordinate separately and then take a <strong>union bound</strong> over the $n$ coordinates, and we&rsquo;ll soon see that this adds an extra $n \log n$ factor in the sample complexity on top of the easy case.</p><p>Let&rsquo;s get started. First, we organise repeated i.i.d. copies of the <em>entire</em> $n$-tuple into <em>blocks</em>. Note that in the medium case (in fact, for all three cases) we are still given i.i.d. copies of</p>$$
\varrho = \rho_1 \otimes \rho_2 \otimes \cdots \otimes \rho_n,
$$<p>but within $\varrho$, the individual $\rho_i$ may be different.</p><blockquote><p><strong>Definition (block).</strong>
A <em>block</em> is one i.i.d. copy of the product state</p>$$
\varrho = \rho_1 \otimes \rho_2 \otimes \cdots \otimes \rho_n.
$$</blockquote><p>In other words, a block is the basic unit of data for the $n$-pair test: after preparing a block, we make independent calls to the single-pair oracle $\mathbb{O}$ on <em>each</em> coordinate $i = 1, \dots, n$. The block then outputs</p>$$
\bigl\{ (M_{(j, i)},\,Y_{(j, i)}) \bigr\}_{i=1}^n,
$$<p>where $j$ indexes the block. Explicitly, in block $j$ we obtain for each coordinate $i$:</p><ul><li>a matching indicator $M_{(j, i)} \in \{0, 1\}$, which is $1$ if Alice&rsquo;s and Bob&rsquo;s bases matched for that pair;</li><li>and, if $M_{(j, i)} = 1$, a mismatch bit $Y_{(j, i)} \in \{0, 1\}$ with $\mathbb{E}[Y_{(j,i)} \mid M_{(j,i)} = 1] = \delta_i$.</li></ul><p>We repeat this procedure over $R$ independent blocks. The entire dataset forms an $R \times n$ table:</p>$$
\begin{array}{c|cccc}
\text{block } j & i=1 & i=2 & \cdots & i=n \\ \hline
1 & (M_{(1,1)}, Y_{(1,1)}) & (M_{(1,2)}, Y_{(1,2)}) & \cdots & (M_{(1,n)}, Y_{(1,n)}) \\
2 & (M_{(2,1)}, Y_{(2,1)}) & (M_{(2,2)}, Y_{(2,2)}) & \cdots & (M_{(2,n)}, Y_{(2,n)}) \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
R & (M_{(R,1)}, Y_{(R,1)}) & (M_{(R,2)}, Y_{(R,2)}) & \cdots & (M_{(R,n)}, Y_{(R,n)})
\end{array}
$$<p>where each cell comes from a single call to $\mathbb{O}(\rho_i)$. In total, we have made $N = n \cdot R$ calls to the oracle. In this table:</p><ul><li><strong>Rows</strong> (fixed $j$): contain all $n$ coordinates in the same block, prepared together as one copy of $\varrho$. The $\rho_i$ can be different, so entries in the same row are generally <em>not</em> identically distributed.</li><li><strong>Columns</strong> (fixed $i$): contain the same coordinate across $R$ i.i.d. blocks. These entries <em>are</em> i.i.d. samples from $\rho_i$, since each block contains a fresh copy of it in position $i$.</li></ul><p>Therefore, when analysing each coordinate ($i$) separately, the $R$ entries in a column are independent and identically distributed. The union bound will later account for all $n$ coordinates at once.</p><h3 id=per-coordinate-estimator-and-decision-rule>Per-coordinate estimator and decision rule<a hidden class=anchor aria-hidden=true href=#per-coordinate-estimator-and-decision-rule>#</a></h3><p>For each coordinate $i$, define the set of matching-basis rounds across blocks (columns)</p>$$
S_i := \{\, j \in \{1, \dots, R\} : M_{(j, i)} = 1 \,\}.
$$<p>The empirical mismatch rate on coordinate $i$ is</p>$$
\hat\delta_i ~=~ \frac{1}{|S_i|} \sum_{j \in S_i} Y_{(j, i)} \quad\text{(defined when }|S_i| > 0\text{)}.
$$<p>Recall the per-coordinate true parameters $\delta_i = \Pr[\text{mismatch} \mid \text{match on }i]$.</p><p>As in the i.i.d. case, define the function</p>$$
f(\varepsilon) := \tfrac{1}{2}\!\left[1 - (1 - \varepsilon^2)^{1/n}\right],
$$<p>the thresholds</p>$$
\delta_{\text{close}} := f(\varepsilon_1), \quad \delta_{\text{far}} := f(\varepsilon_2),
$$<p>the (midpoint) cutoff</p>$$
\kappa := \tfrac{1}{2}(\delta_{\text{close}} + \delta_{\text{far}}),
$$<p>and set the margin</p>$$
t := \tfrac{1}{2}(\delta_{\text{far}} - \delta_{\text{close}}).
$$<p>(As before, $\delta_{\text{far}} - \delta_{\text{close}} = \Delta_\delta \geq \frac{\varepsilon_2^2-\varepsilon_1^2}{2n}$.)</p><blockquote><p><strong>Decision rule (medium case).</strong></p><p>Accept <em><strong>iff</strong></em></p>$$
\max_{i \in [n]} \hat\delta_i < \kappa.
$$</blockquote><p>In other words, we accept if and only if the worst-case error rate is strictly less than our cutoff $\kappa$, meaning all our error rates $\hat\delta_i$ has to pass the cutoff test.</p><p>Define the <strong>good event</strong></p>$$
\mathcal G ~:=~ \bigcap_{i=1}^n \left\{\,|\hat\delta_i - \delta_i| < t\,\right\},
$$<p>i.e. <em>every</em> column concentrates within the margin $t$. We will set $R$ (hence total oracle calls $N = nR$) so that $\Pr[\mathcal G] \geq 1 - \alpha$ using concentration bounds.</p><p>Let&rsquo;s quickly show completeness and soundness of our decision rule.</p><p><strong>Completeness (close $\Rightarrow$ accept).</strong> If every coordinate is close i.e. $\delta_i \leq \delta_{\text{close}}$ for all $i$, then on the <em>good</em> event $\mathcal{G}$,</p>$$
\hat\delta_i < \delta_i + t ~\le~ \delta_{\text{close}} + t ~=~ \kappa
\quad\implies\quad
\max_i \hat\delta_i < \kappa,
$$<p>so we accept.</p><p><strong>Soundness (far $\Rightarrow$ reject).</strong> This requires some work. If the global state $\varrho = \otimes_{i=1}^n \rho_i$ is far i.e. $D(\varrho, \Phi^{\otimes n}) \geq \varepsilon_2$, then by the (right-hand) Fuchs‚Äìvan de Graaf inequality, the global fidelity, $F_n$, satisfies</p>$$
F_n := F(\varrho, \Phi^{\otimes n}) \leq \sqrt{1 - \varepsilon_2^2}.
$$<p>Fidelity is multiplicative even for <em>heterogeneous</em> products:</p>$$
F_n = \prod_{i=1}^n F_i, \quad\text{where } F_i := F(\rho_i,\Phi).
$$<p>Let $\tau := (1 - \varepsilon_2^2)^{1/(2n)}$, so $\tau^n = \sqrt{1 - \varepsilon_2^2}$. If <strong>every</strong> coordinate satisfied $F_i > \tau$, then</p>$$
F_n ~=~ \prod_{i=1}^n F_i ~>~ \tau^n ~=~ \sqrt{1 - \varepsilon_2^2},
$$<p>contradicting the bound for $F_n$ above. Therefore, there has to exist some coordinate $i^\star$ with</p>$$
F_{i^\star} ~\leq~ \tau ~=~ (1 - \varepsilon_2^2)^{1/(2n)}.
$$<p>Now use the single-pair link $F_i \geq \sqrt{1 - 2\delta_i}$ from the lemma above. Rearranging</p>$$
1 - 2\delta_{i^\star} ~\leq~ F_{i^\star}^2 ~\leq~ \tau^2 = (1 - \varepsilon_2^2)^{1/n}
$$<p>gives</p>$$
\delta_{i^\star} ~\geq~ \frac{1 - (1 - \varepsilon_2^2)^{1/n}}{2} ~=~ f(\varepsilon_2) ~=~ \delta_{\text{far}}.
$$<p>On the good event $\mathcal{G}$,</p>$$
\hat\delta_{i^\star} ~>~ \delta_{i^\star} - t ~\geq~ \delta_{\text{far}} - t ~=~ \kappa,
$$<p>so</p>$$
\max_i \hat\delta_i \geq \hat\delta_{i^\star} > \kappa,
$$<p>and we reject.</p><p>So all we owe now is to make the <em>good event</em> $\mathcal{G}$ hold with probability at least $1 - \alpha$ using a concentration bound.</p><hr><h3 id=concentration-all-coordinates-at-once>Concentration: all coordinates at once<a hidden class=anchor aria-hidden=true href=#concentration-all-coordinates-at-once>#</a></h3><p><code>Complete writeup</code></p><hr><blockquote><p><strong>Theorem (Finite-sample tolerant test, medium case)</strong></p><p>Let $\varrho = \rho_1 \otimes \cdots \otimes \rho_n$. Fix $0 \leq \varepsilon_1 < \varepsilon_2 \leq 1$ and failure probability $\alpha \in (0, 1)$.
Define</p>$$
\begin{aligned}
&f(\varepsilon) = \frac{1}{2}\!\left[1 - (1 - \varepsilon^2)^{1/n}\right]&,&
&\delta_{\text{close}} = f(\varepsilon_1),
\\[10pt]&\delta_{\text{far}} = f(\varepsilon_2)&,&
\qquad &\kappa = \frac{\delta_{\text{close}} + \delta_{\text{far}}}{2}.
\end{aligned}
$$<p>Repeat $R$ times: prepare one block (index $j$), and for each coordinate $i \in [n]$ make one call to $\mathbb{O}(\rho_i)$, yielding $(M_{(j,i)},Y_{(j,i)})$.
For each $i$, let $S_i = \{j: M_{(j, i)} = 1\}$ and compute</p>$$
\hat\delta_i = \frac{1}{|S_i|} \sum_{j\ in S_i} Y_{(j, i)} \qquad(|S_i| > 0).
$$<p>In total we have called the oracle $N$ times. For the test, accept <em><strong>iff</strong></em></p>$$
\max_{i \in [n]} \hat\delta_i < \kappa.
$$<p>If the sample complexity</p>$$
R ~=~ \frac{32\,n^{2}}{(\varepsilon_2^2 - \varepsilon_1^2)^2}\,\ln\!\frac{4n}{\alpha}
\quad\iff\quad
N = nR ~\geq~ \frac{32\,n^3}{(\varepsilon_2^2-\varepsilon_1^2)^2}\,\ln\!\frac{4n}{\alpha},
$$<p>then:</p><ul><li>(<strong>Completeness</strong>) If $D(\varrho, \Phi^{\otimes n}) \leq \varepsilon_1$, then the test accepts with probability at least $1 - \alpha$.</li><li>(<strong>Soundness</strong>) If $D(\varrho, \Phi^{\otimes n}) \geq \varepsilon_2$, the test rejects with probability at least $1 - \alpha$.</li><li>No guarantee can be made in the promise gap $\varepsilon_1 < D(\varrho, \Phi^{\otimes n}) < \varepsilon_2$; the test may accept or reject.</li></ul></blockquote><hr><p><strong>A quick sanity check (why it‚Äôs costlier than the i.i.d. case):</strong>
The global closeness promise forces <em>every</em> coordinate‚Äôs fidelity to be extremely high. That squeezes each per-coordinate mismatch threshold to a gap of width $\Delta_\delta=\Theta\big((\varepsilon_2^2-\varepsilon_1^2)/n\big)$. Estimating $n$ such parameters <em>uniformly</em> within that tiny gap costs $\tilde\Theta(n^2)$ matching samples <strong>per coordinate</strong> (hence $R=\tilde\Theta(n^2)$ blocks) and therefore $N=nR=\tilde\Theta(n^3)$ total oracle calls, with the extra $\ln n$ from the union bound across coordinates.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://teaegg.net/research/urss/epr-tolerant-identity-testing/><span class=title>¬´ Prev</span><br><span>Classical tolerant identity test for the EPR state</span></a></nav></footer></article></main><footer class=footer><span>¬© 2025 ∆¨·òø·ó© ·òø·òú·òú ‚ñ∂Ô∏é ‚Ä¢·Åä·Åä||·Åä|·Åã|||| | ¬∑ Built by Howard ìÜ©ìÇÄìÜ™
<span class=only-desktop>¬∑ Powered by
<a href=https://gohugo.io>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod>PaperMod</a></span></span></footer><a href=#top aria-label="go to top" title="Go to Top" class=top-link id=top-link><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){const n=document.getElementById("greeting");if(!n)return;const e=(new Date).getHours();let t;e>=6&&e<12?t="ÍßÅ …¢÷Ö÷Ö÷Ö…ñ  ç÷Ö Ä’º…®’º…¢! üåª ÍßÇ":e>=12&&e<18?t="ùêÜùê®ùê®ùêù ùêöùêüùê≠ùêûùê´ùêßùê®ùê®ùêß. ‚òÄÔ∏èüå≥‚òï":e>=18&&e<22?t="ùòéùò∞ùò∞ùò• ùò¶ùò∑ùò¶ùòØùò™ùòØùò®. üåÑüõãÔ∏èüìñ":t="ùïôùïñùï™ ùïüùïöùïòùïôùï• ùï†ùï®ùïù... ü¶âüåôüåÉ",n.textContent=t})()</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>